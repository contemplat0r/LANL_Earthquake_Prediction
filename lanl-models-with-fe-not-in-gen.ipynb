{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import importlib\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tqdm\n",
    "import dask\n",
    "import dask.multiprocessing\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, CuDNNGRU, Input, InputLayer\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras' from '/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/dask/context.py:23: UserWarning: The dask.set_options function has been deprecated. Please use dask.config.set instead\n",
      "  warnings.warn(\"The dask.set_options function has been deprecated. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7fccd8306cc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(scheduler='processes')\n",
    "dask.set_options( pool=ThreadPool(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_dask_parralel(\n",
    "#def add_features_parallel(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    \n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    full_data_indexes = tuple(acoustic_data_series.index.tolist())\n",
    "\n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "    output_first_index = 0\n",
    "    output_last_index = len(sample_df) - 1\n",
    "    \n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "   \n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    @dask.delayed\n",
    "    def create_features():\n",
    "        for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "\n",
    "            feature_values_list = list(range(sample_size))\n",
    "\n",
    "            half_window_size = window_size // 2\n",
    "\n",
    "            sample_begin_indexes = sample_indexes[:half_window_size]\n",
    "            full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "            min_full_data_index = min(full_data_indexes)\n",
    "        \n",
    "            in_window_full_data_begin_indexes = set(range(input_first_index, input_first_index + half_window_size))              \n",
    "            in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "                in_window_full_data_begin_indexes\n",
    "            )\n",
    "        \n",
    "            sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "            full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "            max_full_data_index = max(full_data_end_indexes) + 1\n",
    "        \n",
    "            in_window_full_data_end_indexes = set(range(input_last_index - half_window_size, input_last_index))        \n",
    "            in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "                in_window_full_data_end_indexes\n",
    "            )\n",
    "            if in_window_begin_indexes:\n",
    "                begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "                for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                    value = sample_df.iloc[i]['acoustic_data']\n",
    "                    temp = acoustic_data_series.iloc[input_first_index:input_first_index + window_size].mean()\n",
    "                    value = value - temp\n",
    "                    feature_values_list[output_first_index + i] = value\n",
    "                \n",
    "            if in_window_end_indexes:\n",
    "                end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "                for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                    value = sample_df.iloc[output_last_index - i]['acoustic_data']\n",
    "                    temp = acoustic_data_series.iloc[input_last_index - window_size:].mean()\n",
    "                    value = value - temp\n",
    "                    feature_values_list[output_last_index - i] = value\n",
    "                \n",
    "            first_regular_idx = len(begin_indexes_set)\n",
    "            last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "            for i in range(first_regular_idx, last_regular_idx):\n",
    "                sample_idx = sample_indexes[i]\n",
    "                feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                    sample_idx - half_window_size:sample_idx + half_window_size\n",
    "                ].mean()\n",
    "            sample_df[feature_name] = feature_values_list\n",
    "        return sample_df\n",
    "      \n",
    "    sample_df = create_features().compute()\n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features = add_features_dask_parralel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    \n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    full_data_indexes = tuple(acoustic_data_series.index.tolist())\n",
    "\n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "    output_first_index = 0\n",
    "    output_last_index = len(sample_df) - 1\n",
    "    \n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "   \n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "\n",
    "        feature_values_list = list(range(sample_size))\n",
    "\n",
    "        half_window_size = window_size // 2\n",
    "\n",
    "        sample_begin_indexes = sample_indexes[:half_window_size]\n",
    "        full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "        min_full_data_index = min(full_data_indexes)\n",
    "        \n",
    "        in_window_full_data_begin_indexes = set(range(input_first_index, input_first_index + half_window_size))              \n",
    "        in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "            in_window_full_data_begin_indexes\n",
    "        )\n",
    "        \n",
    "        sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "        full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "        max_full_data_index = max(full_data_end_indexes) + 1\n",
    "        \n",
    "        in_window_full_data_end_indexes = set(range(input_last_index - half_window_size, input_last_index))        \n",
    "        in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "            in_window_full_data_end_indexes\n",
    "        )\n",
    "        if in_window_begin_indexes:\n",
    "            begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "            for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                value = sample_df.iloc[i]['acoustic_data']\n",
    "                temp = acoustic_data_series.iloc[input_first_index:input_first_index + window_size].mean()\n",
    "                value = value - temp\n",
    "                feature_values_list[output_first_index + i] = value\n",
    "                \n",
    "        if in_window_end_indexes:\n",
    "            end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "            for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                value = sample_df.iloc[output_last_index - i]['acoustic_data']\n",
    "                temp = acoustic_data_series.iloc[input_last_index - window_size:].mean()\n",
    "                value = value - temp\n",
    "                feature_values_list[output_last_index - i] = value\n",
    "                \n",
    "        first_regular_idx = len(begin_indexes_set)\n",
    "        last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "        for i in range(first_regular_idx, last_regular_idx):\n",
    "            sample_idx = sample_indexes[i]\n",
    "            feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                sample_idx - half_window_size:sample_idx + half_window_size\n",
    "            ].mean()\n",
    "        sample_df[feature_name] = feature_values_list\n",
    "        \n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(z):\n",
    "    print()\n",
    "    print(\"extract_features, z.shape:\", z.shape)\n",
    "    #print()\n",
    "    return np.c_[z.mean(axis=1),\n",
    "                 np.transpose(np.percentile(np.abs(z), q=[0, 50, 75, 100], axis=1)),\n",
    "                 z.std(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def extract_features(z):\n",
    "    return np.c_[z.mean(axis=1),\n",
    "                 np.transpose(np.percentile(np.abs(z), q=[0, 50, 75, 100], axis=1)),\n",
    "                 z.std(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, last_index=None, n_steps=150, step_length=1000):\n",
    "    if last_index == None:\n",
    "        last_index=len(x)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"createX, x.shape:\", x.shape)\n",
    "    print(\"createX, last_index:\", last_index)\n",
    "    print(\"createX, n_steps:\", n_steps)\n",
    "    print(\"createX, step_length:\", step_length)\n",
    "    print(\"last_index - n_steps * step_length:\", last_index - n_steps * step_length)\n",
    "    assert last_index - n_steps * step_length >= 0\n",
    "\n",
    "    # Reshaping and approximate standardization with mean 5 and std 3.\n",
    "    # ORIGINAL: I changed this becuase I got an No OpKernel was registered to support Op 'CudnnRNN' error\n",
    "    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) / 3\n",
    "    # MY CHANGE: This doesn't fix things, I get the same errors\n",
    "    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1).astype(np.float32) - 5 ) / 3\n",
    "    temp = x[(last_index - n_steps * step_length):last_index]\n",
    "    print(\"createX, temp.shape before reshape:\", temp.shape)\n",
    "    temp = temp.reshape(n_steps, -1).astype(np.float32)\n",
    "    print(\"create_X, temp.shape after reshape:\", temp.shape)\n",
    "    temp = (temp - 5) / 3\n",
    "    \n",
    "    # Extracts features of sequences of full length 1000, of the last 100 values and finally also \n",
    "    # of the last 10 observations.\n",
    "    print(\"createX, extract_features(temp).shape:\", extract_features(temp).shape)\n",
    "    print(\"createX, extract_features(temp[:, -step_length // 10:]).shape\", extract_features(temp[:, -step_length // 10:]).shape)\n",
    "    print(\"createX, extract_features(temp[:, -step_length // 100:]).shape\", extract_features(temp[:, -step_length // 100:]).shape)\n",
    "    print()\n",
    "    result = np.c_[\n",
    "        extract_features(temp),\n",
    "        extract_features(temp[:, -step_length // 10:]),\n",
    "        extract_features(temp[:, -step_length // 100:])\n",
    "    ]\n",
    "    '''               \n",
    "    result = np.c_[\n",
    "        temp,\n",
    "        temp[:, -step_length // 10:],\n",
    "        temp[:, -step_length // 100:]\n",
    "    ]\n",
    "    '''\n",
    "    print(\"createX, result shape:\", result.shape)\n",
    "    print()\n",
    "    '''\n",
    "    return np.c_[extract_features(temp),\n",
    "                 extract_features(temp[:, -step_length // 10:]),\n",
    "                 extract_features(temp[:, -step_length // 100:])]\n",
    "    '''\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_X(x, last_index=None, n_steps=150, step_length=1000):\n",
    "    if last_index == None:\n",
    "        last_index=len(x)\n",
    "    \n",
    "    assert last_index - n_steps * step_length >= 0\n",
    "\n",
    "    # Reshaping and approximate standardization with mean 5 and std 3.\n",
    "    # ORIGINAL: I changed this becuase I got an No OpKernel was registered to support Op 'CudnnRNN' error\n",
    "    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) / 3\n",
    "    # MY CHANGE: This doesn't fix things, I get the same errors\n",
    "    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1).astype(np.float32) - 5 ) / 3\n",
    "    temp = x[(last_index - n_steps * step_length):last_index]\n",
    "\n",
    "    temp = temp.reshape(n_steps, -1).astype(np.float32)\n",
    "\n",
    "    temp = (temp - 5) / 3\n",
    "    \n",
    "    # Extracts features of sequences of full length 1000, of the last 100 values and finally also \n",
    "    # of the last 10 observations.\n",
    "\n",
    "    result = np.c_[\n",
    "        extract_features(temp),\n",
    "        extract_features(temp[:, -step_length // 10:]),\n",
    "        extract_features(temp[:, -step_length // 100:])\n",
    "    ]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generator endlessly selects \"batch_size\" ending positions of sub-time series. For each ending position,\n",
    "# the \"time_to_failure\" serves as target, while the features are created by the function \"create_X\".\n",
    "#def generator(data, min_index=0, max_index=None, batch_size=16, n_steps=150, step_length=1000):\n",
    "#def simplified_generator(data, y, batch_size=64, n_steps=150, step_length=1000):\n",
    "def simplified_generator(data, y, batch_size=64):\n",
    "    #if max_index is None:\n",
    "    #    max_index = len(data) - 1\n",
    "    print(\"\\n\")   \n",
    "    print(\"generator, data.shape:\", data.shape)\n",
    "    print(\"generator, batch_size:\", batch_size)\n",
    "    num_of_features = data.shape[1]\n",
    "    \n",
    "    num_of_bathes = data.shape[0] // batch_size\n",
    "    while True:\n",
    "        for i in range(num_of_bathes):\n",
    "        #chunk_len = batch_size * step_length\n",
    "        \n",
    "            data_chunk = data[i * batch_size:(i + 1) * batch_size].reshape(batch_size, 1, num_of_features)\n",
    "            target_chunk = y[i * batch_size:(i + 1) * batch_size]\n",
    "            yield data_chunk, target_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, y, batch_size=64):\n",
    "    \n",
    "    num_of_bathes = data.shape[0] // batch_size\n",
    "    num_of_features = data.shape[1]\n",
    "    \n",
    "    #for i in range(num_of_bathes - 1):\n",
    "    #i = 0\n",
    "    \n",
    "    shift = 0\n",
    "    while True:\n",
    "        \n",
    "        #data_batch = data[i * batch_size:(i + 1) * batch_size].reshape(batch_size, 1, num_of_features)\n",
    "        #target_batch = y[i * batch_size:(i + 1) * batch_size]\n",
    "        #i += 1\n",
    "        #yield data_batch, target_batch\n",
    "        #samples = np.zeros((batch_size, n_steps, n_features))\n",
    "        #targets = np.zeros(batch_size, )\n",
    "\n",
    "        data_batch = np.zeros((batch_size, 1, num_of_features))\n",
    "        target_batch = np.zeros(batch_size, )\n",
    "        #data_batch = None\n",
    "        #target_batch = None\n",
    "        for i in range(shift, shift + batch_size):\n",
    "            #print(\"i:\", i)\n",
    "            #samples[j] = create_X(data[:, 0], last_index=row, n_steps=n_steps, step_length=step_length)\n",
    "            '''\n",
    "            print(\"data_batch.shape:\", data_batch.shape)\n",
    "            print(\"data slice shape:\", data[\n",
    "                i * batch_size:(i + 1) * batch_size\n",
    "            ].shape)\n",
    "            print(\n",
    "                \"data_batch[i * batch_size:(i + 1) * batch_size].shape:\",\n",
    "                data_batch[i * batch_size:(i + 1) * batch_size].shape\n",
    "            )\n",
    "            \n",
    "            data_batch[i * batch_size:(i + 1) * batch_size] = data[\n",
    "                i * batch_size:(i + 1) * batch_size\n",
    "            ].reshape(batch_size, 1, num_of_features)\n",
    "            '''\n",
    "            #data_batch = data[\n",
    "            #    i * batch_size:(i + 1) * batch_size\n",
    "            #].reshape(batch_size, 1, num_of_features)\n",
    "\n",
    "            #target_batch[i * batch_size:(i + 1) * batch_size] = y[i * batch_size:(i + 1) * batch_size]\n",
    "            #target_batch = y[i * batch_size:(i + 1) * batch_size]\n",
    "            #targets[j] = data[row - 1, 1]\n",
    "            data_batch[i] = data[i].reshape(1, 1, num_of_features)\n",
    "            target_batch[i] = y[i]\n",
    "            shift += batch_size\n",
    "        #yield samples, targets\n",
    "        yield data_batch, target_batch\n",
    "#return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def generator(data, y, batch_size=64):\n",
    "    \n",
    "    num_of_bathes = data.shape[0] // batch_size\n",
    "    num_of_features = data.shape[1]\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        #data_batch = np.zeros((batch_size, 1, num_of_features))\n",
    "        #target_batch = np.zeros(batch_size, )\n",
    "        data_batch = None\n",
    "        target_batch = None\n",
    "        #for i in range(shift, shift + batch_size):\n",
    "        for i in range(num_of_bathes):\n",
    "            '''\n",
    "            print(\"data_batch.shape:\", data_batch.shape)\n",
    "            print(\"data slice shape:\", data[\n",
    "                i * batch_size:(i + 1) * batch_size\n",
    "            ].shape)\n",
    "            print(\n",
    "                \"data_batch[i * batch_size:(i + 1) * batch_size].shape:\",\n",
    "                data_batch[i * batch_size:(i + 1) * batch_size].shape\n",
    "            )\n",
    "            \n",
    "            data_batch[i * batch_size:(i + 1) * batch_size] = data[\n",
    "                i * batch_size:(i + 1) * batch_size\n",
    "            ].reshape(batch_size, 1, num_of_features)\n",
    "            '''\n",
    "            data_batch = data[\n",
    "                i * batch_size:(i + 1) * batch_size\n",
    "            ].reshape(batch_size, 1, num_of_features)\n",
    "\n",
    "            #target_batch[i * batch_size:(i + 1) * batch_size] = y[i * batch_size:(i + 1) * batch_size]\n",
    "            target_batch = y[i * batch_size:(i + 1) * batch_size]\n",
    "            #data_batch[i] = data[i].reshape(1, 1, num_of_features)\n",
    "            #target_batch[i] = y[i]\n",
    "            #shift += batch_size\n",
    "        #yield samples, targets\n",
    "        yield data_batch, target_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def generator(data, y, rows, batch_size=16, n_steps=150, step_length=1000):\n",
    "    #if max_index is None:\n",
    "    #    max_index = len(data) - 1\n",
    "\n",
    "        \n",
    "    while True:\n",
    "        \n",
    "        # Pick indices of ending positions\n",
    "        #rows = np.random.randint(min_index + n_steps * step_length, max_index, size=batch_size)\n",
    "         \n",
    "        # Initialize feature matrices and targets\n",
    "        samples = np.zeros((batch_size, n_steps, n_features))\n",
    "        targets = np.zeros(batch_size, )\n",
    "        \n",
    "        for j, row in enumerate(rows):\n",
    "            samples[j] = create_X(data, last_index=row, n_steps=n_steps, step_length=step_length)\n",
    "            #targets[j] = data[row - 1, 1]\n",
    "            targets[j] = y[row - 1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = simplified_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnngru_2 (CuDNNGRU)       (None, 48)                7632      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                490       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 8,133\n",
      "Trainable params: 8,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cb = [ModelCheckpoint(\"model.hdf5\", save_best_only=True, period=3)]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(CuDNNGRU(48, input_shape=(None, n_features)))\n",
    "#model.add(InputLayer((4096, 4)))\n",
    "#model.add(Dense(48))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, input_dim=1000))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#float_data = pd.read_csv(\"../input/train/train.csv\", dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 9.72 s, total: 2min 34s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#        earthquake_df = pd.read_csv(\n",
    "#                '../input/train/train.csv',\n",
    "#                #nrows=100000000,\n",
    "#                names=['acoustic_data', 'time_to_failure'],\n",
    "#                dtype={'acoustic_data': np.float32, 'time_to_failure': np.float32},\n",
    "#                skiprows=earthquake_margin_indexes[i],\n",
    "#                nrows=complete_earthquakes_length[i]\n",
    "#            )\n",
    "\n",
    "train_df = pd.read_csv('../input/train/train.csv', dtype={'acoustic_data': np.float32, 'time_to_failure': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full calculation feature value time (with slicing) 115.58776901563009 min:\n",
      "CPU times: user 1h 56min 45s, sys: 40.3 s, total: 1h 57min 25s\n",
      "Wall time: 1h 57min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#        if not sample_size:\n",
    "#            sample_size = complete_earthquakes_length[i] // 10\n",
    "#        if not holdout_size:\n",
    "#            holdout_size = complete_earthquakes_length[i] // 50\n",
    "#sample_size = train_df.shape[0] // 10\n",
    "#holdout_size = train_df.shape[0] // 50\n",
    "sample_size = 15000000\n",
    "holdout_size = 3000000\n",
    "featured_train_df, featured_holdout_df = add_features(\n",
    "                train_df,\n",
    "                sample_size=sample_size,\n",
    "                holdout_size=holdout_size,\n",
    "                smootch_windows_size = (7, 9)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "      <th>smootch_mean_ws_7</th>\n",
       "      <th>smootch_mean_ws_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acoustic_data  time_to_failure  smootch_mean_ws_7  smootch_mean_ws_9\n",
       "0            3.0           1.4691           6.000000              6.125\n",
       "1            7.0           1.4691           6.000000              5.875\n",
       "2            6.0           1.4691           5.333333              5.125\n",
       "3           10.0           1.4691           7.000000              6.750\n",
       "4            8.0           1.4691           5.333333              5.250"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = featured_train_df[featured_train_df.columns.drop('time_to_failure')]\n",
    "y_all = featured_train_df['time_to_failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_all.kurtosis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape[0] // 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = X_train[:9592 * 512]\n",
    "y_train = y_train[:9592 * 512]\n",
    "X_valid = X_valid[:2397 * 512]\n",
    "y_valid = y_valid[:2397 * 512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_temp.shape[0] % 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_valid.shape[0] // 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_rows = tuple(range(0, 4800000, 150000))[1:]\n",
    "valid_rows = tuple(range(0, 1200000, 150000))[1:]\n",
    "print(train_rows)\n",
    "print(valid_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query \"create_X\" to figure out the number of features\n",
    "#n_features = create_X(float_data[0:150000]).shape[1]\n",
    "#n_features = create_X(X_train[0:150000].values).shape[1]\n",
    "#print(\"Our RNN is based on %i features\"% n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "# Position of second (of 16) earthquake. Used to have a clean split\n",
    "# between train and validation\n",
    "#second_earthquake = 50085877\n",
    "#float_data[second_earthquake, 1]\n",
    "#X_train[second_earthquake, 1]\n",
    "\n",
    "# Initialize generators\n",
    "# train_gen = generator(float_data, batch_size=batch_size) # Use this for better score\n",
    "# train_gen = generator(float_data, batch_size=batch_size, min_index=second_earthquake + 1)\n",
    "# valid_gen = generator(float_data, batch_size=batch_size, max_index=second_earthquake)\n",
    "train_gen = generator(X_train.values, y_train.values, batch_size=batch_size)\n",
    "valid_gen = generator(X_valid.values, y_valid.values, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = train_gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 1, 3)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in_ = Input(shape = (4096, 4), name='input_1')\n",
    "out = Dense(48, activation='relu', name='dense_1')(in_)\n",
    "\n",
    "model = Model(in_, out)\n",
    "#model.add(Dense(48), name='dense_2')\n",
    "#model.add(Dense(10, activation='relu', name='dense_2'))\n",
    "#model.add(Dense(1, name='dense_3'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "\n",
      "generator, data.shape: (2456159, 3)\n",
      "generator, batch_size: 512\n",
      "\n",
      "\n",
      "generator, data.shape: (9824636, 3)\n",
      "generator, batch_size: 512\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 3.2135 - val_loss: 3.0102\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 3.0032 - val_loss: 2.9946\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9990 - val_loss: 2.9937\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9957 - val_loss: 2.9994\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9956 - val_loss: 2.9991\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9972 - val_loss: 2.9940\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9977 - val_loss: 2.9973\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9984 - val_loss: 2.9943\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9938 - val_loss: 3.0024\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9885 - val_loss: 3.0044\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9890 - val_loss: 2.9911\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9962 - val_loss: 3.0086\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9949 - val_loss: 3.0115\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9944 - val_loss: 3.0073\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9890 - val_loss: 2.9915\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9964 - val_loss: 2.9993\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9978 - val_loss: 3.0042\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9937 - val_loss: 2.9988\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9924 - val_loss: 2.9967\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9981 - val_loss: 2.9935\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9956 - val_loss: 3.0015\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9967 - val_loss: 2.9942\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9956 - val_loss: 2.9834\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9927 - val_loss: 2.9924\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9972 - val_loss: 2.9897\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9926 - val_loss: 2.9909\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9991 - val_loss: 2.9919\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9940 - val_loss: 2.9949\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9903 - val_loss: 2.9955\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 2.9851 - val_loss: 2.9937\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=adam(lr=0.0005), loss=\"mae\")\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=1000,\n",
    "                              epochs=30,\n",
    "                              verbose=1,\n",
    "                              callbacks=cb,\n",
    "                              validation_data=valid_gen,\n",
    "                              validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def perf_plot(history, what = 'loss'):\n",
    "    x = history.history[what]\n",
    "    val_x = history.history['val_' + what]\n",
    "    epochs = np.asarray(history.epoch) + 1\n",
    "    \n",
    "    plt.plot(epochs, x, 'bo', label = \"Training \" + what)\n",
    "    plt.plot(epochs, val_x, 'b', label = \"Validation \" + what)\n",
    "    plt.title(\"Training and validation \" + what)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "perf_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id', dtype={\"time_to_failure\": np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c249fc85dc4949e885f60c5dd3b4619f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2624), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "createX, x.shape: (150000,)\n",
      "createX, last_index: 150000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 0\n",
      "createX, temp.shape before reshape: (150000,)\n",
      "create_X, temp.shape after reshape: (150, 1000)\n",
      "\n",
      "extract_features, z.shape: (150, 1000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 1000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected cu_dnngru_2_input to have shape (None, 3) but got array with shape (150, 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-cb77204f4838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/test/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mseg_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acoustic_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_to_failure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected cu_dnngru_2_input to have shape (None, 3) but got array with shape (150, 18)"
     ]
    }
   ],
   "source": [
    "for i, seg_id in enumerate(tqdm.tqdm_notebook(submission.index)):\n",
    "  #  print(i)\n",
    "    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n",
    "    x = seg['acoustic_data'].values\n",
    "    submission.time_to_failure[i] = model.predict(np.expand_dims(create_X(x), 0))\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
