{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask\n",
    "import dask.multiprocessing\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNGRU\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def chunk_add_features():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    \n",
    "    def process_df_chunk(df_chunk, )\n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    \n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    full_data_indexes = tuple(acoustic_data_series.index.tolist())\n",
    "\n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "    output_first_index = 0\n",
    "    output_last_index = len(sample_df) - 1\n",
    "    \n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "   \n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "\n",
    "        feature_values_list = list(range(sample_size))\n",
    "\n",
    "        half_window_size = window_size // 2\n",
    "\n",
    "        sample_begin_indexes = sample_indexes[:half_window_size]\n",
    "        full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "        min_full_data_index = min(full_data_indexes)\n",
    "        \n",
    "        in_window_full_data_begin_indexes = set(range(input_first_index, input_first_index + half_window_size))              \n",
    "        in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "            in_window_full_data_begin_indexes\n",
    "        )\n",
    "        \n",
    "        sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "        full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "        max_full_data_index = max(full_data_end_indexes) + 1\n",
    "        \n",
    "        in_window_full_data_end_indexes = set(range(input_last_index - half_window_size, input_last_index))        \n",
    "        in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "            in_window_full_data_end_indexes\n",
    "        )\n",
    "        if in_window_begin_indexes:\n",
    "            begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "            for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                value = sample_df.iloc[i]['acoustic_data']\n",
    "                temp = acoustic_data_series.iloc[input_first_index:input_first_index + window_size].mean()\n",
    "                value = value - temp\n",
    "                feature_values_list[output_first_index + i] = value\n",
    "                \n",
    "        if in_window_end_indexes:\n",
    "            end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "            for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                value = sample_df.iloc[output_last_index - i]['acoustic_data']\n",
    "                temp = acoustic_data_series.iloc[input_last_index - window_size:].mean()\n",
    "                value = value - temp\n",
    "                feature_values_list[output_last_index - i] = value\n",
    "                \n",
    "        first_regular_idx = len(begin_indexes_set)\n",
    "        last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "        for i in range(first_regular_idx, last_regular_idx):\n",
    "            sample_idx = sample_indexes[i]\n",
    "            feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                sample_idx - half_window_size:sample_idx + half_window_size\n",
    "            ].mean()\n",
    "        sample_df[feature_name] = feature_values_list\n",
    "        \n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
