{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import seed\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNGRU\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(639)\n",
    "set_random_seed(5944)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_data = pd.read_csv(\"../input/train/train.csv\", dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "    ):\n",
    "    \n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    \n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    \n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "    \n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(z):\n",
    "     return np.c_[\n",
    "         z.mean(axis=1),\n",
    "         #np.transpose(np.percentile(np.abs(z), q=[0, 50, 75, 100], axis=1)),\n",
    "         z.std(axis=1),\n",
    "         #z.kurtosis(axis=1),\n",
    "         #z.pow(axis=1)\n",
    "         np.sqrt(np.abs(z)).mean(axis=1),\n",
    "         np.sqrt(np.abs(z)).std(axis=1),\n",
    "         #np.prod(np.sqrt(np.abs(z)))\n",
    "         #np.cos(z).mean(axis=1),\n",
    "         #np.log(np.abs(z)).mean(axis=1)\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, last_index=None, n_steps=150, step_length=1000):\n",
    "    if last_index == None:\n",
    "        last_index=len(x)\n",
    "       \n",
    "    assert last_index - n_steps * step_length >= 0\n",
    "\n",
    "    # Reshaping and approximate standardization with mean 5 and std 3.\n",
    "    # ORIGINAL: I changed this becuase I got an No OpKernel was registered to support Op 'CudnnRNN' error\n",
    "    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) / 3\n",
    "    # MY CHANGE: This doesn't fix things, I get the same errors\n",
    "    temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1).astype(np.float32) - 5 ) / 3\n",
    "    \n",
    "    # Extracts features of sequences of full length 1000, of the last 100 values and finally also \n",
    "    # of the last 10 observations. \n",
    "    return np.c_[extract_features(temp),\n",
    "                 extract_features(temp[:, -step_length // 10:]),\n",
    "                 extract_features(temp[:, -step_length // 100:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query \"create_X\" to figure out the number of features\n",
    "n_features = create_X(float_data[0:150000]).shape[1]\n",
    "print(\"Our RNN is based on %i features\"% n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# The generator endlessly selects \"batch_size\" ending positions of sub-time series. For each ending position,\n",
    "# the \"time_to_failure\" serves as target, while the features are created by the function \"create_X\".\n",
    "def generator(data,min_index=0, max_index=None, batch_size=16, n_steps=150, step_length=1000):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - 1\n",
    "     \n",
    "    while True:\n",
    "        # Pick indices of ending positions\n",
    "        rows = np.random.randint(min_index + n_steps * step_length, max_index, size=batch_size)\n",
    "         \n",
    "        # Initialize feature matrices and targets\n",
    "        samples = np.zeros((batch_size, n_steps, n_features))\n",
    "        targets = np.zeros(batch_size, )\n",
    "        \n",
    "        for j, row in enumerate(rows):\n",
    "            samples[j] = create_X(data[:, 0], last_index=row, n_steps=n_steps, step_length=step_length)\n",
    "            targets[j] = data[row - 1, 1]\n",
    "        yield samples, targets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Position of second (of 16) earthquake. Used to have a clean split\n",
    "# between train and validation\n",
    "second_earthquake = 50085877\n",
    "float_data[second_earthquake, 1]\n",
    "\n",
    "# Initialize generators\n",
    "# train_gen = generator(float_data, batch_size=batch_size) # Use this for better score\n",
    "train_gen = generator(float_data, batch_size=batch_size, min_index=second_earthquake + 1)\n",
    "valid_gen = generator(float_data, batch_size=batch_size, max_index=second_earthquake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [ModelCheckpoint(\"model.hdf5\", save_best_only=True, period=3)]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(CuDNNGRU(48, input_shape=(None, n_features)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.compile(optimizer=adam(lr=0.0005), loss=\"mae\")\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=1000,\n",
    "                              epochs=30,\n",
    "                              verbose=1,\n",
    "                              callbacks=cb,\n",
    "                              validation_data=valid_gen,\n",
    "                              validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_plot(history, what = 'loss'):\n",
    "    x = history.history[what]\n",
    "    val_x = history.history['val_' + what]\n",
    "    epochs = np.asarray(history.epoch) + 1\n",
    "    \n",
    "    plt.plot(epochs, x, 'bo', label = \"Training \" + what)\n",
    "    plt.plot(epochs, val_x, 'b', label = \"Validation \" + what)\n",
    "    plt.title(\"Training and validation \" + what)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "perf_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id', dtype={\"time_to_failure\": np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seg_id in enumerate(tqdm(submission.index)):\n",
    "  #  print(i)\n",
    "    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n",
    "    x = seg['acoustic_data'].values\n",
    "    submission.time_to_failure[i] = model.predict(np.expand_dims(create_X(x), 0))\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission-2019-05-25-5-simply-mean-and-std-and-sqrt-mean-and-std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simply mean and std and cos std\n",
    "Epoch 1/30\n",
    "1000/1000 [==============================] - 248s 248ms/step - loss: 2.9901 - val_loss: 1.9164\n",
    "Epoch 2/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.1430 - val_loss: 1.9244\n",
    "Epoch 3/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.1159 - val_loss: 1.9459\n",
    "Epoch 4/30\n",
    "1000/1000 [==============================] - 246s 246ms/step - loss: 2.1170 - val_loss: 1.8193\n",
    "Epoch 5/30\n",
    "1000/1000 [==============================] - 246s 246ms/step - loss: 2.1232 - val_loss: 1.8641\n",
    "Epoch 6/30\n",
    "1000/1000 [==============================] - 242s 242ms/step - loss: 2.1084 - val_loss: 1.8563\n",
    "Epoch 7/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.1159 - val_loss: 1.8426\n",
    "Epoch 8/30\n",
    "1000/1000 [==============================] - 254s 254ms/step - loss: 2.1002 - val_loss: 1.8846\n",
    "Epoch 9/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.0990 - val_loss: 1.9181\n",
    "Epoch 10/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0976 - val_loss: 1.8273\n",
    "Epoch 11/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0807 - val_loss: 1.8851\n",
    "Epoch 12/30\n",
    "1000/1000 [==============================] - 248s 248ms/step - loss: 2.0681 - val_loss: 1.7579\n",
    "Epoch 13/30\n",
    "1000/1000 [==============================] - 244s 244ms/step - loss: 2.0666 - val_loss: 1.8162\n",
    "Epoch 14/30\n",
    "1000/1000 [==============================] - 244s 244ms/step - loss: 2.0657 - val_loss: 1.8746\n",
    "Epoch 15/30\n",
    "1000/1000 [==============================] - 248s 248ms/step - loss: 2.0517 - val_loss: 1.8078\n",
    "Epoch 16/30\n",
    "1000/1000 [==============================] - 249s 249ms/step - loss: 2.0486 - val_loss: 1.8673\n",
    "Epoch 17/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0425 - val_loss: 1.8176\n",
    "Epoch 18/30\n",
    "1000/1000 [==============================] - 247s 247ms/step - loss: 2.0564 - val_loss: 1.7874\n",
    "Epoch 19/30\n",
    "1000/1000 [==============================] - 254s 254ms/step - loss: 2.0357 - val_loss: 1.7595\n",
    "Epoch 20/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0284 - val_loss: 1.7087\n",
    "Epoch 21/30\n",
    "1000/1000 [==============================] - 250s 250ms/step - loss: 2.0457 - val_loss: 1.7775\n",
    "Epoch 22/30\n",
    "1000/1000 [==============================] - 249s 249ms/step - loss: 2.0421 - val_loss: 1.8485\n",
    "Epoch 23/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.0524 - val_loss: 1.8584\n",
    "Epoch 24/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.0299 - val_loss: 1.8553\n",
    "Epoch 25/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.0478 - val_loss: 1.8547\n",
    "Epoch 26/30\n",
    "1000/1000 [==============================] - 249s 249ms/step - loss: 2.0386 - val_loss: 1.8735\n",
    "Epoch 27/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0407 - val_loss: 1.8122\n",
    "Epoch 28/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.0359 - val_loss: 1.9260\n",
    "Epoch 29/30\n",
    "1000/1000 [==============================] - 255s 255ms/step - loss: 2.0335 - val_loss: 1.8426\n",
    "Epoch 30/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0313 - val_loss: 1.7814\n",
    "CPU times: user 2h 15min 42s, sys: 1min 26s, total: 2h 17min 9s\n",
    "Wall time: 2h 5min 9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simply mean and std\n",
    "Epoch 1/30\n",
    "1000/1000 [==============================] - 92s 92ms/step - loss: 2.4773 - val_loss: 1.8584\n",
    "Epoch 2/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.1377 - val_loss: 1.9840\n",
    "Epoch 3/30\n",
    "1000/1000 [==============================] - 93s 93ms/step - loss: 2.1262 - val_loss: 1.8766\n",
    "Epoch 4/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.1176 - val_loss: 2.0576\n",
    "Epoch 5/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.1047 - val_loss: 1.9017\n",
    "Epoch 6/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.1160 - val_loss: 1.8693\n",
    "Epoch 7/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.1052 - val_loss: 1.8665\n",
    "Epoch 8/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.1022 - val_loss: 1.7413\n",
    "Epoch 9/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0809 - val_loss: 1.8707\n",
    "Epoch 10/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0681 - val_loss: 1.8087\n",
    "Epoch 11/30\n",
    "1000/1000 [==============================] - 94s 94ms/step - loss: 2.0653 - val_loss: 1.8031\n",
    "Epoch 12/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0618 - val_loss: 1.8276\n",
    "Epoch 13/30\n",
    "1000/1000 [==============================] - 94s 94ms/step - loss: 2.0504 - val_loss: 1.6156\n",
    "Epoch 14/30\n",
    "1000/1000 [==============================] - 94s 94ms/step - loss: 2.0455 - val_loss: 1.8251\n",
    "Epoch 15/30\n",
    "1000/1000 [==============================] - 93s 93ms/step - loss: 2.0601 - val_loss: 1.8663\n",
    "Epoch 16/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0478 - val_loss: 1.7238\n",
    "Epoch 17/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0511 - val_loss: 1.8351\n",
    "Epoch 18/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0514 - val_loss: 1.8227\n",
    "Epoch 19/30\n",
    "1000/1000 [==============================] - 94s 94ms/step - loss: 2.0538 - val_loss: 1.8032\n",
    "Epoch 20/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0517 - val_loss: 1.8739\n",
    "Epoch 21/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0480 - val_loss: 1.7660\n",
    "Epoch 22/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0491 - val_loss: 1.7206\n",
    "Epoch 23/30\n",
    "1000/1000 [==============================] - 93s 93ms/step - loss: 2.0429 - val_loss: 1.9183\n",
    "Epoch 24/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0418 - val_loss: 1.7688\n",
    "Epoch 25/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0469 - val_loss: 1.7554\n",
    "Epoch 26/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0562 - val_loss: 1.6820\n",
    "Epoch 27/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0588 - val_loss: 1.7710\n",
    "Epoch 28/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0381 - val_loss: 1.8879\n",
    "Epoch 29/30\n",
    "1000/1000 [==============================] - 92s 92ms/step - loss: 2.0401 - val_loss: 1.8273\n",
    "Epoch 30/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0362 - val_loss: 1.8246\n",
    "CPU times: user 54min 47s, sys: 1min 19s, total: 56min 6s\n",
    "Wall time: 45min 36s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simply mean and std and sqrt mean\n",
    "Epoch 1/30\n",
    "1000/1000 [==============================] - 119s 119ms/step - loss: 2.6020 - val_loss: 1.8835\n",
    "Epoch 2/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.1425 - val_loss: 1.8158\n",
    "Epoch 3/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.1146 - val_loss: 2.0112\n",
    "Epoch 4/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.1073 - val_loss: 1.8081\n",
    "Epoch 5/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.1059 - val_loss: 1.7899\n",
    "Epoch 6/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.1087 - val_loss: 1.8111\n",
    "Epoch 7/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.1139 - val_loss: 1.9136\n",
    "Epoch 8/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0855 - val_loss: 1.9241\n",
    "Epoch 9/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0827 - val_loss: 1.9298\n",
    "Epoch 10/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0732 - val_loss: 1.8520\n",
    "Epoch 11/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0762 - val_loss: 1.8775\n",
    "Epoch 12/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0617 - val_loss: 1.8242\n",
    "Epoch 13/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0435 - val_loss: 1.8089\n",
    "Epoch 14/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0519 - val_loss: 1.6844\n",
    "Epoch 15/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0479 - val_loss: 1.7952\n",
    "Epoch 16/30\n",
    "1000/1000 [==============================] - 122s 122ms/step - loss: 2.0517 - val_loss: 1.8399\n",
    "Epoch 17/30\n",
    "1000/1000 [==============================] - 120s 120ms/step - loss: 2.0537 - val_loss: 1.8737\n",
    "Epoch 18/30\n",
    "1000/1000 [==============================] - 120s 120ms/step - loss: 2.0388 - val_loss: 1.8788\n",
    "Epoch 19/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0486 - val_loss: 1.8394\n",
    "Epoch 20/30\n",
    "1000/1000 [==============================] - 120s 120ms/step - loss: 2.0551 - val_loss: 1.8790\n",
    "Epoch 21/30\n",
    "1000/1000 [==============================] - 120s 120ms/step - loss: 2.0580 - val_loss: 1.8425\n",
    "Epoch 22/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0423 - val_loss: 1.6663\n",
    "Epoch 23/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0528 - val_loss: 1.8478\n",
    "Epoch 24/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0481 - val_loss: 1.9197\n",
    "Epoch 25/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0478 - val_loss: 1.8522\n",
    "Epoch 26/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0310 - val_loss: 1.7600\n",
    "Epoch 27/30\n",
    "1000/1000 [==============================] - 119s 119ms/step - loss: 2.0462 - val_loss: 1.7277\n",
    "Epoch 28/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0414 - val_loss: 1.7540\n",
    "Epoch 29/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0317 - val_loss: 1.8865\n",
    "Epoch 30/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0364 - val_loss: 1.7143\n",
    "CPU times: user 1h 8min 33s, sys: 1min 22s, total: 1h 9min 55s\n",
    "Wall time: 59min 4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simply mean and std and sqrt mean and std\n",
    "Epoch 1/30\n",
    "1000/1000 [==============================] - 173s 173ms/step - loss: 2.5647 - val_loss: 1.8682\n",
    "Epoch 2/30\n",
    "1000/1000 [==============================] - 171s 171ms/step - loss: 2.1408 - val_loss: 1.8078\n",
    "Epoch 3/30\n",
    "1000/1000 [==============================] - 172s 172ms/step - loss: 2.1503 - val_loss: 1.9401\n",
    "Epoch 4/30\n",
    "1000/1000 [==============================] - 175s 175ms/step - loss: 2.1204 - val_loss: 2.0239\n",
    "Epoch 5/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.1167 - val_loss: 1.8428\n",
    "Epoch 6/30\n",
    "1000/1000 [==============================] - 176s 176ms/step - loss: 2.1198 - val_loss: 1.9124\n",
    "Epoch 7/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.1093 - val_loss: 1.8500\n",
    "Epoch 8/30\n",
    "1000/1000 [==============================] - 170s 170ms/step - loss: 2.0925 - val_loss: 1.8990\n",
    "Epoch 9/30\n",
    "1000/1000 [==============================] - 171s 171ms/step - loss: 2.0940 - val_loss: 1.9609\n",
    "Epoch 10/30\n",
    "1000/1000 [==============================] - 172s 172ms/step - loss: 2.0713 - val_loss: 1.8797\n",
    "Epoch 11/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.0823 - val_loss: 1.8836\n",
    "Epoch 12/30\n",
    "1000/1000 [==============================] - 177s 177ms/step - loss: 2.0565 - val_loss: 1.8751\n",
    "Epoch 13/30\n",
    "1000/1000 [==============================] - 177s 177ms/step - loss: 2.0569 - val_loss: 1.7065\n",
    "Epoch 14/30\n",
    "1000/1000 [==============================] - 176s 176ms/step - loss: 2.0620 - val_loss: 1.8654\n",
    "Epoch 15/30\n",
    "1000/1000 [==============================] - 173s 173ms/step - loss: 2.0601 - val_loss: 1.8119\n",
    "Epoch 16/30\n",
    "1000/1000 [==============================] - 171s 171ms/step - loss: 2.0681 - val_loss: 1.7609\n",
    "Epoch 17/30\n",
    "1000/1000 [==============================] - 171s 171ms/step - loss: 2.0520 - val_loss: 1.8465\n",
    "Epoch 18/30\n",
    "1000/1000 [==============================] - 177s 177ms/step - loss: 2.0620 - val_loss: 1.8474\n",
    "Epoch 19/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.0488 - val_loss: 1.7527\n",
    "Epoch 20/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.0633 - val_loss: 1.7802\n",
    "Epoch 21/30\n",
    "1000/1000 [==============================] - 170s 170ms/step - loss: 2.0398 - val_loss: 1.7175\n",
    "Epoch 22/30\n",
    "1000/1000 [==============================] - 170s 170ms/step - loss: 2.0485 - val_loss: 1.8967\n",
    "Epoch 23/30\n",
    "1000/1000 [==============================] - 172s 172ms/step - loss: 2.0430 - val_loss: 1.7251\n",
    "Epoch 24/30\n",
    "1000/1000 [==============================] - 176s 176ms/step - loss: 2.0632 - val_loss: 1.8947\n",
    "Epoch 25/30\n",
    "1000/1000 [==============================] - 177s 177ms/step - loss: 2.0498 - val_loss: 1.7527\n",
    "Epoch 26/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.0446 - val_loss: 1.8972\n",
    "Epoch 27/30\n",
    "1000/1000 [==============================] - 174s 174ms/step - loss: 2.0503 - val_loss: 1.8240\n",
    "Epoch 28/30\n",
    "1000/1000 [==============================] - 172s 172ms/step - loss: 2.0489 - val_loss: 1.8254\n",
    "Epoch 29/30\n",
    "1000/1000 [==============================] - 172s 172ms/step - loss: 2.0521 - val_loss: 1.7947\n",
    "Epoch 30/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.0490 - val_loss: 1.7992\n",
    "CPU times: user 1h 37min 7s, sys: 1min 31s, total: 1h 38min 39s\n",
    "Wall time: 1h 27min 9s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
