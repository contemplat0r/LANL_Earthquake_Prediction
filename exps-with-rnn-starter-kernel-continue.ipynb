{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import seed\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNGRU\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(639)\n",
    "set_random_seed(5944)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unarch', 'lanl-features.zip', 'test.zip', 'sample_submission.csv', 'train.csv.zip', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_data = pd.read_csv(\"../input/train/train.csv\", dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "    ):\n",
    "    \n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    \n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    \n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "    \n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(z):\n",
    "     return np.c_[\n",
    "         z.mean(axis=1),\n",
    "         #np.transpose(np.percentile(np.abs(z), q=[0, 50, 75, 100], axis=1)),\n",
    "         #z.std(axis=1),\n",
    "         #z.kurtosis(axis=1),\n",
    "         #z.pow(axis=1)\n",
    "         np.sqrt(np.abs(z)).mean(axis=1),\n",
    "         #np.sqrt(np.abs(z)).std(axis=1),\n",
    "         #np.prod(np.sqrt(np.abs(z)))\n",
    "         #np.cos(z).mean(axis=1),\n",
    "         #np.log(np.abs(z)).mean(axis=1)\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, last_index=None, n_steps=150, step_length=1000):\n",
    "    if last_index == None:\n",
    "        last_index=len(x)\n",
    "       \n",
    "    assert last_index - n_steps * step_length >= 0\n",
    "\n",
    "    # Reshaping and approximate standardization with mean 5 and std 3.\n",
    "    # ORIGINAL: I changed this becuase I got an No OpKernel was registered to support Op 'CudnnRNN' error\n",
    "    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) / 3\n",
    "    # MY CHANGE: This doesn't fix things, I get the same errors\n",
    "    temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1).astype(np.float32) - 5 ) / 3\n",
    "    \n",
    "    # Extracts features of sequences of full length 1000, of the last 100 values and finally also \n",
    "    # of the last 10 observations. \n",
    "    return np.c_[extract_features(temp),\n",
    "                 extract_features(temp[:, -step_length // 10:]),\n",
    "                 extract_features(temp[:, -step_length // 100:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our RNN is based on 6 features\n"
     ]
    }
   ],
   "source": [
    "# Query \"create_X\" to figure out the number of features\n",
    "n_features = create_X(float_data[0:150000]).shape[1]\n",
    "print(\"Our RNN is based on %i features\"% n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# The generator endlessly selects \"batch_size\" ending positions of sub-time series. For each ending position,\n",
    "# the \"time_to_failure\" serves as target, while the features are created by the function \"create_X\".\n",
    "def generator(data,min_index=0, max_index=None, batch_size=16, n_steps=150, step_length=1000):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - 1\n",
    "     \n",
    "    while True:\n",
    "        # Pick indices of ending positions\n",
    "        rows = np.random.randint(min_index + n_steps * step_length, max_index, size=batch_size)\n",
    "         \n",
    "        # Initialize feature matrices and targets\n",
    "        samples = np.zeros((batch_size, n_steps, n_features))\n",
    "        targets = np.zeros(batch_size, )\n",
    "        \n",
    "        for j, row in enumerate(rows):\n",
    "            samples[j] = create_X(data[:, 0], last_index=row, n_steps=n_steps, step_length=step_length)\n",
    "            targets[j] = data[row - 1, 1]\n",
    "        yield samples, targets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Position of second (of 16) earthquake. Used to have a clean split\n",
    "# between train and validation\n",
    "second_earthquake = 50085877\n",
    "float_data[second_earthquake, 1]\n",
    "\n",
    "# Initialize generators\n",
    "# train_gen = generator(float_data, batch_size=batch_size) # Use this for better score\n",
    "train_gen = generator(float_data, batch_size=batch_size, min_index=second_earthquake + 1)\n",
    "valid_gen = generator(float_data, batch_size=batch_size, max_index=second_earthquake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnngru_3 (CuDNNGRU)       (None, 48)                8064      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                490       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 8,565\n",
      "Trainable params: 8,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cb = [ModelCheckpoint(\"model.hdf5\", save_best_only=True, period=3)]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(CuDNNGRU(48, input_shape=(None, n_features)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 2.7623 - val_loss: 2.0632\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.1822 - val_loss: 1.9096\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.1470 - val_loss: 1.9180\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.1497 - val_loss: 2.1051\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.1433 - val_loss: 1.8787\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.1251 - val_loss: 1.8398\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.1094 - val_loss: 1.7963\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 2.0929 - val_loss: 1.7957\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 2.1003 - val_loss: 1.8700\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0859 - val_loss: 1.9502\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 2.0775 - val_loss: 1.9206\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 2.0882 - val_loss: 2.0471\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 2.0842 - val_loss: 1.8330\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0847 - val_loss: 1.9045\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 2.0776 - val_loss: 1.8023\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 2.0687 - val_loss: 1.8187\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0787 - val_loss: 1.8809\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0815 - val_loss: 1.8994\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0638 - val_loss: 1.8222\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0645 - val_loss: 1.7890\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0711 - val_loss: 1.8259\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 2.0729 - val_loss: 1.9304\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0716 - val_loss: 1.8073\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0597 - val_loss: 1.8617\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0739 - val_loss: 1.8091\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0714 - val_loss: 1.7995\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0680 - val_loss: 1.7956\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 2.0748 - val_loss: 1.7930\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 2.0701 - val_loss: 1.8978\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 2.0610 - val_loss: 1.8785\n",
      "CPU times: user 48min 31s, sys: 1min 17s, total: 49min 49s\n",
      "Wall time: 39min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(optimizer=adam(lr=0.0005), loss=\"mae\")\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=1000,\n",
    "                              epochs=30,\n",
    "                              verbose=1,\n",
    "                              callbacks=cb,\n",
    "                              validation_data=valid_gen,\n",
    "                              validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def perf_plot(history, what = 'loss'):\n",
    "    x = history.history[what]\n",
    "    val_x = history.history['val_' + what]\n",
    "    epochs = np.asarray(history.epoch) + 1\n",
    "    \n",
    "    plt.plot(epochs, x, 'bo', label = \"Training \" + what)\n",
    "    plt.plot(epochs, val_x, 'b', label = \"Validation \" + what)\n",
    "    plt.title(\"Training and validation \" + what)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "perf_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id', dtype={\"time_to_failure\": np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2624/2624 [01:06<00:00, 39.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seg_00030f</th>\n",
       "      <td>3.150682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_0012b5</th>\n",
       "      <td>5.456129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_00184e</th>\n",
       "      <td>4.429152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_003339</th>\n",
       "      <td>7.900258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_0042cc</th>\n",
       "      <td>5.565243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_to_failure\n",
       "seg_id                     \n",
       "seg_00030f         3.150682\n",
       "seg_0012b5         5.456129\n",
       "seg_00184e         4.429152\n",
       "seg_003339         7.900258\n",
       "seg_0042cc         5.565243"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, seg_id in enumerate(tqdm(submission.index)):\n",
    "  #  print(i)\n",
    "    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n",
    "    x = seg['acoustic_data'].values\n",
    "    submission.time_to_failure[i] = model.predict(np.expand_dims(create_X(x), 0))\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission-2019-05-25-7-simply-mean-and-sqrt-mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simply mean and std and cos std\n",
    "Epoch 1/30\n",
    "1000/1000 [==============================] - 248s 248ms/step - loss: 2.9901 - val_loss: 1.9164\n",
    "Epoch 2/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.1430 - val_loss: 1.9244\n",
    "Epoch 3/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.1159 - val_loss: 1.9459\n",
    "Epoch 4/30\n",
    "1000/1000 [==============================] - 246s 246ms/step - loss: 2.1170 - val_loss: 1.8193\n",
    "Epoch 5/30\n",
    "1000/1000 [==============================] - 246s 246ms/step - loss: 2.1232 - val_loss: 1.8641\n",
    "Epoch 6/30\n",
    "1000/1000 [==============================] - 242s 242ms/step - loss: 2.1084 - val_loss: 1.8563\n",
    "Epoch 7/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.1159 - val_loss: 1.8426\n",
    "Epoch 8/30\n",
    "1000/1000 [==============================] - 254s 254ms/step - loss: 2.1002 - val_loss: 1.8846\n",
    "Epoch 9/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.0990 - val_loss: 1.9181\n",
    "Epoch 10/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0976 - val_loss: 1.8273\n",
    "Epoch 11/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0807 - val_loss: 1.8851\n",
    "Epoch 12/30\n",
    "1000/1000 [==============================] - 248s 248ms/step - loss: 2.0681 - val_loss: 1.7579\n",
    "Epoch 13/30\n",
    "1000/1000 [==============================] - 244s 244ms/step - loss: 2.0666 - val_loss: 1.8162\n",
    "Epoch 14/30\n",
    "1000/1000 [==============================] - 244s 244ms/step - loss: 2.0657 - val_loss: 1.8746\n",
    "Epoch 15/30\n",
    "1000/1000 [==============================] - 248s 248ms/step - loss: 2.0517 - val_loss: 1.8078\n",
    "Epoch 16/30\n",
    "1000/1000 [==============================] - 249s 249ms/step - loss: 2.0486 - val_loss: 1.8673\n",
    "Epoch 17/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0425 - val_loss: 1.8176\n",
    "Epoch 18/30\n",
    "1000/1000 [==============================] - 247s 247ms/step - loss: 2.0564 - val_loss: 1.7874\n",
    "Epoch 19/30\n",
    "1000/1000 [==============================] - 254s 254ms/step - loss: 2.0357 - val_loss: 1.7595\n",
    "Epoch 20/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0284 - val_loss: 1.7087\n",
    "Epoch 21/30\n",
    "1000/1000 [==============================] - 250s 250ms/step - loss: 2.0457 - val_loss: 1.7775\n",
    "Epoch 22/30\n",
    "1000/1000 [==============================] - 249s 249ms/step - loss: 2.0421 - val_loss: 1.8485\n",
    "Epoch 23/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.0524 - val_loss: 1.8584\n",
    "Epoch 24/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.0299 - val_loss: 1.8553\n",
    "Epoch 25/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.0478 - val_loss: 1.8547\n",
    "Epoch 26/30\n",
    "1000/1000 [==============================] - 249s 249ms/step - loss: 2.0386 - val_loss: 1.8735\n",
    "Epoch 27/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0407 - val_loss: 1.8122\n",
    "Epoch 28/30\n",
    "1000/1000 [==============================] - 252s 252ms/step - loss: 2.0359 - val_loss: 1.9260\n",
    "Epoch 29/30\n",
    "1000/1000 [==============================] - 255s 255ms/step - loss: 2.0335 - val_loss: 1.8426\n",
    "Epoch 30/30\n",
    "1000/1000 [==============================] - 253s 253ms/step - loss: 2.0313 - val_loss: 1.7814\n",
    "CPU times: user 2h 15min 42s, sys: 1min 26s, total: 2h 17min 9s\n",
    "Wall time: 2h 5min 9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simply mean and std\n",
    "Epoch 1/30\n",
    "1000/1000 [==============================] - 92s 92ms/step - loss: 2.4773 - val_loss: 1.8584\n",
    "Epoch 2/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.1377 - val_loss: 1.9840\n",
    "Epoch 3/30\n",
    "1000/1000 [==============================] - 93s 93ms/step - loss: 2.1262 - val_loss: 1.8766\n",
    "Epoch 4/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.1176 - val_loss: 2.0576\n",
    "Epoch 5/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.1047 - val_loss: 1.9017\n",
    "Epoch 6/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.1160 - val_loss: 1.8693\n",
    "Epoch 7/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.1052 - val_loss: 1.8665\n",
    "Epoch 8/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.1022 - val_loss: 1.7413\n",
    "Epoch 9/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0809 - val_loss: 1.8707\n",
    "Epoch 10/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0681 - val_loss: 1.8087\n",
    "Epoch 11/30\n",
    "1000/1000 [==============================] - 94s 94ms/step - loss: 2.0653 - val_loss: 1.8031\n",
    "Epoch 12/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0618 - val_loss: 1.8276\n",
    "Epoch 13/30\n",
    "1000/1000 [==============================] - 94s 94ms/step - loss: 2.0504 - val_loss: 1.6156\n",
    "Epoch 14/30\n",
    "1000/1000 [==============================] - 94s 94ms/step - loss: 2.0455 - val_loss: 1.8251\n",
    "Epoch 15/30\n",
    "1000/1000 [==============================] - 93s 93ms/step - loss: 2.0601 - val_loss: 1.8663\n",
    "Epoch 16/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0478 - val_loss: 1.7238\n",
    "Epoch 17/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0511 - val_loss: 1.8351\n",
    "Epoch 18/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0514 - val_loss: 1.8227\n",
    "Epoch 19/30\n",
    "1000/1000 [==============================] - 94s 94ms/step - loss: 2.0538 - val_loss: 1.8032\n",
    "Epoch 20/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0517 - val_loss: 1.8739\n",
    "Epoch 21/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0480 - val_loss: 1.7660\n",
    "Epoch 22/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0491 - val_loss: 1.7206\n",
    "Epoch 23/30\n",
    "1000/1000 [==============================] - 93s 93ms/step - loss: 2.0429 - val_loss: 1.9183\n",
    "Epoch 24/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0418 - val_loss: 1.7688\n",
    "Epoch 25/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0469 - val_loss: 1.7554\n",
    "Epoch 26/30\n",
    "1000/1000 [==============================] - 90s 90ms/step - loss: 2.0562 - val_loss: 1.6820\n",
    "Epoch 27/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0588 - val_loss: 1.7710\n",
    "Epoch 28/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0381 - val_loss: 1.8879\n",
    "Epoch 29/30\n",
    "1000/1000 [==============================] - 92s 92ms/step - loss: 2.0401 - val_loss: 1.8273\n",
    "Epoch 30/30\n",
    "1000/1000 [==============================] - 91s 91ms/step - loss: 2.0362 - val_loss: 1.8246\n",
    "CPU times: user 54min 47s, sys: 1min 19s, total: 56min 6s\n",
    "Wall time: 45min 36s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simply mean and std and sqrt mean\n",
    "Epoch 1/30\n",
    "1000/1000 [==============================] - 119s 119ms/step - loss: 2.6020 - val_loss: 1.8835\n",
    "Epoch 2/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.1425 - val_loss: 1.8158\n",
    "Epoch 3/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.1146 - val_loss: 2.0112\n",
    "Epoch 4/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.1073 - val_loss: 1.8081\n",
    "Epoch 5/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.1059 - val_loss: 1.7899\n",
    "Epoch 6/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.1087 - val_loss: 1.8111\n",
    "Epoch 7/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.1139 - val_loss: 1.9136\n",
    "Epoch 8/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0855 - val_loss: 1.9241\n",
    "Epoch 9/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0827 - val_loss: 1.9298\n",
    "Epoch 10/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0732 - val_loss: 1.8520\n",
    "Epoch 11/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0762 - val_loss: 1.8775\n",
    "Epoch 12/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0617 - val_loss: 1.8242\n",
    "Epoch 13/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0435 - val_loss: 1.8089\n",
    "Epoch 14/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0519 - val_loss: 1.6844\n",
    "Epoch 15/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0479 - val_loss: 1.7952\n",
    "Epoch 16/30\n",
    "1000/1000 [==============================] - 122s 122ms/step - loss: 2.0517 - val_loss: 1.8399\n",
    "Epoch 17/30\n",
    "1000/1000 [==============================] - 120s 120ms/step - loss: 2.0537 - val_loss: 1.8737\n",
    "Epoch 18/30\n",
    "1000/1000 [==============================] - 120s 120ms/step - loss: 2.0388 - val_loss: 1.8788\n",
    "Epoch 19/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0486 - val_loss: 1.8394\n",
    "Epoch 20/30\n",
    "1000/1000 [==============================] - 120s 120ms/step - loss: 2.0551 - val_loss: 1.8790\n",
    "Epoch 21/30\n",
    "1000/1000 [==============================] - 120s 120ms/step - loss: 2.0580 - val_loss: 1.8425\n",
    "Epoch 22/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0423 - val_loss: 1.6663\n",
    "Epoch 23/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0528 - val_loss: 1.8478\n",
    "Epoch 24/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0481 - val_loss: 1.9197\n",
    "Epoch 25/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0478 - val_loss: 1.8522\n",
    "Epoch 26/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0310 - val_loss: 1.7600\n",
    "Epoch 27/30\n",
    "1000/1000 [==============================] - 119s 119ms/step - loss: 2.0462 - val_loss: 1.7277\n",
    "Epoch 28/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0414 - val_loss: 1.7540\n",
    "Epoch 29/30\n",
    "1000/1000 [==============================] - 118s 118ms/step - loss: 2.0317 - val_loss: 1.8865\n",
    "Epoch 30/30\n",
    "1000/1000 [==============================] - 117s 117ms/step - loss: 2.0364 - val_loss: 1.7143\n",
    "CPU times: user 1h 8min 33s, sys: 1min 22s, total: 1h 9min 55s\n",
    "Wall time: 59min 4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simply mean and std and sqrt mean and std\n",
    "Epoch 1/30\n",
    "1000/1000 [==============================] - 173s 173ms/step - loss: 2.5647 - val_loss: 1.8682\n",
    "Epoch 2/30\n",
    "1000/1000 [==============================] - 171s 171ms/step - loss: 2.1408 - val_loss: 1.8078\n",
    "Epoch 3/30\n",
    "1000/1000 [==============================] - 172s 172ms/step - loss: 2.1503 - val_loss: 1.9401\n",
    "Epoch 4/30\n",
    "1000/1000 [==============================] - 175s 175ms/step - loss: 2.1204 - val_loss: 2.0239\n",
    "Epoch 5/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.1167 - val_loss: 1.8428\n",
    "Epoch 6/30\n",
    "1000/1000 [==============================] - 176s 176ms/step - loss: 2.1198 - val_loss: 1.9124\n",
    "Epoch 7/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.1093 - val_loss: 1.8500\n",
    "Epoch 8/30\n",
    "1000/1000 [==============================] - 170s 170ms/step - loss: 2.0925 - val_loss: 1.8990\n",
    "Epoch 9/30\n",
    "1000/1000 [==============================] - 171s 171ms/step - loss: 2.0940 - val_loss: 1.9609\n",
    "Epoch 10/30\n",
    "1000/1000 [==============================] - 172s 172ms/step - loss: 2.0713 - val_loss: 1.8797\n",
    "Epoch 11/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.0823 - val_loss: 1.8836\n",
    "Epoch 12/30\n",
    "1000/1000 [==============================] - 177s 177ms/step - loss: 2.0565 - val_loss: 1.8751\n",
    "Epoch 13/30\n",
    "1000/1000 [==============================] - 177s 177ms/step - loss: 2.0569 - val_loss: 1.7065\n",
    "Epoch 14/30\n",
    "1000/1000 [==============================] - 176s 176ms/step - loss: 2.0620 - val_loss: 1.8654\n",
    "Epoch 15/30\n",
    "1000/1000 [==============================] - 173s 173ms/step - loss: 2.0601 - val_loss: 1.8119\n",
    "Epoch 16/30\n",
    "1000/1000 [==============================] - 171s 171ms/step - loss: 2.0681 - val_loss: 1.7609\n",
    "Epoch 17/30\n",
    "1000/1000 [==============================] - 171s 171ms/step - loss: 2.0520 - val_loss: 1.8465\n",
    "Epoch 18/30\n",
    "1000/1000 [==============================] - 177s 177ms/step - loss: 2.0620 - val_loss: 1.8474\n",
    "Epoch 19/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.0488 - val_loss: 1.7527\n",
    "Epoch 20/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.0633 - val_loss: 1.7802\n",
    "Epoch 21/30\n",
    "1000/1000 [==============================] - 170s 170ms/step - loss: 2.0398 - val_loss: 1.7175\n",
    "Epoch 22/30\n",
    "1000/1000 [==============================] - 170s 170ms/step - loss: 2.0485 - val_loss: 1.8967\n",
    "Epoch 23/30\n",
    "1000/1000 [==============================] - 172s 172ms/step - loss: 2.0430 - val_loss: 1.7251\n",
    "Epoch 24/30\n",
    "1000/1000 [==============================] - 176s 176ms/step - loss: 2.0632 - val_loss: 1.8947\n",
    "Epoch 25/30\n",
    "1000/1000 [==============================] - 177s 177ms/step - loss: 2.0498 - val_loss: 1.7527\n",
    "Epoch 26/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.0446 - val_loss: 1.8972\n",
    "Epoch 27/30\n",
    "1000/1000 [==============================] - 174s 174ms/step - loss: 2.0503 - val_loss: 1.8240\n",
    "Epoch 28/30\n",
    "1000/1000 [==============================] - 172s 172ms/step - loss: 2.0489 - val_loss: 1.8254\n",
    "Epoch 29/30\n",
    "1000/1000 [==============================] - 172s 172ms/step - loss: 2.0521 - val_loss: 1.7947\n",
    "Epoch 30/30\n",
    "1000/1000 [==============================] - 178s 178ms/step - loss: 2.0490 - val_loss: 1.7992\n",
    "CPU times: user 1h 37min 7s, sys: 1min 31s, total: 1h 38min 39s\n",
    "Wall time: 1h 27min 9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simply mean and std and sqrt mean and cos mean\n",
    "Epoch 1/30\n",
    "1000/1000 [==============================] - 283s 283ms/step - loss: 2.5121 - val_loss: 1.8882\n",
    "Epoch 2/30\n",
    "1000/1000 [==============================] - 281s 281ms/step - loss: 2.1313 - val_loss: 1.9912\n",
    "Epoch 3/30\n",
    "1000/1000 [==============================] - 279s 279ms/step - loss: 2.1246 - val_loss: 1.8005\n",
    "Epoch 4/30\n",
    "1000/1000 [==============================] - 280s 280ms/step - loss: 2.1195 - val_loss: 1.8982\n",
    "Epoch 5/30\n",
    "1000/1000 [==============================] - 285s 285ms/step - loss: 2.1015 - val_loss: 1.8996\n",
    "Epoch 6/30\n",
    "1000/1000 [==============================] - 286s 286ms/step - loss: 2.1031 - val_loss: 1.8608\n",
    "Epoch 7/30\n",
    "1000/1000 [==============================] - 284s 284ms/step - loss: 2.0997 - val_loss: 1.9422\n",
    "Epoch 8/30\n",
    "1000/1000 [==============================] - 286s 286ms/step - loss: 2.0909 - val_loss: 1.8809\n",
    "Epoch 9/30\n",
    "1000/1000 [==============================] - 281s 281ms/step - loss: 2.0680 - val_loss: 1.8748\n",
    "Epoch 10/30\n",
    "1000/1000 [==============================] - 284s 284ms/step - loss: 2.0566 - val_loss: 1.7881\n",
    "Epoch 11/30\n",
    "1000/1000 [==============================] - 286s 286ms/step - loss: 2.0631 - val_loss: 1.9524\n",
    "Epoch 12/30\n",
    "1000/1000 [==============================] - 284s 284ms/step - loss: 2.0583 - val_loss: 1.8290\n",
    "Epoch 13/30\n",
    "1000/1000 [==============================] - 281s 281ms/step - loss: 2.0479 - val_loss: 1.8154\n",
    "Epoch 14/30\n",
    "1000/1000 [==============================] - 287s 287ms/step - loss: 2.0576 - val_loss: 1.8428\n",
    "Epoch 15/30\n",
    "1000/1000 [==============================] - 285s 285ms/step - loss: 2.0586 - val_loss: 1.8704\n",
    "Epoch 16/30\n",
    "1000/1000 [==============================] - 285s 285ms/step - loss: 2.0528 - val_loss: 1.7577\n",
    "Epoch 17/30\n",
    "1000/1000 [==============================] - 285s 285ms/step - loss: 2.0497 - val_loss: 1.8504\n",
    "Epoch 18/30\n",
    "1000/1000 [==============================] - 286s 286ms/step - loss: 2.0391 - val_loss: 1.8619\n",
    "Epoch 19/30\n",
    "1000/1000 [==============================] - 286s 286ms/step - loss: 2.0455 - val_loss: 1.7897\n",
    "Epoch 20/30\n",
    "1000/1000 [==============================] - 286s 286ms/step - loss: 2.0521 - val_loss: 1.7970\n",
    "Epoch 21/30\n",
    "1000/1000 [==============================] - 286s 286ms/step - loss: 2.0428 - val_loss: 1.8860\n",
    "Epoch 22/30\n",
    "1000/1000 [==============================] - 285s 285ms/step - loss: 2.0361 - val_loss: 1.8588\n",
    "Epoch 23/30\n",
    "1000/1000 [==============================] - 285s 285ms/step - loss: 2.0368 - val_loss: 1.9822\n",
    "Epoch 24/30\n",
    "1000/1000 [==============================] - 285s 285ms/step - loss: 2.0255 - val_loss: 1.7730\n",
    "Epoch 25/30\n",
    "1000/1000 [==============================] - 285s 285ms/step - loss: 2.0380 - val_loss: 1.8300\n",
    "Epoch 26/30\n",
    "1000/1000 [==============================] - 284s 284ms/step - loss: 2.0356 - val_loss: 1.7532\n",
    "Epoch 27/30\n",
    "1000/1000 [==============================] - 286s 286ms/step - loss: 2.0226 - val_loss: 1.9497\n",
    "Epoch 28/30\n",
    "1000/1000 [==============================] - 281s 281ms/step - loss: 2.0308 - val_loss: 1.9182\n",
    "Epoch 29/30\n",
    "1000/1000 [==============================] - 280s 280ms/step - loss: 2.0458 - val_loss: 1.8109\n",
    "Epoch 30/30\n",
    "1000/1000 [==============================] - 277s 277ms/step - loss: 2.0233 - val_loss: 1.8135\n",
    "CPU times: user 2h 33min 8s, sys: 1min 29s, total: 2h 34min 38s\n",
    "Wall time: 2h 21min 53s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
