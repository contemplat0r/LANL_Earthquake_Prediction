{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(\n",
    "        df,\n",
    "        first_index=None,\n",
    "        last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    \n",
    "    print(\"df.shape:\", df.shape)\n",
    "    print(\"df.index[:3]\", df.index[:3])\n",
    "    print(\"df.index[-3:]\", df.index[-3:])\n",
    "    if first_index == None or last_index == None:\n",
    "        first_index = df.index.min()\n",
    "        last_index = df.index.max()\n",
    "    print(\"first_index: {}, last_index: {}\".format(first_index, last_index))\n",
    "    #sample_indexes = np.random.randint(first_index, last_index, sample_size)\n",
    "    sample_indexes = random.sample(range(first_index, last_index + 1), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    print(\"sample_indexes[:3]\", sample_indexes[:3])\n",
    "    print(\"sample_indexes[-3:]\", sample_indexes[-3:])\n",
    "    print(\"len(sample_indexes):\", len(sample_indexes))\n",
    "    #print(\"sample_indexes.shape:\", sample_indexes.shape)    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    #half_windows_size = [ws // 2 for ws in smootch_windows_size]\n",
    "\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    \n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True) # There is need map sample_df.index -> sample_indexes\n",
    "                                                    # Должно быть установелнно соотвествие индексов в sample_df\n",
    "                                                    # (Где после .reset_index индексы - это\n",
    "                                                    # все целые числа от 0 до sample_df.shape[0]) и sample_indexes -\n",
    "                                                    # соответствующие индексы в df которые являються случайной\n",
    "                                                    # выборкой из чисел о first_index до last_index и длинной \n",
    "                                                    # равной sample_df.index.shape[0] которая длинна равно sample_size \n",
    "                                                    # Соответсвенно, по видимому, in_window_begin_indexes и\n",
    "                                                    # in_window_end_indexes надо вычислять как то по другому\n",
    "    #print(\"just after create sample_df, sample_df.shape[0]:\", sample_df.shape[0])\n",
    "    \n",
    "    #for feature_name in smootch_feature_names:\n",
    "    #    sample_df[feature_name] = 0\n",
    "    #begin_smootch_features_value = []\n",
    "    #end_smootch_features_value = []\n",
    "    \n",
    "    #sample_indexes_set = set(sample_indexes)\n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #print(\"sample_df.shape[0] just before main loop:\", sample_df.shape[0])\n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "        \n",
    "        print(\"\\n\" * 2)\n",
    "        print(\"window_size:\", window_size)\n",
    "        print()\n",
    "        feature_values_list = list(range(sample_size))\n",
    "        print(\"sample_df.index.tolist()[:window_size]:\\n\", sample_df.index.tolist()[:window_size])\n",
    "        print(\"df.index.tolist()[:window_size]:\\n\", df.index.tolist()[:window_size])\n",
    "\n",
    "        print(\"sample_df.index.tolist()[-window_size:]:\\n\", sample_df.index.tolist()[-window_size:])\n",
    "        print(\"df.index.tolist()[-window_size:]:\\n\", df.index.tolist()[-window_size:])\n",
    "        \n",
    "        half_window_size = window_size // 2\n",
    "        ##>begin_indexes = sample_indexes[:half_window_size]  \n",
    "        ##>print(\"begin_indexes:\\n\", begin_indexes)\n",
    "        sample_begin_indexes = sample_indexes[:half_window_size] #? sample_df.index[:half_window_size]\n",
    "        print(\"sample_begin_indexes:\\n\", sample_begin_indexes)\n",
    "        #full_data_begin_indexes = df.index[:half_window_size].tolist() #df.index[sample_indexes[i]]\n",
    "        full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "        print(\"full_data_begin_indexes:\\n\", full_data_begin_indexes)\n",
    "        \n",
    "        #in_window_begin_indexes = [idx for idx in sample_begin_indexes if idx in full_data_begin_indexes]\n",
    "        min_begin_index = min(full_data_begin_indexes)\n",
    "        print(\"set(range(min_begin_index, min_begin_index + half_window_size))\", set(range(min_begin_index, min_begin_index + half_window_size)))\n",
    "        in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "            set(range(min_begin_index, min_begin_index + half_window_size))\n",
    "        )\n",
    "        print(\"in_window_begin_indexes:\\n\", in_window_begin_indexes)\n",
    "        \n",
    "        sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "        print(\"sample_end_indexes:\\n\", sample_end_indexes)\n",
    "\n",
    "        #full_data_end_indexes = df.index[-half_window_size:].tolist()\n",
    "        full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "        print(\"full_data_end_indexes:\", full_data_end_indexes)\n",
    "        \n",
    "        #in_window_end_indexes = [idx for idx in sample_end_indexes if idx in full_data_end_indexes]\n",
    "        max_end_index = max(full_data_end_indexes)\n",
    "        print(\"max_end_index:\", max_end_index)\n",
    "        print(\"max_end_index - half_window_size:\", max_end_index - half_window_size)\n",
    "        print(\"set(range(max_end_index - half_window_size, max_end_index + 1)):\\n\", set(range(max_end_index + 1 - half_window_size, max_end_index + 1)))\n",
    "        in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "            set(range(max_end_index + 1 - half_window_size, max_end_index + 1))\n",
    "        )\n",
    "        print(\"in_window_end_indexes:\\n\", in_window_end_indexes)\n",
    "        \n",
    "        ##>begin_indexes = begin_indexes[begin_indexes <= half_window_size]\n",
    "        ##>print(\"2 begin_indexes? :\\n\", begin_indexes)\n",
    "        \n",
    "        ##>end_indexes = sample_indexes[-half_window_size:]\n",
    "        ##>print(\"2 end_indexes? :\\n\", end_indexes)\n",
    "        print(\"in_window_begin_indexes:\\n\", in_window_begin_indexes)\n",
    "        print(\"len(in_window_begin_indexes)\", len(in_window_begin_indexes))\n",
    "        print()\n",
    "        if in_window_begin_indexes:\n",
    "            begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "            for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                print(\"i: {}, b_idx {}:\".format(i, b_idx))\n",
    "                print(\"type(b_idx):\", type(b_idx))\n",
    "                print(\"df[:window_size]:\\n\", df[:window_size])\n",
    "                #sample_df[feature_name].iloc[b_idx] = df[b_idx]['acoustic_data'] - df.iloc[first_index:first_index + window_size]['acoustic_data'].mean()\n",
    "                value = df.iloc[b_idx]['acoustic_data']\n",
    "                print(\"begin 1 value:\", value)\n",
    "                print(\"df.iloc[first_index:first_index + window_size]['acoustic_data']:\", df.iloc[first_index:first_index + window_size]['acoustic_data'])\n",
    "                temp = df.iloc[first_index:first_index + window_size]['acoustic_data'].mean()\n",
    "                print(\"begin temp:\", temp)\n",
    "                value = value - temp\n",
    "                print(\"begin 2 value:\", value)\n",
    "                feature_values_list[i] = value\n",
    "        print(\"in_window_end_indexes:\\n\", in_window_end_indexes)\n",
    "        print(\"len(in_window_end_indexes)\", len(in_window_end_indexes))\n",
    "        print()\n",
    "        if in_window_end_indexes:\n",
    "            end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "            for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                print(\"i: {}, e_idx {}:\".format(i, e_idx))\n",
    "                print(\"type(e_idx):\", type(e_idx))\n",
    "                print(\"df[-window_size:]:\\n\", df[-window_size:])\n",
    "                #sample_df[feature_name].iloc[e_idx] = df[e_idx]['acoustic_data'] - df.iloc[last_index - window_size:]['acoustic_data'].mean()\n",
    "                value = df.iloc[e_idx]['acoustic_data']\n",
    "                print(\"end 1 value:\", value)\n",
    "                print(\"df.iloc[last_index + 1 - window_size:]['acoustic_data']:\\n\", df.iloc[last_index + 1 - window_size:]['acoustic_data'])\n",
    "                temp = df.iloc[last_index + 1 - window_size:]['acoustic_data'].mean()\n",
    "                print(\"end temp:\", temp)\n",
    "                value = value - temp\n",
    "                print(\"end 2 value:\", value)\n",
    "                feature_values_list[last_index - i] = value\n",
    "        #print(\"in main loop, sample_df.shape:\", sample_df.shape)\n",
    "        print(\"sample_df_len:\", sample_df_len)\n",
    "        print(\"begin_indexes_set:\\n\", begin_indexes_set)\n",
    "        print(\"len(begin_indexes_set):\", len(begin_indexes_set))\n",
    "        print(\"begin_indexes_set:\\n\", end_indexes_set)\n",
    "        print(\"len(begin_indexes_set):\", len(end_indexes_set))\n",
    "        first_regular_idx = len(begin_indexes_set)\n",
    "        last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "        print(\"first_regular_idx:\", first_regular_idx)\n",
    "        print(\"last_regular_idx:\", last_regular_idx)\n",
    "        #for i in range(sample_df_len)[slice_begin:slice_end]:\n",
    "        for i in range(first_regular_idx, last_regular_idx):\n",
    "            sample_idx = sample_indexes[i]\n",
    "            feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                sample_idx - half_window_size:sample_idx + half_window_size\n",
    "            ].mean()\n",
    "        #print(\"sample_df.shape[0] before assign feature_values_list:\", sample_df.shape[0])\n",
    "        #print(\"len(feature_values_list):\", len(feature_values_list))\n",
    "        sample_df[feature_name] = feature_values_list\n",
    "        \n",
    "    #sample_df_indexes_set = set(sample_df.index)\n",
    "    #train_indexes = sample_df_indexes_set\n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        #print(\"sample_df.index:\\n\", sample_df.index.tolist())\n",
    "        #print(\"holdout_indexes:\\n\", holdout_indexes)\n",
    "        #train_indexes = np.array(sample_df.index)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "    \n",
    "        #train_indexes = sorted(tuple(sample_df_indexes_set.difference(set(holdout_indexes))))\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        #print(\"train_indexes:\\n\", train_indexes)\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(\n",
    "        df,\n",
    "        first_index=None,\n",
    "        last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    \n",
    "    print(\"df.shape:\", df.shape)\n",
    "    print(\"df.index[:3]\", df.index[:3])\n",
    "    print(\"df.index[-3:]\", df.index[-3:])\n",
    "    if first_index == None or last_index == None:\n",
    "        first_index = df.index.min()\n",
    "        last_index = df.index.max()\n",
    "    print(\"first_index: {}, last_index: {}\".format(first_index, last_index))\n",
    "    #sample_indexes = np.random.randint(first_index, last_index, sample_size)\n",
    "    sample_indexes = random.sample(range(first_index, last_index + 1), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    print(\"sample_indexes[:3]\", sample_indexes[:3])\n",
    "    print(\"sample_indexes[-3:]\", sample_indexes[-3:])\n",
    "    print(\"len(sample_indexes):\", len(sample_indexes))\n",
    "    #print(\"sample_indexes.shape:\", sample_indexes.shape)    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    #half_windows_size = [ws // 2 for ws in smootch_windows_size]\n",
    "\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    \n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True) # There is need map sample_df.index -> sample_indexes\n",
    "                                                    # Должно быть установелнно соотвествие индексов в sample_df\n",
    "                                                    # (Где после .reset_index индексы - это\n",
    "                                                    # все целые числа от 0 до sample_df.shape[0]) и sample_indexes -\n",
    "                                                    # соответствующие индексы в df которые являються случайной\n",
    "                                                    # выборкой из чисел о first_index до last_index и длинной \n",
    "                                                    # равной sample_df.index.shape[0] которая длинна равно sample_size \n",
    "                                                    # Соответсвенно, по видимому, in_window_begin_indexes и\n",
    "                                                    # in_window_end_indexes надо вычислять как то по другому\n",
    "    #print(\"just after create sample_df, sample_df.shape[0]:\", sample_df.shape[0])\n",
    "    \n",
    "    #for feature_name in smootch_feature_names:\n",
    "    #    sample_df[feature_name] = 0\n",
    "    #begin_smootch_features_value = []\n",
    "    #end_smootch_features_value = []\n",
    "    \n",
    "    #sample_indexes_set = set(sample_indexes)\n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #print(\"sample_df.shape[0] just before main loop:\", sample_df.shape[0])\n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "        \n",
    "        print(\"\\n\" * 2)\n",
    "        print(\"window_size:\", window_size)\n",
    "        print()\n",
    "        feature_values_list = list(range(sample_size))\n",
    "\n",
    "        half_window_size = window_size // 2\n",
    "\n",
    "        sample_begin_indexes = sample_indexes[:half_window_size] #? sample_df.index[:half_window_size]\n",
    "\n",
    "        full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "\n",
    "        min_begin_index = min(full_data_begin_indexes)\n",
    "        \n",
    "        in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "            set(range(min_begin_index, min_begin_index + half_window_size))\n",
    "        )\n",
    "        print(\"in_window_begin_indexes:\\n\", in_window_begin_indexes)\n",
    "        \n",
    "        sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "\n",
    "        full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "        \n",
    "        max_end_index = max(full_data_end_indexes)\n",
    "        print(\"max_end_index:\", max_end_index)\n",
    "        print(\"max_end_index - half_window_size:\", max_end_index - half_window_size)\n",
    "\n",
    "        in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "            set(range(max_end_index + 1 - half_window_size, max_end_index + 1))\n",
    "        )\n",
    "        print(\"in_window_begin_indexes:\\n\", in_window_begin_indexes)\n",
    "        print(\"len(in_window_begin_indexes)\", len(in_window_begin_indexes))\n",
    "        print(\"in_window_end_indexes:\\n\", in_window_end_indexes)\n",
    "        print(\"len(in_window_end_indexes):\", len(in_window_end_indexes))\n",
    "\n",
    "        print()\n",
    "        if in_window_begin_indexes:\n",
    "            begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "            for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                print(\"i: {}, b_idx {}:\".format(i, b_idx))\n",
    "                print(\"type(b_idx):\", type(b_idx))\n",
    "                print(\"df[:window_size]:\\n\", df[:window_size])\n",
    "                #sample_df[feature_name].iloc[b_idx] = df[b_idx]['acoustic_data'] - df.iloc[first_index:first_index + window_size]['acoustic_data'].mean()\n",
    "                value = df.iloc[b_idx]['acoustic_data']\n",
    "                print(\"begin 1 value:\", value)\n",
    "                print(\"df.iloc[first_index:first_index + window_size]['acoustic_data']:\\n\", df.iloc[first_index:first_index + window_size]['acoustic_data'])\n",
    "                temp = df.iloc[first_index:first_index + window_size]['acoustic_data'].mean()\n",
    "                print(\"begin temp:\", temp)\n",
    "                value = value - temp\n",
    "                print(\"begin 2 value:\", value)\n",
    "                feature_values_list[i] = value\n",
    "        if in_window_end_indexes:\n",
    "            end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "            for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                print(\"i: {}, e_idx {}:\".format(i, e_idx))\n",
    "                print(\"type(e_idx):\", type(e_idx))\n",
    "                print(\"df[-window_size:]:\\n\", df[-window_size:])\n",
    "                #sample_df[feature_name].iloc[e_idx] = df[e_idx]['acoustic_data'] - df.iloc[last_index - window_size:]['acoustic_data'].mean()\n",
    "                value = df.iloc[e_idx]['acoustic_data']\n",
    "                print(\"end 1 value:\", value)\n",
    "                print(\"df.iloc[last_index + 1 - window_size:]['acoustic_data']:\\n\", df.iloc[last_index + 1 - window_size:]['acoustic_data'])\n",
    "                temp = df.iloc[last_index + 1 - window_size:]['acoustic_data'].mean()\n",
    "                print(\"end temp:\", temp)\n",
    "                value = value - temp\n",
    "                print(\"end 2 value:\", value)\n",
    "                feature_values_list[last_index - i] = value\n",
    "        #print(\"in main loop, sample_df.shape:\", sample_df.shape)\n",
    "        print(\"sample_df_len:\", sample_df_len)\n",
    "        print(\"begin_indexes_set:\\n\", begin_indexes_set)\n",
    "        print(\"len(begin_indexes_set):\", len(begin_indexes_set))\n",
    "        print(\"begin_indexes_set:\\n\", end_indexes_set)\n",
    "        print(\"len(begin_indexes_set):\", len(end_indexes_set))\n",
    "        first_regular_idx = len(begin_indexes_set)\n",
    "        last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "        print(\"first_regular_idx:\", first_regular_idx)\n",
    "        print(\"last_regular_idx:\", last_regular_idx)\n",
    "        #for i in range(sample_df_len)[slice_begin:slice_end]:\n",
    "        for i in range(first_regular_idx, last_regular_idx):\n",
    "            sample_idx = sample_indexes[i]\n",
    "            feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                sample_idx - half_window_size:sample_idx + half_window_size\n",
    "            ].mean()\n",
    "        #print(\"sample_df.shape[0] before assign feature_values_list:\", sample_df.shape[0])\n",
    "        #print(\"len(feature_values_list):\", len(feature_values_list))\n",
    "        sample_df[feature_name] = feature_values_list\n",
    "        \n",
    "    #sample_df_indexes_set = set(sample_df.index)\n",
    "    #train_indexes = sample_df_indexes_set\n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        #print(\"sample_df.index:\\n\", sample_df.index.tolist())\n",
    "        #print(\"holdout_indexes:\\n\", holdout_indexes)\n",
    "        #train_indexes = np.array(sample_df.index)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "    \n",
    "        #train_indexes = sorted(tuple(sample_df_indexes_set.difference(set(holdout_indexes))))\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        #print(\"train_indexes:\\n\", train_indexes)\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    #sample_indexes = random.sample(range(input_first_index, input_last_index + 1), sample_size)\n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    print(\"sample_indexes[:8]:\\n\", sample_indexes[:8])\n",
    "    print(\"sample_indexes[-8:]:\\n\", sample_indexes[-8:])\n",
    "    #sample_first_index = min(sample_indexes)\n",
    "    #sample_last_index = max(sample_indexes)\n",
    "    #print(\"sample_first_index:\", sample_first_index)\n",
    "    #print(\"sample_last_index:\", sample_last_index)\n",
    "    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    full_data_indexes = tuple(acoustic_data_series.index.tolist())\n",
    "    '''\n",
    "    print(\"acoustic_data_series.index[:3]:\\n\", acoustic_data_series.index[:3].tolist())\n",
    "    print(\"acoustic_data_series.index[-3:]:\\n\", acoustic_data_series.index[-3:].tolist())\n",
    "    '''\n",
    "    \n",
    "    print(\"acoustic_data_series[:8]:\\n\", acoustic_data_series[:8])\n",
    "    print(\"acoustic_data_series[-8:]:\\n\", acoustic_data_series[-8:])\n",
    "    \n",
    "    '''\n",
    "    print(\"df[:3]['acousitc_data']:\\n\", df[:3]['acoustic_data'])\n",
    "    print(\"df[-3:]['acoustic_data']:\\n\", df[-3:]['acoustic_data'])\n",
    "    '''\n",
    "    \n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "    '''\n",
    "    print(\"before reset sample_df.index[:3]\", sample_df.index[:3])\n",
    "    print(\"before reset sample_df.index[-3:]\", sample_df.index[-3:])\n",
    "    print(\"before reset sample_df[:3]\", sample_df[:3])\n",
    "    print(\"before reset sample_df[-3:]\", sample_df[-3:])\n",
    "    '''\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "    '''\n",
    "    print(\"after reset sample_df.index[:3]\", sample_df.index[:3])\n",
    "    print(\"after reset sample_df.index[-3:]\", sample_df.index[-3:])\n",
    "    print(\"after reset sample_df[:3]\", sample_df[:3])\n",
    "    print(\"after reset sample_df[-3:]\", sample_df[-3:])\n",
    "    '''\n",
    "    output_first_index = 0\n",
    "    output_last_index = len(sample_df) - 1\n",
    "    \n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "   \n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "        print(\"\\n\\nwindow_size: {} feature_name: {}\".format(window_size, feature_name))\n",
    "\n",
    "        feature_values_list = list(range(sample_size))\n",
    "\n",
    "        half_window_size = window_size // 2\n",
    "\n",
    "        sample_begin_indexes = sample_indexes[:half_window_size] #? sample_df.index[:half_window_size]\n",
    "        full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "        min_full_data_index = min(full_data_indexes)\n",
    "        #in_window_full_data_begin_indexes = set(range(min_full_data_index, min_full_data_index + half_window_size))\n",
    "        in_window_full_data_begin_indexes = set(range(input_first_index, input_first_index + half_window_size))\n",
    "        print(\"+++ in_window_full_data_begin_indexes:\\n\", in_window_full_data_begin_indexes)\n",
    "              \n",
    "        in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "            #set(range(min_begin_index, min_begin_index + half_window_size))\n",
    "            #set(range(min_full_data_index, min_full_data_index + half_window_size))\n",
    "            in_window_full_data_begin_indexes\n",
    "        )\n",
    "        print(\"---in_window_begin_indexes:\\n\", in_window_begin_indexes)\n",
    "        \n",
    "        sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "        full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "        max_full_data_index = max(full_data_end_indexes) + 1\n",
    "        \n",
    "        print(\"** max_full_data_index:\", max_full_data_index)\n",
    "        print(\"** input_last_index:\", input_last_index)\n",
    "        #in_window_full_data_end_indexes = set(range(max_full_data_index - half_window_size, max_full_data_index))\n",
    "        #in_window_full_data_end_indexes = set(range(input_last_index + 1 - half_window_size, input_last_index + 1))\n",
    "        in_window_full_data_end_indexes = set(range(input_last_index - half_window_size, input_last_index))\n",
    "        print(\"+++ in_window_full_data_end_indexes:\\n\", in_window_full_data_end_indexes)\n",
    "        \n",
    "        in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "            #set(range(max_end_index + 1 - half_window_size, max_end_index + 1))\n",
    "            #set(range(max_full_data_index + 1 - half_window_size, max_full_data_index))\n",
    "            in_window_full_data_end_indexes\n",
    "        )\n",
    "        print(\"---in_window_end_indexes:\\n\", in_window_end_indexes)\n",
    "        if in_window_begin_indexes:\n",
    "            print(\"\\nin_window_begin_indexes\")\n",
    "            print(\"sorted(tuple(in_window_begin_indexes)):\\n\", sorted(tuple(in_window_begin_indexes)))\n",
    "            begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "            for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                print(\"\\ni:\", i)\n",
    "                #value = df.iloc[b_idx]['acoustic_data']\n",
    "                print(\"sample_df value:\", sample_df.iloc[i]['acoustic_data'])\n",
    "                #value = acoustic_data_series.iloc[b_idx]\n",
    "                value = sample_df.iloc[i]['acoustic_data']\n",
    "                print(\"1 value:\", value)\n",
    "                #temp = df.iloc[input_first_index:input_first_index + window_size]['acoustic_data'].mean()\n",
    "                print(\"acoustic_data_series.iloc[input_first_index:input_first_index + window_size]:\\n\",\n",
    "                      acoustic_data_series.iloc[input_first_index:input_first_index + window_size]\n",
    "                )\n",
    "                temp = acoustic_data_series.iloc[input_first_index:input_first_index + window_size].mean()\n",
    "                print(\"temp:\", temp)\n",
    "                value = value - temp\n",
    "                print(\"2 value:\", value)\n",
    "                print(\"output_first_index + i:\", output_first_index + i)\n",
    "                feature_values_list[output_first_index + i] = value\n",
    "                \n",
    "        if in_window_end_indexes:\n",
    "            print(\"\\nin_window_end_indexes\")\n",
    "            print(\"sorted(tuple(in_window_end_indexes)):\\n\", sorted(tuple(in_window_end_indexes)))\n",
    "            end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "            for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                print(\"\\ni:\", i)\n",
    "                #value = df.iloc[e_idx]['acoustic_data']\n",
    "                print(\"sample_df value:\", sample_df.iloc[output_last_index - i]['acoustic_data'])\n",
    "                #value = acoustic_data_series.iloc[e_idx - max_full_data_index]\n",
    "                value = acoustic_data_series.iloc[e_idx - input_last_index]\n",
    "                #value = sample_df.iloc[output_last_index - i]['acoustic_data']\n",
    "                print(\"1 value:\", value)\n",
    "                #temp = df.iloc[input_last_index + 1 - window_size:]['acoustic_data'].mean()\n",
    "                print(\"acoustic_data_series.iloc[input_last_index - window_size:]:\\n\",\n",
    "                      #acoustic_data_series.iloc[input_last_index + 1 - window_size:]\n",
    "                      acoustic_data_series.iloc[input_last_index - window_size:]\n",
    "                )\n",
    "                #temp = acoustic_data_series.iloc[input_last_index + 1 - window_size:].mean()\n",
    "                temp = acoustic_data_series.iloc[input_last_index - window_size:].mean()\n",
    "                print(\"temp:\", temp)\n",
    "                value = value - temp\n",
    "                print(\"2 value:\", value)\n",
    "                print(\"output_last_index - i:\", output_last_index - i)\n",
    "                feature_values_list[output_last_index - i] = value\n",
    "                \n",
    "        first_regular_idx = len(begin_indexes_set)\n",
    "        last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "        for i in range(first_regular_idx, last_regular_idx):\n",
    "            sample_idx = sample_indexes[i]\n",
    "            feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                sample_idx - half_window_size:sample_idx + half_window_size\n",
    "            ].mean()\n",
    "        sample_df[feature_name] = feature_values_list\n",
    "        \n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    \n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    full_data_indexes = tuple(acoustic_data_series.index.tolist())\n",
    "\n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "    output_first_index = 0\n",
    "    output_last_index = len(sample_df) - 1\n",
    "    \n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "   \n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "\n",
    "        feature_values_list = list(range(sample_size))\n",
    "\n",
    "        half_window_size = window_size // 2\n",
    "\n",
    "        sample_begin_indexes = sample_indexes[:half_window_size]\n",
    "        full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "        min_full_data_index = min(full_data_indexes)\n",
    "        \n",
    "        in_window_full_data_begin_indexes = set(range(input_first_index, input_first_index + half_window_size))              \n",
    "        in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "            in_window_full_data_begin_indexes\n",
    "        )\n",
    "        \n",
    "        sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "        full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "        max_full_data_index = max(full_data_end_indexes) + 1\n",
    "        \n",
    "        in_window_full_data_end_indexes = set(range(input_last_index - half_window_size, input_last_index))        \n",
    "        in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "            in_window_full_data_end_indexes\n",
    "        )\n",
    "        if in_window_begin_indexes:\n",
    "            begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "            for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                value = sample_df.iloc[i]['acoustic_data']\n",
    "                temp = acoustic_data_series.iloc[input_first_index:input_first_index + window_size].mean()\n",
    "                value = value - temp\n",
    "                feature_values_list[output_first_index + i] = value\n",
    "                \n",
    "        if in_window_end_indexes:\n",
    "            end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "            for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                value = sample_df.iloc[output_last_index - i]['acoustic_data']\n",
    "                temp = acoustic_data_series.iloc[input_last_index - window_size:].mean()\n",
    "                value = value - temp\n",
    "                feature_values_list[output_last_index - i] = value\n",
    "                \n",
    "        first_regular_idx = len(begin_indexes_set)\n",
    "        last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "        for i in range(first_regular_idx, last_regular_idx):\n",
    "            sample_idx = sample_indexes[i]\n",
    "            feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                sample_idx - half_window_size:sample_idx + half_window_size\n",
    "            ].mean()\n",
    "        sample_df[feature_name] = feature_values_list\n",
    "        \n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_seen_data_df = pd.read_csv(\n",
    "    '../input/train/train.csv',\n",
    "    #nrows=100000000,\n",
    "    names=['acoustic_data', 'time_to_failure'],\n",
    "    dtype={'acoustic_data': np.float32, 'time_to_failure': np.float32},\n",
    "    skiprows=1,\n",
    "    nrows=5656572\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full calculation feature value time (with slicing) 0.015858737627665202 min:\n",
      "CPU times: user 1.07 s, sys: 0 ns, total: 1.07 s\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "featured_not_seen_data_df, _ = add_features(\n",
    "    not_seen_data_df[:3000],\n",
    "    sample_size=not_seen_data_df[:1000].shape[0],\n",
    "    holdout_size=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_not_seen_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  8.,  9.,  7., -5.,  3.,  5.], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_not_seen_data_df['acoustic_data'][:7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "      <th>smootch_mean_ws_3</th>\n",
       "      <th>smootch_mean_ws_5</th>\n",
       "      <th>smootch_mean_ws_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4691</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acoustic_data  time_to_failure  smootch_mean_ws_3  smootch_mean_ws_5  \\\n",
       "0           12.0           1.4691           3.333333               4.20   \n",
       "1            8.0           1.4691           7.000000               7.75   \n",
       "2            9.0           1.4691           8.500000               8.00   \n",
       "3           -5.0           1.4691           1.000000               3.50   \n",
       "4            3.0           1.4691          -1.000000               2.50   \n",
       "5            5.0           1.4691           4.000000               1.25   \n",
       "6            2.0           1.4691           3.500000               3.00   \n",
       "7            2.0           1.4691           2.000000               3.00   \n",
       "8            3.0           1.4691           2.500000               1.50   \n",
       "9            2.0           1.4691           3.000000               4.25   \n",
       "\n",
       "   smootch_mean_ws_7  \n",
       "0           4.000000  \n",
       "1           0.000000  \n",
       "2           5.333333  \n",
       "3           4.500000  \n",
       "4           3.500000  \n",
       "5           2.333333  \n",
       "6           1.666667  \n",
       "7           2.333333  \n",
       "8           2.666667  \n",
       "9           4.500000  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_not_seen_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.,  7.,  3.,  3.,  2., -1., -4.], dtype=float32)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_not_seen_data_df['acoustic_data'][-7:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "      <th>smootch_mean_ws_3</th>\n",
       "      <th>smootch_mean_ws_5</th>\n",
       "      <th>smootch_mean_ws_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.469097</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>-1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.469097</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.75</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.469097</td>\n",
       "      <td>24.5</td>\n",
       "      <td>24.50</td>\n",
       "      <td>23.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.469097</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-14.25</td>\n",
       "      <td>-11.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.469097</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.50</td>\n",
       "      <td>21.833334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1.469097</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>25.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-24.0</td>\n",
       "      <td>1.469097</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-18.00</td>\n",
       "      <td>-16.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.469097</td>\n",
       "      <td>-24.5</td>\n",
       "      <td>-21.50</td>\n",
       "      <td>-19.166666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-23.0</td>\n",
       "      <td>1.469097</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-23.00</td>\n",
       "      <td>-20.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.469097</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.60</td>\n",
       "      <td>26.428572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acoustic_data  time_to_failure  smootch_mean_ws_3  smootch_mean_ws_5  \\\n",
       "990            0.0         1.469097               -4.0              -2.75   \n",
       "991           20.0         1.469097               15.0              14.75   \n",
       "992           29.0         1.469097               24.5              24.50   \n",
       "993           -9.0         1.469097              -13.0             -14.25   \n",
       "994           29.0         1.469097               27.0              25.50   \n",
       "995           33.0         1.469097               31.0              29.00   \n",
       "996          -24.0         1.469097              -19.0             -18.00   \n",
       "997          -25.0         1.469097              -24.5             -21.50   \n",
       "998          -23.0         1.469097              -24.0             -23.00   \n",
       "999           17.0         1.469097               11.0              20.60   \n",
       "\n",
       "     smootch_mean_ws_7  \n",
       "990          -1.333333  \n",
       "991          15.000000  \n",
       "992          23.500000  \n",
       "993         -11.833333  \n",
       "994          21.833334  \n",
       "995          25.333334  \n",
       "996         -16.333334  \n",
       "997         -19.166666  \n",
       "998         -20.333334  \n",
       "999          26.428572  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_not_seen_data_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_seen_data_df[:1000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_seen_data_df[:1000].index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94842548, 0.15565242, 0.13225282, 0.44878307, 0.79942495,\n",
       "       0.46168806, 0.16916164, 0.35274032, 0.16233877, 0.06494294,\n",
       "       0.4119373 , 0.8498234 , 0.89188705, 0.86023744, 0.99186619,\n",
       "       0.57907303, 0.92444036, 0.80596842, 0.35860679, 0.09529798])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 8, 0, 5, 4, 2, 7, 6, 9, 1]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(range(10), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = not_seen_data_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.469099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.469099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.469099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.469099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.469099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.469099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.469099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acoustic_data  time_to_failure\n",
       "993            6.0         1.469099\n",
       "994            7.0         1.469099\n",
       "995            8.0         1.469099\n",
       "996            9.0         1.469099\n",
       "997            7.0         1.469099\n",
       "998            8.0         1.469099\n",
       "999            5.0         1.469099"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_idx = temp_df.index.min()\n",
    "last_idx = temp_df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 999\n"
     ]
    }
   ],
   "source": [
    "print(first_idx, last_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "994\n"
     ]
    }
   ],
   "source": [
    "print(first_idx + ws)\n",
    "print(last_idx - ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12.0\n",
       "1     6.0\n",
       "2     8.0\n",
       "3     5.0\n",
       "4     8.0\n",
       "Name: acoustic_data, dtype: float32"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[first_idx:first_idx + ws]['acoustic_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994    7.0\n",
       "995    8.0\n",
       "996    9.0\n",
       "997    7.0\n",
       "998    8.0\n",
       "Name: acoustic_data, dtype: float32"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[last_idx - ws:last_idx]['acoustic_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995    8.0\n",
       "996    9.0\n",
       "997    7.0\n",
       "998    8.0\n",
       "999    5.0\n",
       "Name: acoustic_data, dtype: float32"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[last_idx + 1 - ws:]['acoustic_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training until validation scores don't improve for 4000 rounds.\n",
    "[1000]\ttraining's l1: 2.85332\tvalid_1's l1: 2.85467\n",
    "[2000]\ttraining's l1: 2.84694\tvalid_1's l1: 2.84851\n",
    "[3000]\ttraining's l1: 2.84517\tvalid_1's l1: 2.84683\n",
    "[4000]\ttraining's l1: 2.84444\tvalid_1's l1: 2.84614\n",
    "[5000]\ttraining's l1: 2.84409\tvalid_1's l1: 2.84583\n",
    "[6000]\ttraining's l1: 2.84391\tvalid_1's l1: 2.84568\n",
    "[7000]\ttraining's l1: 2.8438\tvalid_1's l1: 2.84561\n",
    "[8000]\ttraining's l1: 2.84371\tvalid_1's l1: 2.84555\n",
    "[9000]\ttraining's l1: 2.84364\tvalid_1's l1: 2.84551\n",
    "[10000]\ttraining's l1: 2.84357\tvalid_1's l1: 2.84547\n",
    "[11000]\ttraining's l1: 2.84351\tvalid_1's l1: 2.84544\n",
    "[12000]\ttraining's l1: 2.84345\tvalid_1's l1: 2.84541\n",
    "[13000]\ttraining's l1: 2.84339\tvalid_1's l1: 2.84539\n",
    "[14000]\ttraining's l1: 2.84334\tvalid_1's l1: 2.84536\n",
    "[15000]\ttraining's l1: 2.84329\tvalid_1's l1: 2.84534\n",
    "[16000]\ttraining's l1: 2.84323\tvalid_1's l1: 2.84532\n",
    "[17000]\ttraining's l1: 2.84319\tvalid_1's l1: 2.84531\n",
    "[18000]\ttraining's l1: 2.84314\tvalid_1's l1: 2.84529\n",
    "[19000]\ttraining's l1: 2.8431\tvalid_1's l1: 2.84528\n",
    "[20000]\ttraining's l1: 2.84306\tvalid_1's l1: 2.84527\n",
    "[21000]\ttraining's l1: 2.84302\tvalid_1's l1: 2.84526\n",
    "[22000]\ttraining's l1: 2.84298\tvalid_1's l1: 2.84525\n",
    "[23000]\ttraining's l1: 2.84294\tvalid_1's l1: 2.84524\n",
    "[24000]\ttraining's l1: 2.84291\tvalid_1's l1: 2.84524\n",
    "[25000]\ttraining's l1: 2.84287\tvalid_1's l1: 2.84523\n",
    "[26000]\ttraining's l1: 2.84284\tvalid_1's l1: 2.84523\n",
    "[27000]\ttraining's l1: 2.8428\tvalid_1's l1: 2.84523\n",
    "[28000]\ttraining's l1: 2.84277\tvalid_1's l1: 2.84523\n",
    "[29000]\ttraining's l1: 2.84274\tvalid_1's l1: 2.84523\n",
    "[30000]\ttraining's l1: 2.84271\tvalid_1's l1: 2.84522\n",
    "[31000]\ttraining's l1: 2.84267\tvalid_1's l1: 2.84522\n",
    "[32000]\ttraining's l1: 2.84264\tvalid_1's l1: 2.84521\n",
    "[33000]\ttraining's l1: 2.84261\tvalid_1's l1: 2.84521\n",
    "[34000]\ttraining's l1: 2.84258\tvalid_1's l1: 2.84521\n",
    "[35000]\ttraining's l1: 2.84256\tvalid_1's l1: 2.8452\n",
    "[36000]\ttraining's l1: 2.84253\tvalid_1's l1: 2.8452\n",
    "[37000]\ttraining's l1: 2.8425\tvalid_1's l1: 2.8452\n",
    "[38000]\ttraining's l1: 2.84247\tvalid_1's l1: 2.84519\n",
    "[39000]\ttraining's l1: 2.84244\tvalid_1's l1: 2.84519\n",
    "[40000]\ttraining's l1: 2.84241\tvalid_1's l1: 2.84519\n",
    "Did not meet early stopping. Best iteration is:\n",
    "[40000]\ttraining's l1: 2.84241\tvalid_1's l1: 2.84519\n",
    "earthquake 0 mae 2.8432238740079154\n",
    "not seen data mae: 4.975486288323955"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
