{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask\n",
    "import dask.multiprocessing\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNGRU\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/dask/context.py:23: UserWarning: The dask.set_options function has been deprecated. Please use dask.config.set instead\n",
      "  warnings.warn(\"The dask.set_options function has been deprecated. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7f05e1a26a90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(scheduler='processes')\n",
    "dask.set_options( pool=ThreadPool(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_dask_parralel(\n",
    "#def add_features_parallel(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    \n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    full_data_indexes = tuple(acoustic_data_series.index.tolist())\n",
    "\n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "    output_first_index = 0\n",
    "    output_last_index = len(sample_df) - 1\n",
    "    \n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "   \n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    @dask.delayed\n",
    "    def create_features():\n",
    "        for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "\n",
    "            feature_values_list = list(range(sample_size))\n",
    "\n",
    "            half_window_size = window_size // 2\n",
    "\n",
    "            sample_begin_indexes = sample_indexes[:half_window_size]\n",
    "            full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "            min_full_data_index = min(full_data_indexes)\n",
    "        \n",
    "            in_window_full_data_begin_indexes = set(range(input_first_index, input_first_index + half_window_size))              \n",
    "            in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "                in_window_full_data_begin_indexes\n",
    "            )\n",
    "        \n",
    "            sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "            full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "            max_full_data_index = max(full_data_end_indexes) + 1\n",
    "        \n",
    "            in_window_full_data_end_indexes = set(range(input_last_index - half_window_size, input_last_index))        \n",
    "            in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "                in_window_full_data_end_indexes\n",
    "            )\n",
    "            if in_window_begin_indexes:\n",
    "                begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "                for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                    value = sample_df.iloc[i]['acoustic_data']\n",
    "                    temp = acoustic_data_series.iloc[input_first_index:input_first_index + window_size].mean()\n",
    "                    value = value - temp\n",
    "                    feature_values_list[output_first_index + i] = value\n",
    "                \n",
    "            if in_window_end_indexes:\n",
    "                end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "                for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                    value = sample_df.iloc[output_last_index - i]['acoustic_data']\n",
    "                    temp = acoustic_data_series.iloc[input_last_index - window_size:].mean()\n",
    "                    value = value - temp\n",
    "                    feature_values_list[output_last_index - i] = value\n",
    "                \n",
    "            first_regular_idx = len(begin_indexes_set)\n",
    "            last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "            for i in range(first_regular_idx, last_regular_idx):\n",
    "                sample_idx = sample_indexes[i]\n",
    "                feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                    sample_idx - half_window_size:sample_idx + half_window_size\n",
    "                ].mean()\n",
    "            sample_df[feature_name] = feature_values_list\n",
    "        return sample_df\n",
    "      \n",
    "    sample_df = create_features().compute()\n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features = add_features_dask_parralel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    \n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    full_data_indexes = tuple(acoustic_data_series.index.tolist())\n",
    "\n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "    output_first_index = 0\n",
    "    output_last_index = len(sample_df) - 1\n",
    "    \n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "   \n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "\n",
    "        feature_values_list = list(range(sample_size))\n",
    "\n",
    "        half_window_size = window_size // 2\n",
    "\n",
    "        sample_begin_indexes = sample_indexes[:half_window_size]\n",
    "        full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "        min_full_data_index = min(full_data_indexes)\n",
    "        \n",
    "        in_window_full_data_begin_indexes = set(range(input_first_index, input_first_index + half_window_size))              \n",
    "        in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "            in_window_full_data_begin_indexes\n",
    "        )\n",
    "        \n",
    "        sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "        full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "        max_full_data_index = max(full_data_end_indexes) + 1\n",
    "        \n",
    "        in_window_full_data_end_indexes = set(range(input_last_index - half_window_size, input_last_index))        \n",
    "        in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "            in_window_full_data_end_indexes\n",
    "        )\n",
    "        if in_window_begin_indexes:\n",
    "            begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "            for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                value = sample_df.iloc[i]['acoustic_data']\n",
    "                temp = acoustic_data_series.iloc[input_first_index:input_first_index + window_size].mean()\n",
    "                value = value - temp\n",
    "                feature_values_list[output_first_index + i] = value\n",
    "                \n",
    "        if in_window_end_indexes:\n",
    "            end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "            for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                value = sample_df.iloc[output_last_index - i]['acoustic_data']\n",
    "                temp = acoustic_data_series.iloc[input_last_index - window_size:].mean()\n",
    "                value = value - temp\n",
    "                feature_values_list[output_last_index - i] = value\n",
    "                \n",
    "        first_regular_idx = len(begin_indexes_set)\n",
    "        last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "        for i in range(first_regular_idx, last_regular_idx):\n",
    "            sample_idx = sample_indexes[i]\n",
    "            feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                sample_idx - half_window_size:sample_idx + half_window_size\n",
    "            ].mean()\n",
    "        sample_df[feature_name] = feature_values_list\n",
    "        \n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(z):\n",
    "    print()\n",
    "    print(\"extract_features, z.shape:\", z.shape)\n",
    "    #print()\n",
    "    return np.c_[z.mean(axis=1),\n",
    "                 np.transpose(np.percentile(np.abs(z), q=[0, 50, 75, 100], axis=1)),\n",
    "                 z.std(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(z):\n",
    "    return np.c_[z.mean(axis=1),\n",
    "                 np.transpose(np.percentile(np.abs(z), q=[0, 50, 75, 100], axis=1)),\n",
    "                 z.std(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, last_index=None, n_steps=150, step_length=1000):\n",
    "    if last_index == None:\n",
    "        last_index=len(x)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"createX, x.shape:\", x.shape)\n",
    "    print(\"createX, last_index:\", last_index)\n",
    "    print(\"createX, n_steps:\", n_steps)\n",
    "    print(\"createX, step_length:\", step_length)\n",
    "    print(\"last_index - n_steps * step_length:\", last_index - n_steps * step_length)\n",
    "    assert last_index - n_steps * step_length >= 0\n",
    "\n",
    "    # Reshaping and approximate standardization with mean 5 and std 3.\n",
    "    # ORIGINAL: I changed this becuase I got an No OpKernel was registered to support Op 'CudnnRNN' error\n",
    "    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) / 3\n",
    "    # MY CHANGE: This doesn't fix things, I get the same errors\n",
    "    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1).astype(np.float32) - 5 ) / 3\n",
    "    temp = x[(last_index - n_steps * step_length):last_index]\n",
    "    print(\"createX, temp.shape before reshape:\", temp.shape)\n",
    "    temp = temp.reshape(n_steps, -1).astype(np.float32)\n",
    "    print(\"create_X, temp.shape after reshape:\", temp.shape)\n",
    "    temp = (temp - 5) / 3\n",
    "    \n",
    "    # Extracts features of sequences of full length 1000, of the last 100 values and finally also \n",
    "    # of the last 10 observations.\n",
    "    print(\"createX, extract_features(temp).shape:\", extract_features(temp).shape)\n",
    "    print(\"createX, extract_features(temp[:, -step_length // 10:]).shape\", extract_features(temp[:, -step_length // 10:]).shape)\n",
    "    print(\"createX, extract_features(temp[:, -step_length // 100:]).shape\", extract_features(temp[:, -step_length // 100:]).shape)\n",
    "    print()\n",
    "    result = np.c_[\n",
    "        extract_features(temp),\n",
    "        extract_features(temp[:, -step_length // 10:]),\n",
    "        extract_features(temp[:, -step_length // 100:])\n",
    "    ]\n",
    "    '''               \n",
    "    result = np.c_[\n",
    "        temp,\n",
    "        temp[:, -step_length // 10:],\n",
    "        temp[:, -step_length // 100:]\n",
    "    ]\n",
    "    '''\n",
    "    print(\"createX, result shape:\", result.shape)\n",
    "    print()\n",
    "    '''\n",
    "    return np.c_[extract_features(temp),\n",
    "                 extract_features(temp[:, -step_length // 10:]),\n",
    "                 extract_features(temp[:, -step_length // 100:])]\n",
    "    '''\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, last_index=None, n_steps=150, step_length=1000):\n",
    "    if last_index == None:\n",
    "        last_index=len(x)\n",
    "    \n",
    "    assert last_index - n_steps * step_length >= 0\n",
    "\n",
    "    # Reshaping and approximate standardization with mean 5 and std 3.\n",
    "    # ORIGINAL: I changed this becuase I got an No OpKernel was registered to support Op 'CudnnRNN' error\n",
    "    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) / 3\n",
    "    # MY CHANGE: This doesn't fix things, I get the same errors\n",
    "    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1).astype(np.float32) - 5 ) / 3\n",
    "    temp = x[(last_index - n_steps * step_length):last_index]\n",
    "\n",
    "    temp = temp.reshape(n_steps, -1).astype(np.float32)\n",
    "\n",
    "    temp = (temp - 5) / 3\n",
    "    \n",
    "    # Extracts features of sequences of full length 1000, of the last 100 values and finally also \n",
    "    # of the last 10 observations.\n",
    "\n",
    "    result = np.c_[\n",
    "        extract_features(temp),\n",
    "        extract_features(temp[:, -step_length // 10:]),\n",
    "        extract_features(temp[:, -step_length // 100:])\n",
    "    ]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generator endlessly selects \"batch_size\" ending positions of sub-time series. For each ending position,\n",
    "# the \"time_to_failure\" serves as target, while the features are created by the function \"create_X\".\n",
    "#def generator(data, min_index=0, max_index=None, batch_size=16, n_steps=150, step_length=1000):\n",
    "def generator(data, y, rows, batch_size=16, n_steps=150, step_length=1000):\n",
    "    #if max_index is None:\n",
    "    #    max_index = len(data) - 1\n",
    "    print(\"\\n\")   \n",
    "    print(\"generator, data.shape:\", data.shape)\n",
    "    \n",
    "    '''\n",
    "    while True:\n",
    "        # Pick indices of ending positions\n",
    "        #rows = np.random.randint(min_index + n_steps * step_length, max_index, size=batch_size)\n",
    "        print(\"generator, type(rows):\", type(rows))\n",
    "        print(\"generator, rows.shape:\", rows.shape)\n",
    "        print(\"generator rows:\\n\", rows)\n",
    "         \n",
    "        # Initialize feature matrices and targets\n",
    "        samples = np.zeros((batch_size, n_steps, n_features))\n",
    "        targets = np.zeros(batch_size, )\n",
    "        print(\"generator, samples.shape:\", samples.shape)\n",
    "        print(\"generator, targets.shape:\", targets.shape)\n",
    "        \n",
    "        for j, row in enumerate(rows):\n",
    "            print(\"generator j: {}, row: {}\".format(j, row))\n",
    "            samples[j] = create_X(data[:, 0], last_index=row, n_steps=n_steps, step_length=step_length)\n",
    "            print(\"generator, samples[{}].shape:\".format(j), samples[j].shape)\n",
    "            print(\"generator, row - 1:\", row - 1)\n",
    "            targets[j] = data[row - 1, 1]\n",
    "            print(\"generator, targets[{}].shape:\".format(j), targets[j].shape)\n",
    "            print()\n",
    "        yield samples, targets\n",
    "    '''\n",
    "        \n",
    "    while True:\n",
    "        \n",
    "        # Pick indices of ending positions\n",
    "        #rows = np.random.randint(min_index + n_steps * step_length, max_index, size=batch_size)\n",
    "         \n",
    "        # Initialize feature matrices and targets\n",
    "        samples = np.zeros((batch_size, n_steps, n_features))\n",
    "        targets = np.zeros(batch_size, )\n",
    "        \n",
    "        for j, row in enumerate(rows):\n",
    "            samples[j] = create_X(data, last_index=row, n_steps=n_steps, step_length=step_length)\n",
    "            #targets[j] = data[row - 1, 1]\n",
    "            targets[j] = y[row - 1]\n",
    "            #temp = x[(last_index - n_steps * step_length):last_index]\n",
    "            #print(\"createX, temp.shape before reshape:\", temp.shape)\n",
    "            #temp = temp.reshape(n_steps, -1).astype(np.float32)\n",
    "            #print(\"create_X, temp.shape after reshape:\", temp.shape)\n",
    "            #temp = (temp - 5) / 3\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, y, rows, batch_size=16, n_steps=150, step_length=1000):\n",
    "    #if max_index is None:\n",
    "    #    max_index = len(data) - 1\n",
    "\n",
    "        \n",
    "    while True:\n",
    "        \n",
    "        # Pick indices of ending positions\n",
    "        #rows = np.random.randint(min_index + n_steps * step_length, max_index, size=batch_size)\n",
    "         \n",
    "        # Initialize feature matrices and targets\n",
    "        samples = np.zeros((batch_size, n_steps, n_features))\n",
    "        targets = np.zeros(batch_size, )\n",
    "        \n",
    "        for j, row in enumerate(rows):\n",
    "            samples[j] = create_X(data, last_index=row, n_steps=n_steps, step_length=step_length)\n",
    "            #targets[j] = data[row - 1, 1]\n",
    "            targets[j] = y[row - 1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 48)                9792      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                490       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 10,293\n",
      "Trainable params: 10,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cb = [ModelCheckpoint(\"model.hdf5\", save_best_only=True, period=3)]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(CuDNNGRU(48, input_shape=(None, n_features)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generator, data.shape: (1228017, 4)\n",
      "CPU times: user 5h 22min 57s, sys: 1min 36s, total: 5h 24min 33s\n",
      "Wall time: 5h 9min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(optimizer=adam(lr=0.0005), loss=\"mae\")\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=1000,\n",
    "                              epochs=30,\n",
    "                              verbose=0,\n",
    "                              callbacks=cb,\n",
    "                              validation_data=valid_gen,\n",
    "                              validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#float_data = pd.read_csv(\"../input/train/train.csv\", dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 25s, sys: 12 s, total: 2min 37s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#        earthquake_df = pd.read_csv(\n",
    "#                '../input/train/train.csv',\n",
    "#                #nrows=100000000,\n",
    "#                names=['acoustic_data', 'time_to_failure'],\n",
    "#                dtype={'acoustic_data': np.float32, 'time_to_failure': np.float32},\n",
    "#                skiprows=earthquake_margin_indexes[i],\n",
    "#                nrows=complete_earthquakes_length[i]\n",
    "#            )\n",
    "\n",
    "train_df = pd.read_csv('../input/train/train.csv', dtype={'acoustic_data': np.float32, 'time_to_failure': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full calculation feature value time (with slicing) 84.39742310841878 min:\n",
      "CPU times: user 1h 25min 13s, sys: 27.8 s, total: 1h 25min 41s\n",
      "Wall time: 1h 25min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#        if not sample_size:\n",
    "#            sample_size = complete_earthquakes_length[i] // 10\n",
    "#        if not holdout_size:\n",
    "#            holdout_size = complete_earthquakes_length[i] // 50\n",
    "#sample_size = train_df.shape[0] // 10\n",
    "#holdout_size = train_df.shape[0] // 50\n",
    "sample_size = 7500000\n",
    "holdout_size = 1500000\n",
    "featured_train_df, featured_holdout_df = add_features(\n",
    "                train_df,\n",
    "                sample_size=sample_size,\n",
    "                holdout_size=holdout_size\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "      <th>smootch_mean_ws_3</th>\n",
       "      <th>smootch_mean_ws_5</th>\n",
       "      <th>smootch_mean_ws_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.469100</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.469100</td>\n",
       "      <td>11.5</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.469099</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.469099</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>6.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.469099</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acoustic_data  time_to_failure  smootch_mean_ws_3  smootch_mean_ws_5  \\\n",
       "0            6.0         1.469100                7.0               5.50   \n",
       "1           15.0         1.469100               11.5              10.75   \n",
       "2            5.0         1.469099                3.5               3.25   \n",
       "3            6.0         1.469099                8.0               7.75   \n",
       "4            7.0         1.469099                7.0               7.00   \n",
       "\n",
       "   smootch_mean_ws_7  \n",
       "0           6.000000  \n",
       "1           9.500000  \n",
       "2           2.666667  \n",
       "3           6.166667  \n",
       "4           6.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = featured_train_df[featured_train_df.columns.drop('time_to_failure')]\n",
    "y_all = featured_train_df['time_to_failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 300000, 450000, 600000, 750000, 900000, 1050000, 1200000, 1350000, 1500000, 1650000, 1800000, 1950000, 2100000, 2250000, 2400000, 2550000, 2700000, 2850000, 3000000, 3150000, 3300000, 3450000, 3600000, 3750000, 3900000, 4050000, 4200000, 4350000, 4500000, 4650000)\n",
      "(150000, 300000, 450000, 600000, 750000, 900000, 1050000)\n"
     ]
    }
   ],
   "source": [
    "train_rows = tuple(range(0, 4800000, 150000))[1:]\n",
    "valid_rows = tuple(range(0, 1200000, 150000))[1:]\n",
    "print(train_rows)\n",
    "print(valid_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "createX, x.shape: (150000, 4)\n",
      "createX, last_index: 150000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 0\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "Our RNN is based on 18 features\n"
     ]
    }
   ],
   "source": [
    "# Query \"create_X\" to figure out the number of features\n",
    "#n_features = create_X(float_data[0:150000]).shape[1]\n",
    "n_features = create_X(X_train[0:150000].values).shape[1]\n",
    "print(\"Our RNN is based on %i features\"% n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Position of second (of 16) earthquake. Used to have a clean split\n",
    "# between train and validation\n",
    "#second_earthquake = 50085877\n",
    "#float_data[second_earthquake, 1]\n",
    "#X_train[second_earthquake, 1]\n",
    "\n",
    "# Initialize generators\n",
    "# train_gen = generator(float_data, batch_size=batch_size) # Use this for better score\n",
    "# train_gen = generator(float_data, batch_size=batch_size, min_index=second_earthquake + 1)\n",
    "# valid_gen = generator(float_data, batch_size=batch_size, max_index=second_earthquake)\n",
    "train_gen = generator(X_train.values, y_train.values, train_rows, batch_size=batch_size)\n",
    "valid_gen = generator(X_valid.values, y_valid.values, valid_rows, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generator, data.shape: (4912068, 4)\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 150000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 0\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 300000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 150000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 450000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 300000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 600000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 450000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 750000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 600000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 900000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 750000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 1050000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 900000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 1200000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 1050000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 1350000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 1200000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 1500000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 1350000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 1650000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 1500000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 1800000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 1650000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 1950000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 1800000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 2100000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 1950000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 2250000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 2100000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 2400000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 2250000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 2550000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 2400000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 2700000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 2550000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 2850000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 2700000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 3000000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 2850000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 3150000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 3000000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 3300000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 3150000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 3450000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 3300000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 3600000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 3450000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 3750000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 3600000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 3900000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 3750000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 4050000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 3900000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 4200000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 4050000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 4350000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 4200000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 4500000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 4350000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n",
      "\n",
      "\n",
      "createX, x.shape: (4912068, 4)\n",
      "createX, last_index: 4650000\n",
      "createX, n_steps: 150\n",
      "createX, step_length: 1000\n",
      "last_index - n_steps * step_length: 4500000\n",
      "createX, temp.shape before reshape: (150000, 4)\n",
      "create_X, temp.shape after reshape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "createX, extract_features(temp).shape: (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "createX, extract_features(temp[:, -step_length // 10:]).shape (150, 6)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, extract_features(temp[:, -step_length // 100:]).shape (150, 6)\n",
      "\n",
      "\n",
      "extract_features, z.shape: (150, 4000)\n",
      "\n",
      "extract_features, z.shape: (150, 100)\n",
      "\n",
      "extract_features, z.shape: (150, 10)\n",
      "createX, result shape: (150, 18)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[-0.19120835,  0.        ,  0.66666669, ...,  3.66666675,\n",
       "           4.08333349,  1.63776803],\n",
       "         [-0.10288889,  0.        ,  0.66666669, ...,  1.06250003,\n",
       "           1.5       ,  0.73864347],\n",
       "         [-0.14128472,  0.        ,  0.66666669, ...,  1.09722218,\n",
       "           1.5       ,  0.78963679],\n",
       "         ...,\n",
       "         [-0.09711111,  0.        ,  0.66666669, ...,  0.62500001,\n",
       "           1.11111116,  0.48464859],\n",
       "         [-0.28977081,  0.        ,  0.66666669, ...,  1.04166664,\n",
       "           1.66666663,  0.86270463],\n",
       "         [-0.10181945,  0.        ,  0.66666669, ...,  0.66666669,\n",
       "           1.08333337,  0.65216291]],\n",
       " \n",
       "        [[-0.17263888,  0.        ,  0.66666669, ...,  0.54166664,\n",
       "           0.83333331,  0.47369868],\n",
       "         [-0.250375  ,  0.        ,  0.58333331, ...,  1.        ,\n",
       "           1.16666663,  0.39166665],\n",
       "         [-0.17546527,  0.        ,  0.6111111 , ...,  4.37499976,\n",
       "           5.        ,  2.06230307],\n",
       "         ...,\n",
       "         [-0.19015972,  0.        ,  0.66666669, ...,  0.62500001,\n",
       "           0.72222227,  0.48177433],\n",
       "         [-0.32173613,  0.        ,  0.6111111 , ...,  2.13888896,\n",
       "           2.33333325,  0.78154349],\n",
       "         [-0.20577084,  0.        ,  0.66666669, ...,  0.77083339,\n",
       "           1.        ,  0.32381076]],\n",
       " \n",
       "        [[-0.22253473,  0.        ,  0.66666669, ...,  2.60416669,\n",
       "           4.33333349,  1.72561491],\n",
       "         [-0.19748612,  0.        ,  0.66666669, ...,  0.62500001,\n",
       "           1.33333337,  0.50944775],\n",
       "         [-0.1427014 ,  0.        ,  0.66666669, ...,  1.14583331,\n",
       "           1.66666663,  0.24247946],\n",
       "         ...,\n",
       "         [-0.13039583,  0.        ,  0.66666669, ...,  0.48611113,\n",
       "           0.72222227,  0.41612002],\n",
       "         [-0.17304169,  0.        ,  0.66666669, ...,  1.47916664,\n",
       "           2.25      ,  0.75545847],\n",
       "         [-0.38841665,  0.        ,  0.66666669, ...,  1.60416663,\n",
       "           2.        ,  1.23118246]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.17774305,  0.        ,  0.66666669, ...,  0.45833334,\n",
       "           1.91666663,  0.76646531],\n",
       "         [-0.22639582,  0.        ,  0.61111116, ...,  1.60416663,\n",
       "           2.08333325,  0.88675523],\n",
       "         [-0.19846527,  0.        ,  0.6111111 , ...,  0.57638888,\n",
       "           0.94444442,  0.44330582],\n",
       "         ...,\n",
       "         [-0.07599305,  0.        ,  0.66666669, ...,  1.0833333 ,\n",
       "           1.66666663,  0.72181612],\n",
       "         [-0.1376389 ,  0.        ,  0.6111111 , ...,  0.97222221,\n",
       "           1.33333337,  0.44596961],\n",
       "         [-0.12827085,  0.        ,  0.66666669, ...,  1.        ,\n",
       "           1.33333337,  0.76449472]],\n",
       " \n",
       "        [[-0.14572223,  0.        ,  0.66666669, ...,  0.61111114,\n",
       "           1.33333337,  0.50124079],\n",
       "         [-0.06861806,  0.        ,  0.66666669, ...,  0.9375    ,\n",
       "           2.        ,  0.66458011],\n",
       "         [-0.12329166,  0.        ,  0.66666669, ...,  0.39583333,\n",
       "           0.66666669,  0.29845276],\n",
       "         ...,\n",
       "         [-0.17461112,  0.        ,  0.66666669, ...,  0.37499996,\n",
       "           1.        ,  0.34649926],\n",
       "         [-0.1895625 ,  0.        ,  0.66666669, ...,  0.81944442,\n",
       "           1.66666663,  0.4765245 ],\n",
       "         [-0.2215625 ,  0.        ,  0.66666669, ...,  1.52777773,\n",
       "           2.        ,  1.24850523]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]]]),\n",
       " array([ 0.81509632, 10.99709606, 10.47159576,  3.73469901,  6.53939867,\n",
       "         0.26519781, 10.31809902,  7.36389923,  6.72089672,  3.30869865,\n",
       "         1.56359684,  8.7434988 , 11.60239697, 11.19769955,  3.62949729,\n",
       "         5.41839695,  6.6612978 ,  8.80619907, 10.67139626, 10.55759811,\n",
       "         1.42849565,  1.23409653,  4.26179695,  0.76739579,  8.23649883,\n",
       "         8.21809769,  4.5033989 ,  0.14319867,  2.04769611,  3.47999597,\n",
       "         5.97489548,  0.        ]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "      <th>smootch_mean_ws_3</th>\n",
       "      <th>smootch_mean_ws_5</th>\n",
       "      <th>smootch_mean_ws_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.582099</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10.564999</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.599000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.518199</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.50</td>\n",
       "      <td>12.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acoustic_data  time_to_failure  smootch_mean_ws_3  smootch_mean_ws_5  \\\n",
       "0            7.0         0.582099                8.5               7.75   \n",
       "1            3.0        10.564999                6.0               6.25   \n",
       "2            2.0         0.320900                4.0               3.75   \n",
       "3            2.0         2.599000                4.5               4.00   \n",
       "4           15.0         3.518199               11.5              12.50   \n",
       "\n",
       "   smootch_mean_ws_7  \n",
       "0           7.500000  \n",
       "1           5.333333  \n",
       "2           4.333333  \n",
       "3           4.833333  \n",
       "4          12.833333  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_holdout_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected cu_dnngru_1_input to have 3 dimensions, but got array with shape (1500000, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-767483b46472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mholdout_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatured_holdout_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatured_holdout_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acoustic_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                              'argument.')\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected cu_dnngru_1_input to have 3 dimensions, but got array with shape (1500000, 4)"
     ]
    }
   ],
   "source": [
    "holdout_prediction = model.predict(featured_holdout_df[featured_holdout_df.columns.drop('acoustic_data')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam(lr=0.0005), loss=\"mae\")\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=1000,\n",
    "                              epochs=30,\n",
    "                              verbose=0,\n",
    "                              callbacks=cb,\n",
    "                              validation_data=valid_gen,\n",
    "                              validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def perf_plot(history, what = 'loss'):\n",
    "    x = history.history[what]\n",
    "    val_x = history.history['val_' + what]\n",
    "    epochs = np.asarray(history.epoch) + 1\n",
    "    \n",
    "    plt.plot(epochs, x, 'bo', label = \"Training \" + what)\n",
    "    plt.plot(epochs, val_x, 'b', label = \"Validation \" + what)\n",
    "    plt.title(\"Training and validation \" + what)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "perf_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id', dtype={\"time_to_failure\": np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56df9304b98643c098807d018b4452a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2624), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seg_00030f</th>\n",
       "      <td>3.775189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_0012b5</th>\n",
       "      <td>3.561212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_00184e</th>\n",
       "      <td>3.827060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_003339</th>\n",
       "      <td>3.929479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_0042cc</th>\n",
       "      <td>3.956853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_to_failure\n",
       "seg_id                     \n",
       "seg_00030f         3.775189\n",
       "seg_0012b5         3.561212\n",
       "seg_00184e         3.827060\n",
       "seg_003339         3.929479\n",
       "seg_0042cc         3.956853"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, seg_id in enumerate(tqdm_notebook(submission.index)):\n",
    "  #  print(i)\n",
    "    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n",
    "    x = seg['acoustic_data'].values\n",
    "    submission.time_to_failure[i] = model.predict(np.expand_dims(create_X(x), 0))\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_rnn_smoothing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rnn_s = pd.read_csv('submission_rnn_smoothing.csv')\n",
    "s_base = pd.read_csv('submission_chunks_10.csv')\n",
    "s_rnn_base = pd.read_csv('rnn-submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.017881146654393"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(s_base['time_to_failure'], s_rnn_base['time_to_failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916080741280486"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(s_base['time_to_failure'], s_rnn_s['time_to_failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6419703508384154"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(s_rnn_base['time_to_failure'], s_rnn_s['time_to_failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
