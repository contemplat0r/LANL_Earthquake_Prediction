{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask\n",
    "import dask.multiprocessing\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/dask/context.py:23: UserWarning: The dask.set_options function has been deprecated. Please use dask.config.set instead\n",
      "  warnings.warn(\"The dask.set_options function has been deprecated. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7f55afc984e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(scheduler='processes')\n",
    "dask.set_options( pool=ThreadPool(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    \n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    full_data_indexes = tuple(acoustic_data_series.index.tolist())\n",
    "\n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "    output_first_index = 0\n",
    "    output_last_index = len(sample_df) - 1\n",
    "    \n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "   \n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "\n",
    "        feature_values_list = list(range(sample_size))\n",
    "\n",
    "        half_window_size = window_size // 2\n",
    "\n",
    "        sample_begin_indexes = sample_indexes[:half_window_size]\n",
    "        full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "        min_full_data_index = min(full_data_indexes)\n",
    "        \n",
    "        in_window_full_data_begin_indexes = set(range(input_first_index, input_first_index + half_window_size))              \n",
    "        in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "            in_window_full_data_begin_indexes\n",
    "        )\n",
    "        \n",
    "        sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "        full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "        max_full_data_index = max(full_data_end_indexes) + 1\n",
    "        \n",
    "        in_window_full_data_end_indexes = set(range(input_last_index - half_window_size, input_last_index))        \n",
    "        in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "            in_window_full_data_end_indexes\n",
    "        )\n",
    "        if in_window_begin_indexes:\n",
    "            begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "            for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                value = sample_df.iloc[i]['acoustic_data']\n",
    "                temp = acoustic_data_series.iloc[input_first_index:input_first_index + window_size].mean()\n",
    "                value = value - temp\n",
    "                feature_values_list[output_first_index + i] = value\n",
    "                \n",
    "        if in_window_end_indexes:\n",
    "            end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "            for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                value = sample_df.iloc[output_last_index - i]['acoustic_data']\n",
    "                temp = acoustic_data_series.iloc[input_last_index - window_size:].mean()\n",
    "                value = value - temp\n",
    "                feature_values_list[output_last_index - i] = value\n",
    "                \n",
    "        first_regular_idx = len(begin_indexes_set)\n",
    "        last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "        for i in range(first_regular_idx, last_regular_idx):\n",
    "            sample_idx = sample_indexes[i]\n",
    "            feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                sample_idx - half_window_size:sample_idx + half_window_size\n",
    "            ].mean()\n",
    "        sample_df[feature_name] = feature_values_list\n",
    "        \n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_dask_parralel(\n",
    "#def add_features_parallel(\n",
    "        df,\n",
    "        input_first_index=None,\n",
    "        input_last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    if input_first_index == None or input_last_index == None:\n",
    "        input_first_index = df.index.min()\n",
    "        input_last_index = df.index.max() + 1\n",
    "        \n",
    "    \n",
    "    sample_indexes = random.sample(range(input_first_index, input_last_index), sample_size)\n",
    "    sample_indexes.sort()\n",
    "    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    full_data_indexes = tuple(acoustic_data_series.index.tolist())\n",
    "\n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "    output_first_index = 0\n",
    "    output_last_index = len(sample_df) - 1\n",
    "    \n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "   \n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    @dask.delayed\n",
    "    def create_features():\n",
    "        for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "\n",
    "            feature_values_list = list(range(sample_size))\n",
    "\n",
    "            half_window_size = window_size // 2\n",
    "\n",
    "            sample_begin_indexes = sample_indexes[:half_window_size]\n",
    "            full_data_begin_indexes = set(df.index[sample_begin_indexes].tolist())\n",
    "            min_full_data_index = min(full_data_indexes)\n",
    "        \n",
    "            in_window_full_data_begin_indexes = set(range(input_first_index, input_first_index + half_window_size))              \n",
    "            in_window_begin_indexes = full_data_begin_indexes.intersection(\n",
    "                in_window_full_data_begin_indexes\n",
    "            )\n",
    "        \n",
    "            sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "            full_data_end_indexes = set(df.index[sample_end_indexes].tolist())\n",
    "            max_full_data_index = max(full_data_end_indexes) + 1\n",
    "        \n",
    "            in_window_full_data_end_indexes = set(range(input_last_index - half_window_size, input_last_index))        \n",
    "            in_window_end_indexes = full_data_end_indexes.intersection(\n",
    "                in_window_full_data_end_indexes\n",
    "            )\n",
    "            if in_window_begin_indexes:\n",
    "                begin_indexes_set = begin_indexes_set.union(in_window_begin_indexes)\n",
    "                for i, b_idx in enumerate(sorted(tuple(in_window_begin_indexes))):\n",
    "                    value = sample_df.iloc[i]['acoustic_data']\n",
    "                    temp = acoustic_data_series.iloc[input_first_index:input_first_index + window_size].mean()\n",
    "                    value = value - temp\n",
    "                    feature_values_list[output_first_index + i] = value\n",
    "                \n",
    "            if in_window_end_indexes:\n",
    "                end_indexes_set = end_indexes_set.union(in_window_end_indexes)\n",
    "                for i, e_idx in enumerate(sorted(tuple(in_window_end_indexes))):\n",
    "                    value = sample_df.iloc[output_last_index - i]['acoustic_data']\n",
    "                    temp = acoustic_data_series.iloc[input_last_index - window_size:].mean()\n",
    "                    value = value - temp\n",
    "                    feature_values_list[output_last_index - i] = value\n",
    "                \n",
    "            first_regular_idx = len(begin_indexes_set)\n",
    "            last_regular_idx = sample_df_len - len(end_indexes_set)\n",
    "            for i in range(first_regular_idx, last_regular_idx):\n",
    "                sample_idx = sample_indexes[i]\n",
    "                feature_values_list[i] = acoustic_data_series.iloc[\n",
    "                    sample_idx - half_window_size:sample_idx + half_window_size\n",
    "                ].mean()\n",
    "            sample_df[feature_name] = feature_values_list\n",
    "        return sample_df\n",
    "        \n",
    "    holdout_df = None\n",
    "    if holdout_size > 0:\n",
    "        holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "        holdout_df = sample_df.iloc[holdout_indexes]\n",
    "        holdout_df.reset_index(inplace=True)\n",
    "        holdout_df.drop(columns=['index'], inplace=True)\n",
    "        train_indexes = sorted(tuple(set(sample_df.index).difference(set(holdout_indexes))))\n",
    "        sample_df = sample_df.iloc[train_indexes]\n",
    "        sample_df.reset_index(inplace=True)\n",
    "        sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features = add_features_dask_parralel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_margin_indexes =[\n",
    "    5656573,\n",
    "    50085877,\n",
    "    104677355,\n",
    "    138772452,\n",
    "    187641819,\n",
    "    218652629,\n",
    "    245829584,\n",
    "    307838916,\n",
    "    338276286,\n",
    "    375377847,\n",
    "    419368879,\n",
    "    461811622,\n",
    "    495800224,\n",
    "    528777114,\n",
    "    585568143,\n",
    "    621985672\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes_length = [earthquake_margin_indexes[i + 1] - earthquake_margin_indexes[i] for i in range(len(earthquake_margin_indexes) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44429304,\n",
       " 54591478,\n",
       " 34095097,\n",
       " 48869367,\n",
       " 31010810,\n",
       " 27176955,\n",
       " 62009332,\n",
       " 30437370,\n",
       " 37101561,\n",
       " 43991032,\n",
       " 42442743,\n",
       " 33988602,\n",
       " 32976890,\n",
       " 56791029,\n",
       " 36417529]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_earthquakes_length = earthquakes_length[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete_earthquaces_length = complete_earthquaces_length[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44429304,\n",
       " 54591478,\n",
       " 34095097,\n",
       " 48869367,\n",
       " 31010810,\n",
       " 27176955,\n",
       " 62009332,\n",
       " 30437370,\n",
       " 37101561,\n",
       " 43991032,\n",
       " 42442743,\n",
       " 33988602,\n",
       " 32976890,\n",
       " 56791029]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_earthquakes_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 s, sys: 80 ms, total: 1.46 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "not_seen_data_df = pd.read_csv(\n",
    "    '../input/train/train.csv',\n",
    "    #nrows=100000000,\n",
    "    names=['acoustic_data', 'time_to_failure'],\n",
    "    dtype={'acoustic_data': np.float32, 'time_to_failure': np.float32},\n",
    "    skiprows=1,\n",
    "    nrows=5656572\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full calculation feature value time (with slicing) 5.046526590983073e-06 min:\n",
      "CPU times: user 984 ms, sys: 212 ms, total: 1.2 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "featured_not_seen_data_df, _ = add_features(\n",
    "    not_seen_data_df,\n",
    "    sample_size=not_seen_data_df.shape[0] // 20,\n",
    "    holdout_size=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_not_seen_data = featured_not_seen_data_df['time_to_failure']\n",
    "featured_not_seen_data_no_time_df = featured_not_seen_data_df[featured_not_seen_data_df.columns.drop('time_to_failure')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
