{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from tqdm import tqdm_notebook\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from tensorflow import keras\n",
    "#from gplearn.genetic import SymbolicRegressor\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "#import numpy as np \n",
    "#import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# Define model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNGRU, Dropout, TimeDistributed, LSTM, CuDNNLSTM\n",
    "from keras.optimizers import adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# Fix seeds\n",
    "from numpy.random import seed\n",
    "#seed(639)\n",
    "from tensorflow import set_random_seed\n",
    "#set_random_seed(5944)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(639)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(5944)\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "#from sklearn.ensemble import AdaBoostRegressor\n",
    "#from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training file with simple derived features\n",
    "\n",
    "def add_trend_feature(arr, abs_values=False):\n",
    "    idx = np.array(range(len(arr)))\n",
    "    if abs_values:\n",
    "        arr = np.abs(arr)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(idx.reshape(-1, 1), arr)\n",
    "    return lr.coef_[0]\n",
    "\n",
    "def classic_sta_lta(x, length_sta, length_lta):\n",
    "    \n",
    "    sta = np.cumsum(x ** 2)\n",
    "\n",
    "    # Convert to float\n",
    "    sta = np.require(sta, dtype=np.float)\n",
    "\n",
    "    # Copy for LTA\n",
    "    lta = sta.copy()\n",
    "\n",
    "    # Compute the STA and the LTA\n",
    "    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "    sta /= length_sta\n",
    "    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "    lta /= length_lta\n",
    "\n",
    "    # Pad zeros\n",
    "    sta[:length_lta - 1] = 0\n",
    "\n",
    "    # Avoid division by zero by setting zero values to tiny float\n",
    "    dtiny = np.finfo(0.0).tiny\n",
    "    idx = lta < dtiny\n",
    "    lta[idx] = dtiny\n",
    "\n",
    "    return sta / lta\n",
    "\n",
    "def calc_change_rate(x):\n",
    "    change = (np.diff(x) / x[:-1]).values\n",
    "    change = change[np.nonzero(change)[0]]\n",
    "    change = change[~np.isnan(change)]\n",
    "    change = change[change != -np.inf]\n",
    "    change = change[change != np.inf]\n",
    "    return np.mean(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extremal_accelerations(df, sort_field_name='acoustic_data', num_of_extremals=12):\n",
    "    sorted_df = df.sort_values(sort_field_name)\n",
    "    extremal_accelerations = []\n",
    "    for i in range(num_of_extremals):\n",
    "        idx_min = sorted_df.index[i]\n",
    "        idx_max = sorted_df.index[-i - 1]\n",
    "        min_v = df.iloc[idx_min][sort_field_name]\n",
    "        max_v = df.iloc[idx_max][sort_field_name]\n",
    "        extremal_accelerations.append((\n",
    "            (max_v - min_v) / (idx_max - idx_min)\n",
    "        ))\n",
    "    return extremal_accelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extremal_accelerations(series, num_of_extremals=12):\n",
    "    sorted_series = series.sort_values()\n",
    "    extremal_accelerations = []\n",
    "    for i in range(num_of_extremals):\n",
    "        idx_min = sorted_series.index[i]\n",
    "        idx_max = sorted_series.index[-i - 1]\n",
    "        min_v = series.iloc[idx_min]\n",
    "        max_v = series.iloc[idx_max]\n",
    "        extremal_accelerations.append((\n",
    "            (max_v - min_v) / (idx_max - idx_min)\n",
    "        ))\n",
    "    return extremal_accelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extremals(series, num_of_extremals=6):\n",
    "\n",
    "    sorted_series = series.sort_values()\n",
    "    extremals_indexes = set()\n",
    "    extremals = []\n",
    "    \n",
    "    i = 0\n",
    "    min_idx_idx = 0\n",
    "    max_idx_idx = 0\n",
    "    extremals_coutner = 0\n",
    "    while (extremals_coutner < num_of_extremals):\n",
    "\n",
    "        idx_min = sorted_series.index[min_idx_idx]\n",
    "        idx_min_not_proceed = not idx_min in extremals_indexes\n",
    "\n",
    "        idx_max = sorted_series.index[-max_idx_idx - 1]\n",
    "        idx_max_not_proceed = not idx_max in extremals_indexes\n",
    "\n",
    "        if idx_min_not_proceed and idx_max_not_proceed:\n",
    "            if idx_max < idx_min:               \n",
    "                idx_min, idx_max = idx_max, idx_min\n",
    "            extremals_indexes = extremals_indexes.union(set(range(idx_min, idx_max + 1)))\n",
    "            extremals.append(series.iloc[idx_min:idx_max])\n",
    "            min_idx_idx += 1\n",
    "            max_idx_idx += 1\n",
    "            extremals_coutner += 1\n",
    "        else:\n",
    "            if not idx_min_not_proceed:\n",
    "                min_idx_idx += 1\n",
    "            if not idx_max_not_proceed:\n",
    "                max_idx_idx += 1\n",
    "\n",
    "    return extremals, series.loc[set(series.index).difference(extremals_indexes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extremals(series, num_of_extremals=12):\n",
    "    sorted_series = series.sort_values()\n",
    "    extremals_indexes = set()\n",
    "    extremals = []    \n",
    "    for i in range(num_of_extremals):\n",
    "        idx_min = sorted_series.index[i]\n",
    "        idx_max = sorted_series.index[-i - 1]\n",
    "        if idx_max < idx_min:               \n",
    "            idx_min, idx_max = idx_max, idx_min\n",
    "        extremals_indexes = extremals_indexes.union(set(range(idx_min, idx_max + 1)))\n",
    "        extremals.append(series.iloc[idx_min:idx_max])\n",
    "        \n",
    "    return extremals, series.loc[set(series.index).difference(extremals_indexes)]    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator(object):\n",
    "    def __init__(self, dtype, n_jobs=1, chunk_size=None):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dtype = dtype\n",
    "        self.filename = None\n",
    "        self.n_jobs = n_jobs\n",
    "        self.test_files = []\n",
    "        if self.dtype == 'train':\n",
    "            self.filename = '../input/train/train.csv'\n",
    "            self.total_data = int(629145481 / self.chunk_size)\n",
    "            #print(\"Feature Generator __init__, self.total_data:\", self.total_data)\n",
    "        else:\n",
    "            submission = pd.read_csv('../input/sample_submission.csv')\n",
    "            for seg_id in submission.seg_id.values:\n",
    "                self.test_files.append((seg_id, '../input/test/' + seg_id + '.csv'))\n",
    "            #print(\"Feature Generator __init__, int(len(submission)):\", int(len(submission)))\n",
    "            self.total_data = int(len(submission))\n",
    "\n",
    "    def read_chunks(self):\n",
    "        if self.dtype == 'train':\n",
    "            iter_df = pd.read_csv(self.filename, iterator=True, chunksize=self.chunk_size,\n",
    "                                  dtype={'acoustic_data': np.float64, 'time_to_failure': np.float64})\n",
    "            for counter, df in enumerate(iter_df):\n",
    "                x = df.acoustic_data.values\n",
    "                y = df.time_to_failure.values[-1]\n",
    "                seg_id = 'train_' + str(counter)\n",
    "                del df\n",
    "                yield seg_id, x, y\n",
    "        else:\n",
    "            for seg_id, f in self.test_files:\n",
    "                df = pd.read_csv(f, dtype={'acoustic_data': np.float64})\n",
    "                x = df.acoustic_data.values[-self.chunk_size:]\n",
    "                del df\n",
    "                yield seg_id, x, -999\n",
    "    \n",
    "    def get_features(self, x, y, seg_id):\n",
    "        \"\"\"\n",
    "        Gets three groups of features: from original data and from reald and imaginary parts of FFT.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = pd.Series(x)\n",
    "        \n",
    "        '''\n",
    "        zc = np.fft.fft(x)\n",
    "        realFFT = pd.Series(np.real(zc))\n",
    "        imagFFT = pd.Series(np.imag(zc))\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        main_dict = self.features(x, y, seg_id)\n",
    "        \n",
    "        '''\n",
    "        r_dict = self.features(realFFT, y, seg_id)\n",
    "        i_dict = self.features(imagFFT, y, seg_id)\n",
    "        \n",
    "        for k, v in r_dict.items():\n",
    "            if k not in ['target', 'seg_id']:\n",
    "                main_dict[f'fftr_{k}'] = v\n",
    "                \n",
    "        for k, v in i_dict.items():\n",
    "            if k not in ['target', 'seg_id']:\n",
    "                main_dict[f'ffti_{k}'] = v\n",
    "        '''\n",
    "        return main_dict\n",
    "        \n",
    "    \n",
    "    def features(self, x, y, seg_id):\n",
    "        feature_dict = dict()\n",
    "        feature_dict['target'] = y\n",
    "        feature_dict['seg_id'] = seg_id\n",
    "\n",
    "        # create features here\n",
    "\n",
    "        # lists with parameters to iterate over them\n",
    "        #percentiles = [1, 5, 10, 20, 25, 30, 40, 50, 60, 70, 75, 80, 90, 95, 99]\n",
    "        percentiles = [10, 20]\n",
    "        hann_windows = [50, 150, 1500, 15000]\n",
    "        spans = [300, 3000, 30000, 50000]\n",
    "        windows = [10, 50, 100, 500, 1000, 10000]\n",
    "        borders = list(range(-4000, 4001, 1000))\n",
    "        #peaks = [10, 20, 50, 100]\n",
    "        peaks = [10]\n",
    "        coefs = [1, 5, 10, 50, 100]\n",
    "        lags = [10, 100, 1000, 10000]\n",
    "        #autocorr_lags = [5, 10, 50, 100, 500, 1000, 5000, 10000]\n",
    "        autocorr_lags = [5]\n",
    "        \n",
    "        # basic stats\n",
    "        feature_dict['mean'] = x.mean()\n",
    "        feature_dict['std'] = x.std()\n",
    "        feature_dict['max'] = x.max()\n",
    "        feature_dict['min'] = x.min()\n",
    "        \n",
    "        extremals, not_extremals = get_extremals(x, num_of_extremals=5)\n",
    "        \n",
    "        \n",
    "        for i, extremal in enumerate(extremals):\n",
    "            feature_dict[f'extr_accel_{i}'] = np.abs((extremal.max() - extremal.min()) / len(extremal))\n",
    "            feature_dict[f'extr_mean_{i}'] = extremal.mean()\n",
    "            feature_dict[f'extr_std_{i}'] = extremal.std()\n",
    "         \n",
    "        for i, item in enumerate(x.value_counts().iloc[:5].items()):\n",
    "            feature_dict[f'rel_freq_{i}'] = item[0] / item[1]\n",
    "\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        feature_dict[f'not_extr_mean'] = not_extremals.mean()\n",
    "        feature_dict[f'not_extr_std'] = not_extremals.std()\n",
    "        feature_dict[f'not_extr_min'] = not_extremals.min()\n",
    "        feature_dict[f'not_extr_max'] = not_extremals.max()\n",
    "        '''\n",
    "            \n",
    "        '''\n",
    "        # basic stats on absolute values\n",
    "        feature_dict['mean_change_abs'] = np.mean(np.diff(x))\n",
    "        feature_dict['abs_max'] = np.abs(x).max()\n",
    "        feature_dict['abs_mean'] = np.abs(x).mean()\n",
    "        feature_dict['abs_std'] = np.abs(x).std()\n",
    "        '''\n",
    "        \n",
    "\n",
    "        # geometric and harminic means\n",
    "        '''\n",
    "        feature_dict['hmean'] = stats.hmean(np.abs(x[np.nonzero(x)[0]]))\n",
    "        feature_dict['gmean'] = stats.gmean(np.abs(x[np.nonzero(x)[0]])) \n",
    "\n",
    "        # k-statistic and moments\n",
    "        for i in range(1, 5):\n",
    "            feature_dict[f'kstat_{i}'] = stats.kstat(x, i)\n",
    "            feature_dict[f'moment_{i}'] = stats.moment(x, i)\n",
    "\n",
    "        for i in [1, 2]:\n",
    "            feature_dict[f'kstatvar_{i}'] = stats.kstatvar(x, i)\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        # aggregations on various slices of data\n",
    "        for agg_type, slice_length, direction in product(['std', 'min', 'max', 'mean'], [1000, 10000, 50000], ['first', 'last']):\n",
    "            if direction == 'first':\n",
    "                feature_dict[f'{agg_type}_{direction}_{slice_length}'] = x[:slice_length].agg(agg_type)\n",
    "            elif direction == 'last':\n",
    "                feature_dict[f'{agg_type}_{direction}_{slice_length}'] = x[-slice_length:].agg(agg_type)\n",
    "        '''\n",
    "        \n",
    "\n",
    "        '''\n",
    "        feature_dict['max_to_min'] = x.max() / np.abs(x.min())\n",
    "        feature_dict['max_to_min_diff'] = x.max() - np.abs(x.min())\n",
    "        feature_dict['count_big'] = len(x[np.abs(x) > 500])\n",
    "        feature_dict['sum'] = x.sum()\n",
    "\n",
    "        feature_dict['mean_change_rate'] = calc_change_rate(x)\n",
    "        # calc_change_rate on slices of data\n",
    "        for slice_length, direction in product([1000, 10000, 50000], ['first', 'last']):\n",
    "            if direction == 'first':\n",
    "                feature_dict[f'mean_change_rate_{direction}_{slice_length}'] = calc_change_rate(x[:slice_length])\n",
    "            elif direction == 'last':\n",
    "                feature_dict[f'mean_change_rate_{direction}_{slice_length}'] = calc_change_rate(x[-slice_length:])\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        # percentiles on original and absolute values\n",
    "        for p in percentiles:\n",
    "            feature_dict[f'percentile_{p}'] = np.percentile(x, p)\n",
    "            feature_dict[f'abs_percentile_{p}'] = np.percentile(np.abs(x), p)\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        feature_dict['trend'] = add_trend_feature(x)\n",
    "        feature_dict['abs_trend'] = add_trend_feature(x, abs_values=True)\n",
    "        '''\n",
    "\n",
    "        #feature_dict['mad'] = x.mad()\n",
    "        feature_dict['kurt'] = x.kurtosis()\n",
    "        feature_dict['skew'] = x.skew()\n",
    "        #feature_dict['med'] = x.median()\n",
    "\n",
    "        '''\n",
    "        feature_dict['Hilbert_mean'] = np.abs(hilbert(x)).mean()\n",
    "\n",
    "        for hw in hann_windows:\n",
    "            feature_dict[f'Hann_window_mean_{hw}'] = (convolve(x, hann(hw), mode='same') / sum(hann(hw))).mean()\n",
    "\n",
    "        feature_dict['classic_sta_lta1_mean'] = classic_sta_lta(x, 500, 10000).mean()\n",
    "        feature_dict['classic_sta_lta2_mean'] = classic_sta_lta(x, 5000, 100000).mean()\n",
    "        feature_dict['classic_sta_lta3_mean'] = classic_sta_lta(x, 3333, 6666).mean()\n",
    "        feature_dict['classic_sta_lta4_mean'] = classic_sta_lta(x, 10000, 25000).mean()\n",
    "        feature_dict['classic_sta_lta5_mean'] = classic_sta_lta(x, 50, 1000).mean()\n",
    "        feature_dict['classic_sta_lta6_mean'] = classic_sta_lta(x, 100, 5000).mean()\n",
    "        feature_dict['classic_sta_lta7_mean'] = classic_sta_lta(x, 333, 666).mean()\n",
    "        feature_dict['classic_sta_lta8_mean'] = classic_sta_lta(x, 4000, 10000).mean()\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        # exponential rolling statistics\n",
    "        ewma = pd.Series.ewm\n",
    "        for s in spans:\n",
    "            feature_dict[f'exp_Moving_average_{s}_mean'] = (ewma(x, span=s).mean(skipna=True)).mean(skipna=True)\n",
    "            feature_dict[f'exp_Moving_average_{s}_std'] = (ewma(x, span=s).mean(skipna=True)).std(skipna=True)\n",
    "            feature_dict[f'exp_Moving_std_{s}_mean'] = (ewma(x, span=s).std(skipna=True)).mean(skipna=True)\n",
    "            feature_dict[f'exp_Moving_std_{s}_std'] = (ewma(x, span=s).std(skipna=True)).std(skipna=True)\n",
    "\n",
    "        feature_dict['iqr'] = np.subtract(*np.percentile(x, [75, 25]))\n",
    "        feature_dict['iqr1'] = np.subtract(*np.percentile(x, [95, 5]))\n",
    "        feature_dict['ave10'] = stats.trim_mean(x, 0.1)\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        for slice_length, threshold in product([50000, 100000, 150000],\n",
    "                                                     [5, 10, 20, 50, 100]):\n",
    "            feature_dict[f'count_big_{slice_length}_threshold_{threshold}'] = (np.abs(x[-slice_length:]) > threshold).sum()\n",
    "            feature_dict[f'count_big_{slice_length}_less_threshold_{threshold}'] = (np.abs(x[-slice_length:]) < threshold).sum()\n",
    "\n",
    "        # tfresh features take too long to calculate, so I comment them for now\n",
    "\n",
    "#         feature_dict['abs_energy'] = feature_calculators.abs_energy(x)\n",
    "#         feature_dict['abs_sum_of_changes'] = feature_calculators.absolute_sum_of_changes(x)\n",
    "#         feature_dict['count_above_mean'] = feature_calculators.count_above_mean(x)\n",
    "#         feature_dict['count_below_mean'] = feature_calculators.count_below_mean(x)\n",
    "#         feature_dict['mean_abs_change'] = feature_calculators.mean_abs_change(x)\n",
    "#         feature_dict['mean_change'] = feature_calculators.mean_change(x)\n",
    "#         feature_dict['var_larger_than_std_dev'] = feature_calculators.variance_larger_than_standard_deviation(x)\n",
    "        feature_dict['range_minf_m4000'] = feature_calculators.range_count(x, -np.inf, -4000)\n",
    "        feature_dict['range_p4000_pinf'] = feature_calculators.range_count(x, 4000, np.inf)\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        for i, j in zip(borders, borders[1:]):\n",
    "            feature_dict[f'range_{i}_{j}'] = feature_calculators.range_count(x, i, j)\n",
    "        '''\n",
    "\n",
    "#         feature_dict['ratio_unique_values'] = feature_calculators.ratio_value_number_to_time_series_length(x)\n",
    "#         feature_dict['first_loc_min'] = feature_calculators.first_location_of_minimum(x)\n",
    "#         feature_dict['first_loc_max'] = feature_calculators.first_location_of_maximum(x)\n",
    "#         feature_dict['last_loc_min'] = feature_calculators.last_location_of_minimum(x)\n",
    "#         feature_dict['last_loc_max'] = feature_calculators.last_location_of_maximum(x)\n",
    "\n",
    "#         for lag in lags:\n",
    "#             feature_dict[f'time_rev_asym_stat_{lag}'] = feature_calculators.time_reversal_asymmetry_statistic(x, lag)\n",
    "        ## for autocorr_lag in autocorr_lags:\n",
    "        ##    feature_dict[f'autocorrelation_{autocorr_lag}'] = feature_calculators.autocorrelation(x, autocorr_lag)\n",
    "        ##    #feature_dict[f'c3_{autocorr_lag}'] = feature_calculators.c3(x, autocorr_lag)\n",
    "\n",
    "#         for coeff, attr in product([1, 2, 3, 4, 5], ['real', 'imag', 'angle']):\n",
    "#             feature_dict[f'fft_{coeff}_{attr}'] = list(feature_calculators.fft_coefficient(x, [{'coeff': coeff, 'attr': attr}]))[0][1]\n",
    "\n",
    "#         feature_dict['long_strk_above_mean'] = feature_calculators.longest_strike_above_mean(x)\n",
    "#         feature_dict['long_strk_below_mean'] = feature_calculators.longest_strike_below_mean(x)\n",
    "#         feature_dict['cid_ce_0'] = feature_calculators.cid_ce(x, 0)\n",
    "#         feature_dict['cid_ce_1'] = feature_calculators.cid_ce(x, 1)\n",
    "        \n",
    "    \n",
    "        '''\n",
    "        for p in percentiles:\n",
    "            feature_dict[f'binned_entropy_{p}'] = feature_calculators.binned_entropy(x, p)\n",
    "\n",
    "        feature_dict['num_crossing_0'] = feature_calculators.number_crossing_m(x, 0)\n",
    "        '''\n",
    "        \n",
    "        ## for peak in peaks:\n",
    "        ##    feature_dict[f'num_peaks_{peak}'] = feature_calculators.number_peaks(x, peak)\n",
    "        \n",
    "        '''\n",
    "        for c in coefs:\n",
    "            feature_dict[f'spkt_welch_density_{c}'] = list(feature_calculators.spkt_welch_density(x, [{'coeff': c}]))[0][1]\n",
    "            feature_dict[f'time_rev_asym_stat_{c}'] = feature_calculators.time_reversal_asymmetry_statistic(x, c)  \n",
    "        '''\n",
    "        \n",
    "        # statistics on rolling windows of various sizes\n",
    "        for w in windows:\n",
    "            break\n",
    "            #pass\n",
    "            ## x_roll_std = x.rolling(w).std().dropna().values\n",
    "            ## x_roll_mean = x.rolling(w).mean().dropna().values\n",
    "            \n",
    "            \n",
    "            #feature_dict[f'ave_roll_std_{w}'] = x_roll_std.mean()\n",
    "            #feature_dict[f'std_roll_std_{w}'] = x_roll_std.std()\n",
    "            #feature_dict[f'max_roll_std_{w}'] = x_roll_std.max()\n",
    "            \n",
    "            ## feature_dict[f'min_roll_std_{w}'] = x_roll_std.min()\n",
    "            \n",
    "\n",
    "            ## for p in percentiles:\n",
    "            ##    feature_dict[f'percentile_roll_std_{p}_window_{w}'] = np.percentile(x_roll_std, p)\n",
    "            \n",
    "            '''\n",
    "            feature_dict[f'av_change_abs_roll_std_{w}'] = np.mean(np.diff(x_roll_std))\n",
    "            feature_dict[f'av_change_rate_roll_std_{w}'] = np.mean(np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n",
    "            feature_dict[f'abs_max_roll_std_{w}'] = np.abs(x_roll_std).max()\n",
    "\n",
    "            feature_dict[f'ave_roll_mean_{w}'] = x_roll_mean.mean()\n",
    "            feature_dict[f'std_roll_mean_{w}'] = x_roll_mean.std()\n",
    "            feature_dict[f'max_roll_mean_{w}'] = x_roll_mean.max()\n",
    "            feature_dict[f'min_roll_mean_{w}'] = x_roll_mean.min()\n",
    "            \n",
    "            for p in percentiles:\n",
    "                feature_dict[f'percentile_roll_mean_{p}_window_{w}'] = np.percentile(x_roll_mean, p)\n",
    "\n",
    "            feature_dict[f'av_change_abs_roll_mean_{w}'] = np.mean(np.diff(x_roll_mean))\n",
    "            feature_dict[f'av_change_rate_roll_mean_{w}'] = np.mean(np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n",
    "            feature_dict[f'abs_max_roll_mean_{w}'] = np.abs(x_roll_mean).max()    \n",
    "            '''\n",
    "\n",
    "        return feature_dict\n",
    "\n",
    "    def generate(self):\n",
    "        feature_list = []\n",
    "        res = Parallel(n_jobs=self.n_jobs,\n",
    "                       backend='threading')(delayed(self.get_features)(x, y, s)\n",
    "                                            for s, x, y in tqdm_notebook(self.read_chunks(), total=self.total_data))\n",
    "        #print(\"FeatureGenerator, generate, type(res)\", type(res))\n",
    "        #print(\"FeatureGenerator, generate, len(res)\", len(res))\n",
    "        for r in res:\n",
    "            feature_list.append(r)\n",
    "        #print(\"FeatureGenerator, generate, len(feature_list)\", len(feature_list))\n",
    "        return pd.DataFrame(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df, selection_list=[], condition=False):\n",
    "    if condition:\n",
    "        return [df.columns.get_loc(col) for col in df.columns if col in  pd.DatetimeIndex(selection_list)]\n",
    "    else:\n",
    "        return [df.columns.get_loc(col) for col in df.columns if col not in pd.DatetimeIndex(selection_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df, selection_list=[], condition=False):\n",
    "    if condition:\n",
    "        return [df.columns.get_loc(col) for col in df.columns if col in selection_list]\n",
    "    else:\n",
    "        return [df.columns.get_loc(col) for col in df.columns if col not in selection_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbefff88ce54b0f8fdf199a83fc2938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a83fde9370447c9042cf4bf2bc62c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2624), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_fg = FeatureGenerator(dtype='train', n_jobs=20, chunk_size=30000)\n",
    "\n",
    "\n",
    "training_data = training_fg.generate()\n",
    "\n",
    "test_fg = FeatureGenerator(dtype='test', n_jobs=20, chunk_size=30000)\n",
    "test_data = test_fg.generate()\n",
    "\n",
    "X = training_data.drop(['target', 'seg_id'], axis=1)\n",
    "X_test = test_data.drop(['target', 'seg_id'], axis=1)\n",
    "test_segs = test_data.seg_id\n",
    "y = training_data.target\n",
    "train_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extr_accel_0</th>\n",
       "      <th>extr_accel_1</th>\n",
       "      <th>extr_accel_2</th>\n",
       "      <th>extr_accel_3</th>\n",
       "      <th>extr_accel_4</th>\n",
       "      <th>extr_mean_0</th>\n",
       "      <th>extr_mean_1</th>\n",
       "      <th>extr_mean_2</th>\n",
       "      <th>extr_mean_3</th>\n",
       "      <th>extr_mean_4</th>\n",
       "      <th>...</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>rel_freq_0</th>\n",
       "      <th>rel_freq_1</th>\n",
       "      <th>rel_freq_2</th>\n",
       "      <th>rel_freq_3</th>\n",
       "      <th>rel_freq_4</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.777778</td>\n",
       "      <td>18.363636</td>\n",
       "      <td>24.428571</td>\n",
       "      <td>18.222222</td>\n",
       "      <td>1.887850</td>\n",
       "      <td>13.555556</td>\n",
       "      <td>11.454545</td>\n",
       "      <td>15.714286</td>\n",
       "      <td>-22.111111</td>\n",
       "      <td>5.429907</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>5.011700</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>-0.129510</td>\n",
       "      <td>7.367779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.750000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.917457</td>\n",
       "      <td>4.881322</td>\n",
       "      <td>4.889489</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.846700</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.070504</td>\n",
       "      <td>4.630081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.555556</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>5.189255</td>\n",
       "      <td>5.190115</td>\n",
       "      <td>5.184966</td>\n",
       "      <td>5.188974</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.132100</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.024047</td>\n",
       "      <td>4.939919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.880000</td>\n",
       "      <td>2.769231</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>6.653846</td>\n",
       "      <td>3.148148</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.922000</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>3.947113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.070764</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>5.120567</td>\n",
       "      <td>4.750466</td>\n",
       "      <td>4.401866</td>\n",
       "      <td>5.602273</td>\n",
       "      <td>4.308824</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.508067</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.047550</td>\n",
       "      <td>3.766104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   extr_accel_0  extr_accel_1  extr_accel_2  extr_accel_3  extr_accel_4  \\\n",
       "0     21.777778     18.363636     24.428571     18.222222      1.887850   \n",
       "1      8.750000      7.500000      0.004669      0.007467      0.007361   \n",
       "2     11.555556      0.004831      0.004381      0.004831      0.004917   \n",
       "3      6.800000      7.875000      2.880000      2.769231      2.666667   \n",
       "4      0.297872      0.070764      0.002079      0.465909      0.573529   \n",
       "\n",
       "   extr_mean_0  extr_mean_1  extr_mean_2  extr_mean_3  extr_mean_4    ...     \\\n",
       "0    13.555556    11.454545    15.714286   -22.111111     5.429907    ...      \n",
       "1     8.625000     7.200000     4.917457     4.881322     4.889489    ...      \n",
       "2     2.777778     5.189255     5.190115     5.184966     5.188974    ...      \n",
       "3     9.800000    10.750000     2.920000     6.653846     3.148148    ...      \n",
       "4     5.120567     4.750466     4.401866     5.602273     4.308824    ...      \n",
       "\n",
       "     max      mean   min  rel_freq_0  rel_freq_1  rel_freq_2  rel_freq_3  \\\n",
       "0  104.0  5.011700 -98.0    0.001516    0.001949    0.001328    0.001094   \n",
       "1   40.0  4.846700 -35.0    0.001546    0.001259    0.001963    0.001066   \n",
       "2   52.0  5.132100 -56.0    0.001701    0.001442    0.001192    0.002355   \n",
       "3   40.0  4.922000 -32.0    0.001388    0.001139    0.001747    0.000981   \n",
       "4   26.0  4.508067 -16.0    0.001359    0.001104    0.000924    0.001852   \n",
       "\n",
       "   rel_freq_4      skew       std  \n",
       "0    0.002663 -0.129510  7.367779  \n",
       "1    0.002614  0.070504  4.630081  \n",
       "2    0.001067  0.024047  4.939919  \n",
       "3    0.002424  0.018361  3.947113  \n",
       "4    0.002671  0.047550  3.766104  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_dict = {}\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().any():\n",
    "        print(col)\n",
    "        mean_value = X.loc[X[col] != -np.inf, col].mean()\n",
    "        X.loc[X[col] == -np.inf, col] = mean_value\n",
    "        X[col] = X[col].fillna(mean_value)\n",
    "        means_dict[col] = mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_test.columns:\n",
    "    if X_test[col].isnull().any():\n",
    "        X_test.loc[X_test[col] == -np.inf, col] = means_dict[col]\n",
    "        X_test[col] = X_test[col].fillna(means_dict[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_columns = X.columns\n",
    "\n",
    "X[train_columns] = scaler.fit_transform(X[train_columns])\n",
    "X_test[train_columns] = scaler.transform(X_test[train_columns])\n",
    "test_X = X_test\n",
    "\n",
    "print(type(X))\n",
    "print(type(X_test))\n",
    "print(type(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extr_accel_0</th>\n",
       "      <th>extr_accel_1</th>\n",
       "      <th>extr_accel_2</th>\n",
       "      <th>extr_accel_3</th>\n",
       "      <th>extr_accel_4</th>\n",
       "      <th>extr_mean_0</th>\n",
       "      <th>extr_mean_1</th>\n",
       "      <th>extr_mean_2</th>\n",
       "      <th>extr_mean_3</th>\n",
       "      <th>extr_mean_4</th>\n",
       "      <th>...</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>rel_freq_0</th>\n",
       "      <th>rel_freq_1</th>\n",
       "      <th>rel_freq_2</th>\n",
       "      <th>rel_freq_3</th>\n",
       "      <th>rel_freq_4</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988970</td>\n",
       "      <td>0.718051</td>\n",
       "      <td>1.273306</td>\n",
       "      <td>0.937130</td>\n",
       "      <td>-0.321056</td>\n",
       "      <td>0.663726</td>\n",
       "      <td>0.453977</td>\n",
       "      <td>0.648854</td>\n",
       "      <td>-1.578266</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143610</td>\n",
       "      <td>1.731440</td>\n",
       "      <td>-0.187763</td>\n",
       "      <td>0.585335</td>\n",
       "      <td>1.692747</td>\n",
       "      <td>-0.145393</td>\n",
       "      <td>-0.589257</td>\n",
       "      <td>0.932536</td>\n",
       "      <td>-0.574439</td>\n",
       "      <td>0.157014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005752</td>\n",
       "      <td>-0.065023</td>\n",
       "      <td>-0.571063</td>\n",
       "      <td>-0.521407</td>\n",
       "      <td>-0.483163</td>\n",
       "      <td>0.259964</td>\n",
       "      <td>0.139379</td>\n",
       "      <td>-0.022595</td>\n",
       "      <td>-0.012324</td>\n",
       "      <td>-0.003651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329195</td>\n",
       "      <td>1.151043</td>\n",
       "      <td>0.290751</td>\n",
       "      <td>0.663968</td>\n",
       "      <td>-0.158424</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>-0.630294</td>\n",
       "      <td>0.884871</td>\n",
       "      <td>-0.011521</td>\n",
       "      <td>-0.149899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217490</td>\n",
       "      <td>-0.605291</td>\n",
       "      <td>-0.571085</td>\n",
       "      <td>-0.521618</td>\n",
       "      <td>-0.483374</td>\n",
       "      <td>-0.218862</td>\n",
       "      <td>-0.009304</td>\n",
       "      <td>-0.005639</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.016438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240544</td>\n",
       "      <td>2.154953</td>\n",
       "      <td>0.131246</td>\n",
       "      <td>1.064304</td>\n",
       "      <td>0.332338</td>\n",
       "      <td>-0.386772</td>\n",
       "      <td>1.313055</td>\n",
       "      <td>-0.628703</td>\n",
       "      <td>-0.142269</td>\n",
       "      <td>-0.115164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.141416</td>\n",
       "      <td>-0.037993</td>\n",
       "      <td>-0.353933</td>\n",
       "      <td>-0.300260</td>\n",
       "      <td>-0.253919</td>\n",
       "      <td>0.356185</td>\n",
       "      <td>0.401880</td>\n",
       "      <td>-0.146816</td>\n",
       "      <td>0.090507</td>\n",
       "      <td>-0.120460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329195</td>\n",
       "      <td>1.415915</td>\n",
       "      <td>0.313537</td>\n",
       "      <td>0.255240</td>\n",
       "      <td>-0.482048</td>\n",
       "      <td>0.591956</td>\n",
       "      <td>-0.759129</td>\n",
       "      <td>0.698914</td>\n",
       "      <td>-0.158271</td>\n",
       "      <td>-0.226464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.632138</td>\n",
       "      <td>-0.600538</td>\n",
       "      <td>-0.571258</td>\n",
       "      <td>-0.484697</td>\n",
       "      <td>-0.434357</td>\n",
       "      <td>-0.027012</td>\n",
       "      <td>-0.041749</td>\n",
       "      <td>-0.054660</td>\n",
       "      <td>0.029501</td>\n",
       "      <td>-0.042602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.432621</td>\n",
       "      <td>-0.040117</td>\n",
       "      <td>0.435065</td>\n",
       "      <td>0.180286</td>\n",
       "      <td>-0.576587</td>\n",
       "      <td>-0.859040</td>\n",
       "      <td>0.553917</td>\n",
       "      <td>0.940487</td>\n",
       "      <td>-0.076123</td>\n",
       "      <td>-0.246756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   extr_accel_0  extr_accel_1  extr_accel_2  extr_accel_3  extr_accel_4  \\\n",
       "0      0.988970      0.718051      1.273306      0.937130     -0.321056   \n",
       "1      0.005752     -0.065023     -0.571063     -0.521407     -0.483163   \n",
       "2      0.217490     -0.605291     -0.571085     -0.521618     -0.483374   \n",
       "3     -0.141416     -0.037993     -0.353933     -0.300260     -0.253919   \n",
       "4     -0.632138     -0.600538     -0.571258     -0.484697     -0.434357   \n",
       "\n",
       "   extr_mean_0  extr_mean_1  extr_mean_2  extr_mean_3  extr_mean_4    ...     \\\n",
       "0     0.663726     0.453977     0.648854    -1.578266     0.032600    ...      \n",
       "1     0.259964     0.139379    -0.022595    -0.012324    -0.003651    ...      \n",
       "2    -0.218862    -0.009304    -0.005639     0.005291     0.016438    ...      \n",
       "3     0.356185     0.401880    -0.146816     0.090507    -0.120460    ...      \n",
       "4    -0.027012    -0.041749    -0.054660     0.029501    -0.042602    ...      \n",
       "\n",
       "        max      mean       min  rel_freq_0  rel_freq_1  rel_freq_2  \\\n",
       "0  0.143610  1.731440 -0.187763    0.585335    1.692747   -0.145393   \n",
       "1 -0.329195  1.151043  0.290751    0.663968   -0.158424    0.973843   \n",
       "2 -0.240544  2.154953  0.131246    1.064304    0.332338   -0.386772   \n",
       "3 -0.329195  1.415915  0.313537    0.255240   -0.482048    0.591956   \n",
       "4 -0.432621 -0.040117  0.435065    0.180286   -0.576587   -0.859040   \n",
       "\n",
       "   rel_freq_3  rel_freq_4      skew       std  \n",
       "0   -0.589257    0.932536 -0.574439  0.157014  \n",
       "1   -0.630294    0.884871 -0.011521 -0.149899  \n",
       "2    1.313055   -0.628703 -0.142269 -0.115164  \n",
       "3   -0.759129    0.698914 -0.158271 -0.226464  \n",
       "4    0.553917    0.940487 -0.076123 -0.246756  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select_columns(X, selection_list=['extr_accel_%i' % i for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, holdout_idx, _, _ = train_test_split(\n",
    "    X.index,\n",
    "    y.index,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X.iloc[train_idx]\n",
    "holdout_X = X.iloc[holdout_X_idx]\n",
    "train_y = y.iloc[train_idx]\n",
    "holdout_y = y.iloc[holdout_X_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([20338, 7490, 705, 15580, 3569], dtype='int64')\n",
      "Int64Index([20338, 7490, 705, 15580, 3569], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(train_idx[:5])\n",
    "#print(train_y_idx[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, params=None, folds=folds, model_type='lgb', plot_feature_importance=False, model=None):\n",
    "\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    model = None\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[train_index], X[valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            #model = lgb.LGBMRegressor(**params, n_estimators = 50000, n_jobs = -1)\n",
    "            model = lgb.LGBMRegressor(**params, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='mae',\n",
    "                    verbose=10000, early_stopping_rounds=600)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = mean_absolute_error(y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. MAE: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric='MAE', **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(mean_absolute_error(y_valid, y_pred_valid))\n",
    "\n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance, model\n",
    "        return oof, prediction, scores, model\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction, scores, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_filtered_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_X)\n",
    "type(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat Jun  1 19:17:00 2019\n",
      "[0]\ttrain-mae:5.06189\tvalid_data-mae:5.03256\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 600 rounds.\n",
      "[500]\ttrain-mae:1.67475\tvalid_data-mae:2.30048\n",
      "Stopping. Best iteration:\n",
      "[94]\ttrain-mae:2.07649\tvalid_data-mae:2.27365\n",
      "\n",
      "Fold 1 started at Sat Jun  1 19:17:05 2019\n",
      "[0]\ttrain-mae:5.03309\tvalid_data-mae:5.15163\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 600 rounds.\n",
      "[500]\ttrain-mae:1.67568\tvalid_data-mae:2.24867\n",
      "Stopping. Best iteration:\n",
      "[140]\ttrain-mae:2.02986\tvalid_data-mae:2.24216\n",
      "\n",
      "Fold 2 started at Sat Jun  1 19:17:11 2019\n",
      "[0]\ttrain-mae:5.06879\tvalid_data-mae:5.00458\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 600 rounds.\n",
      "[500]\ttrain-mae:1.66485\tvalid_data-mae:2.30025\n",
      "Stopping. Best iteration:\n",
      "[82]\ttrain-mae:2.09996\tvalid_data-mae:2.26506\n",
      "\n",
      "Fold 3 started at Sat Jun  1 19:17:15 2019\n",
      "[0]\ttrain-mae:5.05969\tvalid_data-mae:5.04221\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 600 rounds.\n",
      "[500]\ttrain-mae:1.69508\tvalid_data-mae:2.26251\n",
      "Stopping. Best iteration:\n",
      "[89]\ttrain-mae:2.09908\tvalid_data-mae:2.22963\n",
      "\n",
      "Fold 4 started at Sat Jun  1 19:17:20 2019\n",
      "[0]\ttrain-mae:5.05721\tvalid_data-mae:5.05455\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 600 rounds.\n",
      "[500]\ttrain-mae:1.66786\tvalid_data-mae:2.31008\n",
      "Stopping. Best iteration:\n",
      "[98]\ttrain-mae:2.06657\tvalid_data-mae:2.28306\n",
      "\n",
      "CV mean score: 2.2587, std: 0.0199.\n",
      "CPU times: user 4min 4s, sys: 440 ms, total: 4min 5s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_params = {\n",
    "    'eta': 0.03,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.85,\n",
    "    #'colsample_bytree': 0.8,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'silent': True,\n",
    "    'nthread': 10,\n",
    "    'n_estimators': 4000\n",
    "}\n",
    "oof_xgb, prediction_xgb, scores, xgb_model = train_model(\n",
    "    train_X[train_X.columns.drop(xgb_filtered_columns)],\n",
    "    test_X[test_X.columns.drop(xgb_filtered_columns)],\n",
    "    train_y,\n",
    "    params=xgb_params,\n",
    "    model_type='xgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(test_X))\n",
    "print(type(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_filtered_columns = []\n",
    "#lgb_filtered_columns_np = select_columns(X, lgb_filtered_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat Jun  1 19:20:17 2019\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1986]\ttraining's l1: 1.9665\tvalid_1's l1: 2.29132\n",
      "Fold 1 started at Sat Jun  1 19:20:21 2019\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1334]\ttraining's l1: 2.0383\tvalid_1's l1: 2.25179\n",
      "Fold 2 started at Sat Jun  1 19:20:24 2019\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2149]\ttraining's l1: 1.94794\tvalid_1's l1: 2.28445\n",
      "Fold 3 started at Sat Jun  1 19:20:28 2019\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1738]\ttraining's l1: 2.004\tvalid_1's l1: 2.24556\n",
      "Fold 4 started at Sat Jun  1 19:20:31 2019\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1438]\ttraining's l1: 2.01638\tvalid_1's l1: 2.30449\n",
      "CV mean score: 2.2755, std: 0.0229.\n",
      "CPU times: user 2min 50s, sys: 1.03 s, total: 2min 51s\n",
      "Wall time: 18.7 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "params = {'num_leaves': 128,\n",
    "          'min_data_in_leaf': 79,\n",
    "          'objective': 'gamma',\n",
    "          'max_depth': 6,\n",
    "          'learning_rate': 0.01,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"bagging_freq\": 5,\n",
    "          \"bagging_fraction\": 0.8126672064208567,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.1302650970728192,\n",
    "          'reg_lambda': 0.3603427518866501,\n",
    "          'feature_fraction': 0.2,\n",
    "          'n_estimators': 4000\n",
    "         }\n",
    "oof_lgb, prediction_lgb, feature_importance, lgb_model = train_model(\n",
    "    train_X[train_X.columns.drop(lgb_filtered_columns)],\n",
    "    test_X[test_X.columns.drop(lgb_filtered_columns)],    \n",
    "    train_y,\n",
    "    params=params,\n",
    "    model_type='lgb',\n",
    "    plot_feature_importance=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 50\n",
    "call_ES = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=patience,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    #restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "cb = [ModelCheckpoint(\"model.hdf5\", save_best_only=True, period=3)]\n",
    "def create_model(input_dim=10):\n",
    "\n",
    "    # The LSTM architecture\n",
    "    model = Sequential()\n",
    "    # First LSTM layer with Dropout regularisation\n",
    "    model.add(CuDNNLSTM(units=50, return_sequences=True, input_shape=(None, input_dim)))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Second LSTM layer\n",
    "    model.add(CuDNNLSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Third LSTM layer\n",
    "    model.add(CuDNNLSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Fourth LSTM layer\n",
    "    model.add(CuDNNLSTM(units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    # The output layer\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    # Compiling the RNN\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer='rmsprop', loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_filtered_columns = []\n",
    "#nn_filtered_columns = []\n",
    "#nn_filtered_columns_np = select_columns(X, nn_filtered_columns)\n",
    "\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "\n",
    "NN_oof = np.zeros(len(train_X))\n",
    "train_score = []\n",
    "fold_idxs = []\n",
    "\n",
    "NN_predictions = np.zeros(len(test_X))\n",
    "\n",
    "def train_nn(train_X, test_X, train_columns):\n",
    "    \n",
    "    num_of_features = train_X.shape[-1]\n",
    "    model = None\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_X, train_y.values)):\n",
    "        strLog = \"fold {}\".format(fold_)\n",
    "        print(strLog)\n",
    "        fold_idxs.append(val_idx)\n",
    "    \n",
    "        X_tr, X_val = train_X[train_columns].iloc[trn_idx], train_X[train_columns].iloc[val_idx]\n",
    "        #X_tr, X_val = train_X[trn_idx], train_X[val_idx]\n",
    "        X_tr = (X_tr.values).reshape(len(X_tr), 1, num_of_features)\n",
    "        X_val = (X_val.values).reshape(len(X_val), 1, num_of_features)\n",
    "        y_tr, y_val = train_y[trn_idx], train_y[val_idx]\n",
    "        model = create_model(num_of_features)\n",
    "        model.fit(X_tr, y_tr, epochs=50, batch_size=32, verbose=2, callbacks=[call_ES,], validation_data=[X_val, y_val]) #\n",
    "    \n",
    "        NN_oof[val_idx] = model.predict(X_val)[:,0]\n",
    "    \n",
    "        #NN_predictions += model.predict(test_X[train_columns])[:,0] / folds.n_splits\n",
    "        test_X = (test_X.values).reshape(len(test_X), 1, num_of_features)\n",
    "        NN_predictions += model.predict(test_X)[:,0] / folds.n_splits\n",
    "        history = model.history.history\n",
    "        tr_loss = history[\"loss\"]\n",
    "        val_loss = history[\"val_loss\"]\n",
    "        print(f\"loss: {tr_loss[-patience]:.3f} | val_loss: {val_loss[-patience]:.3f} | diff: {val_loss[-patience]-tr_loss[-patience]:.3f}\")\n",
    "        train_score.append(tr_loss[-patience])\n",
    "        #     break\n",
    "    \n",
    "        cv_score = mean_absolute_error(train_y, NN_oof)\n",
    "        print(f\"After {n_fold} test_CV = {cv_score:.3f} | train_CV = {np.mean(train_score):.3f} | {cv_score-np.mean(train_score):.3f}\", end=\" \")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "WARNING:tensorflow:From /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, None, 50)          15600     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, None, 50)          20400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, None, 50)          20400     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 50)                20400     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 76,851\n",
      "Trainable params: 76,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 13421 samples, validate on 3356 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py:517) with these attrs: [dropout=0, seed=5944, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py:517) ]]\n\nCaused by op 'cu_dnnlstm_1/CudnnRNN', defined at:\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2907, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-78-67967e312284>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', '\\n\\'\\'\\'\\nn_fold = 5\\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\\n\\nNN_oof = np.zeros(len(train_X))\\ntrain_score = []\\nfold_idxs = []\\n\\nNN_predictions = np.zeros(len(test_X))\\n\\nnum_of_features = train_X.shape[-1]\\n\\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train_X, train_y.values)):\\n    strLog = \"fold {}\".format(fold_)\\n    print(strLog)\\n    fold_idxs.append(val_idx)\\n    \\n    ## X_tr, X_val = train_X[train_columns].iloc[trn_idx], train_X[train_columns].iloc[val_idx]\\n    X_tr, X_val = train_X[trn_idx], train_X[val_idx]\\n    X_tr = X_tr.reshape(len(X_tr), 1, num_of_features)\\n    X_val = X_val.reshape(len(X_val), 1, num_of_features)\\n    y_tr, y_val = train_y[trn_idx], train_y[val_idx]\\n    model = create_model(num_of_features)\\n    model.fit(X_tr, y_tr, epochs=50, batch_size=32, verbose=2, callbacks=[call_ES,], validation_data=[X_val, y_val]) #\\n    \\n    NN_oof[val_idx] = model.predict(X_val)[:,0]\\n    \\n    #NN_predictions += model.predict(test_X[train_columns])[:,0] / folds.n_splits\\n    test_X = test_X.reshape(len(test_X), 1, num_of_features)\\n    NN_predictions += model.predict(test_X)[:,0] / folds.n_splits\\n    history = model.history.history\\n    tr_loss = history[\"loss\"]\\n    val_loss = history[\"val_loss\"]\\n    print(f\"loss: {tr_loss[-patience]:.3f} | val_loss: {val_loss[-patience]:.3f} | diff: {val_loss[-patience]-tr_loss[-patience]:.3f}\")\\n    train_score.append(tr_loss[-patience])\\n#     break\\n    \\ncv_score = mean_absolute_error(train_y, NN_oof)\\nprint(f\"After {n_fold} test_CV = {cv_score:.3f} | train_CV = {np.mean(train_score):.3f} | {cv_score-np.mean(train_score):.3f}\", end=\" \")\\n\\'\\'\\'\\nnn_model = train_nn(train_X, test_X, train_X.columns.drop(nn_filtered_columns))')\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2167, in run_cell_magic\n    result = fn(magic_arg_s, cell)\n  File \"<decorator-gen-62>\", line 2, in time\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 1237, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 42, in <module>\n  File \"<ipython-input-77-def88f3065e8>\", line 28, in train_nn\n    model = create_model(num_of_features)\n  File \"<ipython-input-69-7639f9149d25>\", line 8, in create_model\n    model.add(CuDNNLSTM(units=50, return_sequences=True, input_shape=(None, input_dim)))\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/sequential.py\", line 165, in add\n    layer(x)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 532, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\", line 517, in _process_batch\n    is_training=True)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1636, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1527, in __call__\n    seed=self._seed)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1014, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\", line 142, in cudnn_rnn\n    seed2=seed2, is_training=is_training, name=name)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py:517) with these attrs: [dropout=0, seed=5944, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py:517) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by {{node cu_dnnlstm_1/CudnnRNN}}with these attrs: [dropout=0, seed=5944, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[{{node cu_dnnlstm_1/CudnnRNN}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-def88f3065e8>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(train_X, test_X, train_columns)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcall_ES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mNN_oof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py:517) with these attrs: [dropout=0, seed=5944, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py:517) ]]\n\nCaused by op 'cu_dnnlstm_1/CudnnRNN', defined at:\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2907, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-78-67967e312284>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', '\\n\\'\\'\\'\\nn_fold = 5\\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\\n\\nNN_oof = np.zeros(len(train_X))\\ntrain_score = []\\nfold_idxs = []\\n\\nNN_predictions = np.zeros(len(test_X))\\n\\nnum_of_features = train_X.shape[-1]\\n\\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train_X, train_y.values)):\\n    strLog = \"fold {}\".format(fold_)\\n    print(strLog)\\n    fold_idxs.append(val_idx)\\n    \\n    ## X_tr, X_val = train_X[train_columns].iloc[trn_idx], train_X[train_columns].iloc[val_idx]\\n    X_tr, X_val = train_X[trn_idx], train_X[val_idx]\\n    X_tr = X_tr.reshape(len(X_tr), 1, num_of_features)\\n    X_val = X_val.reshape(len(X_val), 1, num_of_features)\\n    y_tr, y_val = train_y[trn_idx], train_y[val_idx]\\n    model = create_model(num_of_features)\\n    model.fit(X_tr, y_tr, epochs=50, batch_size=32, verbose=2, callbacks=[call_ES,], validation_data=[X_val, y_val]) #\\n    \\n    NN_oof[val_idx] = model.predict(X_val)[:,0]\\n    \\n    #NN_predictions += model.predict(test_X[train_columns])[:,0] / folds.n_splits\\n    test_X = test_X.reshape(len(test_X), 1, num_of_features)\\n    NN_predictions += model.predict(test_X)[:,0] / folds.n_splits\\n    history = model.history.history\\n    tr_loss = history[\"loss\"]\\n    val_loss = history[\"val_loss\"]\\n    print(f\"loss: {tr_loss[-patience]:.3f} | val_loss: {val_loss[-patience]:.3f} | diff: {val_loss[-patience]-tr_loss[-patience]:.3f}\")\\n    train_score.append(tr_loss[-patience])\\n#     break\\n    \\ncv_score = mean_absolute_error(train_y, NN_oof)\\nprint(f\"After {n_fold} test_CV = {cv_score:.3f} | train_CV = {np.mean(train_score):.3f} | {cv_score-np.mean(train_score):.3f}\", end=\" \")\\n\\'\\'\\'\\nnn_model = train_nn(train_X, test_X, train_X.columns.drop(nn_filtered_columns))')\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2167, in run_cell_magic\n    result = fn(magic_arg_s, cell)\n  File \"<decorator-gen-62>\", line 2, in time\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 1237, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 42, in <module>\n  File \"<ipython-input-77-def88f3065e8>\", line 28, in train_nn\n    model = create_model(num_of_features)\n  File \"<ipython-input-69-7639f9149d25>\", line 8, in create_model\n    model.add(CuDNNLSTM(units=50, return_sequences=True, input_shape=(None, input_dim)))\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/sequential.py\", line 165, in add\n    layer(x)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 532, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\", line 517, in _process_batch\n    is_training=True)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1636, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1527, in __call__\n    seed=self._seed)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1014, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\", line 142, in cudnn_rnn\n    seed2=seed2, is_training=is_training, name=name)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py:517) with these attrs: [dropout=0, seed=5944, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at /home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py:517) ]]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "'''\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "\n",
    "NN_oof = np.zeros(len(train_X))\n",
    "train_score = []\n",
    "fold_idxs = []\n",
    "\n",
    "NN_predictions = np.zeros(len(test_X))\n",
    "\n",
    "num_of_features = train_X.shape[-1]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_X, train_y.values)):\n",
    "    strLog = \"fold {}\".format(fold_)\n",
    "    print(strLog)\n",
    "    fold_idxs.append(val_idx)\n",
    "    \n",
    "    ## X_tr, X_val = train_X[train_columns].iloc[trn_idx], train_X[train_columns].iloc[val_idx]\n",
    "    X_tr, X_val = train_X[trn_idx], train_X[val_idx]\n",
    "    X_tr = X_tr.reshape(len(X_tr), 1, num_of_features)\n",
    "    X_val = X_val.reshape(len(X_val), 1, num_of_features)\n",
    "    y_tr, y_val = train_y[trn_idx], train_y[val_idx]\n",
    "    model = create_model(num_of_features)\n",
    "    model.fit(X_tr, y_tr, epochs=50, batch_size=32, verbose=2, callbacks=[call_ES,], validation_data=[X_val, y_val]) #\n",
    "    \n",
    "    NN_oof[val_idx] = model.predict(X_val)[:,0]\n",
    "    \n",
    "    #NN_predictions += model.predict(test_X[train_columns])[:,0] / folds.n_splits\n",
    "    test_X = test_X.reshape(len(test_X), 1, num_of_features)\n",
    "    NN_predictions += model.predict(test_X)[:,0] / folds.n_splits\n",
    "    history = model.history.history\n",
    "    tr_loss = history[\"loss\"]\n",
    "    val_loss = history[\"val_loss\"]\n",
    "    print(f\"loss: {tr_loss[-patience]:.3f} | val_loss: {val_loss[-patience]:.3f} | diff: {val_loss[-patience]-tr_loss[-patience]:.3f}\")\n",
    "    train_score.append(tr_loss[-patience])\n",
    "#     break\n",
    "    \n",
    "cv_score = mean_absolute_error(train_y, NN_oof)\n",
    "print(f\"After {n_fold} test_CV = {cv_score:.3f} | train_CV = {np.mean(train_score):.3f} | {cv_score-np.mean(train_score):.3f}\", end=\" \")\n",
    "'''\n",
    "nn_model = train_nn(train_X, test_X, train_X.columns.drop(nn_filtered_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-25ac490a2618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_holdout_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlgb_holdout_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnn_holdout_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xgb holdout prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_hodlout_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lgb holdout prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb_hodlout_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_holdout_pred = xgb_model.predict(holdout_X)\n",
    "lgb_holdout_pred = lgb_model.predict(holdout_X)\n",
    "nn_holdout_pred = nn_model.predict(holdout_X)\n",
    "print(\"xgb holdout prediction:\", mean_absolute_error(holdout_y, xgb_hodlout_pred))\n",
    "print(\"lgb holdout prediction:\", mean_absolute_error(holdout_y, lgb_hodlout_pred))\n",
    "print(\"nn holdout prediction:\", mean_absolute_error(holdout_y, nn_hodlout_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_prediction = (xgb_holdout_pred + lgb_holdout_pred + nn_holdout_pred) / 3\n",
    "print(\"holdout prediction MAE:\", mean_absolute_error(holdout_y, holdout_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(datetime.date.today())\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "submission[\"time_to_failure\"] = (prediction_xgb + prediction_lgb + NN_predictions) / 3\n",
    "submission.to_csv(f'xgb_lgb_nn_{i}_{today}_submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
