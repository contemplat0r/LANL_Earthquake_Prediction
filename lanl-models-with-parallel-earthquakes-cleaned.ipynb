{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(\n",
    "        df,\n",
    "        first_index=None,\n",
    "        last_index=None,\n",
    "        sample_size=150000,\n",
    "        holdout_size=50000,\n",
    "        smootch_windows_size = (3, 5, 7)\n",
    "    ):\n",
    "    \n",
    "    if first_index == None or last_index == None:\n",
    "        first_index = df.index.min()\n",
    "        last_index = df.index.max()\n",
    "    sample_indexes = np.random.randint(first_index, last_index, sample_size)\n",
    "    sample_indexes.sort()\n",
    "    print(\"sample_indexes.shape:\", sample_indexes.shape)    \n",
    "    smootch_feature_names = ['smootch_mean_ws_{}'.format(window_size) for window_size in smootch_windows_size]\n",
    "    #half_windows_size = [ws // 2 for ws in smootch_windows_size]\n",
    "\n",
    "    acoustic_data_series = df['acoustic_data']\n",
    "    \n",
    "    sample_df = df.iloc[sample_indexes]\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"just after create sample_df, sample_df.shape[0]:\", sample_df.shape[0])\n",
    "    \n",
    "    #for feature_name in smootch_feature_names:\n",
    "    #    sample_df[feature_name] = 0\n",
    "    begin_smootch_features_value = []\n",
    "    end_smootch_features_value = []\n",
    "    \n",
    "    #sample_indexes_set = set(sample_indexes)\n",
    "    begin_indexes_set = set()\n",
    "    end_indexes_set = set()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(\"sample_df.shape[0] just before main loop:\", sample_df.shape[0])\n",
    "    sample_df_len = sample_df.shape[0]\n",
    "    for window_size, feature_name in zip(smootch_windows_size, smootch_feature_names):\n",
    "        \n",
    "        feature_values_list = list(range(sample_size))\n",
    "        \n",
    "        half_window_size = window_size // 2\n",
    "        begin_indexes = sample_indexes[:half_window_size]        \n",
    "        sample_begin_indexes = sample_indexes[:half_window_size]\n",
    "        full_data_begin_indexes = df.index[:half_window_size].tolist()\n",
    "\n",
    "        in_window_begin_indexes = [idx for idx in sample_begin_indexes if idx in full_data_begin_indexes]\n",
    "        \n",
    "        sample_end_indexes = sample_indexes[-half_window_size:]\n",
    "\n",
    "        full_data_end_indexes = df.index[-half_window_size:].tolist()\n",
    "        \n",
    "        in_window_end_indexes = [idx for idx in sample_end_indexes if idx in full_data_end_indexes]\n",
    "        begin_indexes = begin_indexes[begin_indexes <= half_window_size]\n",
    "        \n",
    "        end_indexes = sample_indexes[-half_window_size:]\n",
    "        \n",
    "        if in_window_begin_indexes:\n",
    "            begin_indexes_set.union(set(in_window_begin_indexes))\n",
    "            for i, b_idx in enumerate(in_window_begin_indexes):\n",
    "                #sample_df[feature_name].iloc[b_idx] = df[b_idx]['acoustic_data'] - df.iloc[first_index:first_index + window_size]['acoustic_data'].mean()\n",
    "                feature_values_list[i] = df[b_idx]['acoustic_data'] - df.iloc[first_index:first_index + window_size]['acoustic_data'].mean()\n",
    "        if in_window_end_indexes:\n",
    "            end_indexes_set.union(set(in_window_end_indexes))\n",
    "            for i, e_idx in enumerat(in_window_end_indexes):\n",
    "                #sample_df[feature_name].iloc[e_idx] = df[e_idx]['acoustic_data'] - df.iloc[last_index - window_size:]['acoustic_data'].mean()\n",
    "                feature_values_list[-i] = df[e_idx]['acoustic_data'] - df.iloc[last_index - window_size:]['acoustic_data'].mean()\n",
    "        print(\"in main loop, sample_df.shape:\", sample_df.shape)\n",
    "        slice_begin = len(begin_indexes_set)\n",
    "        slice_end = sample_df_len - len(end_indexes_set)\n",
    "        for i in range(sample_df_len)[slice_begin:slice_end]:\n",
    "            sample_idx = sample_indexes[i]\n",
    "            feature_values_list[i] = acoustic_data_series.iloc[sample_idx - half_window_size:sample_idx + half_window_size].mean()\n",
    "        print(\"sample_df.shape[0] before assign feature_values_list:\", sample_df.shape[0])\n",
    "        print(\"len(feature_values_list):\", len(feature_values_list))\n",
    "        sample_df[feature_name] = feature_values_list\n",
    "    holdout_indexes = np.random.randint(0, sample_df.shape[0], holdout_size)\n",
    "    print(\"sample_df.index:\\n\", sample_df.index.tolist())\n",
    "    print(\"holdout_indexes:\\n\", holdout_indexes)\n",
    "    #train_indexes = np.array(sample_df.index)\n",
    "    holdout_df = sample_df.iloc[holdout_indexes]\n",
    "    holdout_df.reset_index(inplace=True)\n",
    "    holdout_df.drop(columns=['index'], inplace=True)\n",
    "    sample_df_indexes_set = set(sample_df.index)\n",
    "    train_indexes = sorted(tuple(sample_df_indexes_set.difference(set(holdout_indexes))))\n",
    "    print(\"train_indexes:\\n\", train_indexes)\n",
    "    sample_df = sample_df.iloc[train_indexes]\n",
    "    sample_df.reset_index(inplace=True)\n",
    "    sample_df.drop(columns=['index'], inplace=True)\n",
    "    print(\"Full calculation feature value time (with slicing) {} min:\".format((time.time() - start_time) / 60))\n",
    "    return sample_df, holdout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_margin_indexes =[\n",
    "    5656573,\n",
    "    50085877,\n",
    "    104677355,\n",
    "    138772452,\n",
    "    187641819,\n",
    "    218652629,\n",
    "    245829584,\n",
    "    307838916,\n",
    "    338276286,\n",
    "    375377847,\n",
    "    419368879,\n",
    "    461811622,\n",
    "    495800224,\n",
    "    528777114,\n",
    "    585568143,\n",
    "    621985672\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes_length = [earthquake_margin_indexes[i + 1] - earthquake_margin_indexes[i] for i in range(len(earthquake_margin_indexes) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44429304,\n",
       " 54591478,\n",
       " 34095097,\n",
       " 48869367,\n",
       " 31010810,\n",
       " 27176955,\n",
       " 62009332,\n",
       " 30437370,\n",
       " 37101561,\n",
       " 43991032,\n",
       " 42442743,\n",
       " 33988602,\n",
       " 32976890,\n",
       " 56791029,\n",
       " 36417529]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_earthquakes_length = earthquakes_length[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete_earthquaces_length = complete_earthquaces_length[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44429304,\n",
       " 54591478,\n",
       " 34095097,\n",
       " 48869367,\n",
       " 31010810,\n",
       " 27176955,\n",
       " 62009332,\n",
       " 30437370,\n",
       " 37101561,\n",
       " 43991032,\n",
       " 42442743,\n",
       " 33988602,\n",
       " 32976890,\n",
       " 56791029]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_earthquakes_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.15 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "earthquake_1_df = pd.read_csv(\n",
    "    '../input/train/train.csv',\n",
    "    #nrows=100000000,\n",
    "    names=['acoustic_data', 'time_to_failure'],\n",
    "    dtype={'acoustic_data': np.float32, 'time_to_failure': np.float32},\n",
    "    skiprows=earthquake_margin_indexes[0],\n",
    "    nrows=complete_earthquakes_length[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44429304 entries, 0 to 44429303\n",
      "Data columns (total 2 columns):\n",
      "acoustic_data      float32\n",
      "time_to_failure    float32\n",
      "dtypes: float32(2)\n",
      "memory usage: 339.0 MB\n"
     ]
    }
   ],
   "source": [
    "earthquake_1_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "earthquake_1_with_additional_features_df = features_maker(earthquake_1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.randint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_indexes.shape: (20,)\n",
      "just after create sample_df, sample_df.shape[0]: 20\n",
      "sample_df.shape[0] just before main loop: 20\n",
      "in main loop, sample_df.shape: (20, 2)\n",
      "sample_df.shape[0] before assign feature_values_list: 20\n",
      "len(feature_values_list): 20\n",
      "in main loop, sample_df.shape: (20, 3)\n",
      "sample_df.shape[0] before assign feature_values_list: 20\n",
      "len(feature_values_list): 20\n",
      "in main loop, sample_df.shape: (20, 4)\n",
      "sample_df.shape[0] before assign feature_values_list: 20\n",
      "len(feature_values_list): 20\n",
      "sample_df.index:\n",
      " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "holdout_indexes:\n",
      " [6 3 0 9]\n",
      "train_indexes:\n",
      " [1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Full calculation feature value time (with slicing) 0.008262900511423747 min:\n",
      "CPU times: user 612 ms, sys: 4 ms, total: 616 ms\n",
      "Wall time: 613 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "earthquake_1_with_additional_features_df, holdout_df = add_features(earthquake_1_df, sample_size=20, holdout_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'earthquake_1_with_additional_features_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e76a252ba289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mearthquake_1_with_additional_features_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mearthquake_1_with_additional_features_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'earthquake_1_with_additional_features_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(earthquake_1_with_additional_features_df[:10])\n",
    "print()\n",
    "print(earthquake_1_with_additional_features_df[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
